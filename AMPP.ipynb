{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVkpw5b_DPw6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vx95u-dFsBx",
        "outputId": "dd366414-3f45-4878-ada2-084aef8e18aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3C6HBGyFs6G"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAXBHqfFw9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5rkGmusF1Qs"
      },
      "outputs": [],
      "source": [
        "estimator = [('RF', RandomForestClassifier(n_estimators = 450, max_depth = 9)), ('XGB', XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1)),\n",
        "             ('Cat', CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35)), ('LGBM', LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50)),\n",
        "             ('ETC', ExtraTreesClassifier(n_estimators = 450, max_depth = 7)),('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
        "             ('ADB', AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50))]\n",
        "Stacking = StackingClassifier( estimators=estimator, final_estimator= XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X7dcTDneAxU"
      },
      "source": [
        "# **FastText**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gY63zhgSJKK"
      },
      "source": [
        "**Imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJhc0y_av66D"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcmhpOeZv7yj",
        "outputId": "a627c856-9616-4783-f644-d5653cf0e837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.947773  0.627461   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.935628  0.528320   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.931579  0.467813   \n",
            "3                             KNeighborsClassifier()  0.938057  0.535662   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.982996  0.891603   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.981377  0.884385   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983401  0.894370   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.982996  0.891687   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.985830  0.910625   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.564978   1.000000  0.416290  0.587859     1.000000     0.416290  \n",
            "1  0.499818   0.762712  0.407240  0.530973     0.987550     0.407240  \n",
            "2  0.359107   1.000000  0.235294  0.380952     1.000000     0.235294  \n",
            "3  0.456981   0.959459  0.321267  0.481356     0.998666     0.321267  \n",
            "4  0.886367   0.994475  0.814480  0.895522     0.999555     0.814480  \n",
            "5  0.884284   0.906977  0.882353  0.894495     0.991107     0.882353  \n",
            "6  0.888825   1.000000  0.814480  0.897756     1.000000     0.814480  \n",
            "7  0.885860   1.000000  0.809955  0.895000     1.000000     0.809955  \n",
            "8  0.909526   0.960396  0.877828  0.917258     0.996443     0.877828  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total metrics(FT-CV).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io3c-HQQVWnW"
      },
      "source": [
        "**ADASYN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tasr1hZ24x-S"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoADQ0q6VcRQ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN(random_state=42)\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4mxq7S1Vstf",
        "outputId": "9c9ebd14-dcbd-470a-e555-ac513761e6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.987033  0.974390   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.830315  0.660917   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.788732  0.636056   \n",
            "3                             KNeighborsClassifier()  0.835010  0.710252   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989269  0.978538   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.957299  0.915184   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.997317  0.994635   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996647  0.993295   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.997988  0.995981   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.974062   1.000000  0.973921  0.986788     1.000000     0.973921  \n",
            "1  0.660672   0.820569  0.843076  0.831670     0.817697     0.843076  \n",
            "2  0.576453   0.999219  0.575540  0.730385     0.999555     0.575540  \n",
            "3  0.670617   0.750844  1.000000  0.857694     0.671854     1.000000  \n",
            "4  0.978537   0.989649  0.988759  0.989204     0.989773     0.988759  \n",
            "5  0.914613   0.941381  0.974820  0.957809     0.939973     0.974820  \n",
            "6  0.994634   0.997750  0.996853  0.997301     0.997777     0.996853  \n",
            "7  0.993293   0.997747  0.995504  0.996624     0.997777     0.995504  \n",
            "8  0.995976   0.996414  0.999550  0.997980     0.996443     0.999550  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(ADASYN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgOf9Y5O5f8T"
      },
      "source": [
        "**SMOTEN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf5G-CAj45RF"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUJ4mLrJ5lZP"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DI8ytRS5w0K",
        "outputId": "8eddce73-814f-4bab-cb1e-eacaed39f723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.977546  0.956056   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.931525  0.863281   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.937750  0.882365   \n",
            "3                             KNeighborsClassifier()  0.975100  0.950322   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.994664  0.989360   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.991774  0.983565   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.995109  0.990243   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995331  0.990706   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993997  0.988023   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.955091   1.000000  0.955091  0.977030     1.000000     0.955091  \n",
            "1  0.863050   0.941739  0.919964  0.930724     0.943086     0.919964  \n",
            "2  0.875500   1.000000  0.875500  0.933618     1.000000     0.875500  \n",
            "3  0.950200   0.982829  0.967096  0.974899     0.983104     0.967096  \n",
            "4  0.989329   0.998655  0.990663  0.994643     0.998666     0.990663  \n",
            "5  0.983548   0.988948  0.994664  0.991798     0.988884     0.994664  \n",
            "6  0.990218   0.998657  0.991552  0.995091     0.998666     0.991552  \n",
            "7  0.990663   1.000000  0.990663  0.995309     1.000000     0.990663  \n",
            "8  0.987995   0.997760  0.990218  0.993975     0.997777     0.990218  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(SMOTEN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12nyQiuNrIP"
      },
      "source": [
        "**SMOTETomek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxR-J65q46ZN"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qarUdpJdNsUX"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek(random_state=42)\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DT1z0BbOKbg",
        "outputId": "ce23dd9e-16e7-472c-dd82-18524b0f6601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.985549  0.971479   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.805691  0.612439   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.819031  0.684467   \n",
            "3                             KNeighborsClassifier()  0.841263  0.719761   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.991774  0.983553   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960427  0.921326   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.996221  0.992444   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996888  0.993777   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.998666  0.997332   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.971098   0.999543  0.971543  0.985344     0.999555     0.971543  \n",
            "1  0.611383   0.824752  0.776345  0.799817     0.835038     0.776345  \n",
            "2  0.638061   1.000000  0.638061  0.779045     1.000000     0.638061  \n",
            "3  0.682526   0.759028  1.000000  0.863008     0.682526     1.000000  \n",
            "4  0.983548   0.990248  0.993330  0.991787     0.990218     0.993330  \n",
            "5  0.920854   0.946144  0.976434  0.961050     0.944420     0.976434  \n",
            "6  0.992441   0.997326  0.995109  0.996216     0.997332     0.995109  \n",
            "7  0.993775   0.997773  0.995998  0.996885     0.997777     0.995998  \n",
            "8  0.997332   0.998666  0.998666  0.998666     0.998666     0.998666  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"FastText-CV(SMOTETomek.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WqNyX8B2AZF"
      },
      "source": [
        "**NearMiss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK61E1Tc47js"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrAY5z3h2FBj"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiYfdLVM2HfO",
        "outputId": "724b599c-cfdc-40fa-b666-4cf57ddcf27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.984163  0.968574   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.832579  0.666908   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932127  0.871275   \n",
            "3                             KNeighborsClassifier()  0.685520  0.472860   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.986425  0.973209   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.968326  0.936690   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.986425  0.972891   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.981900  0.963801   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988688  0.977466   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.968326   0.995370  0.972851  0.983982     0.995475     0.972851  \n",
            "1  0.665158   0.858537  0.796380  0.826291     0.868778     0.796380  \n",
            "2  0.864253   0.994819  0.868778  0.927536     0.995475     0.868778  \n",
            "3  0.371041   0.988095  0.375566  0.544262     0.995475     0.375566  \n",
            "4  0.972851   1.000000  0.972851  0.986239     1.000000     0.972851  \n",
            "5  0.936652   0.964126  0.972851  0.968468     0.963801     0.972851  \n",
            "6  0.972851   0.990868  0.981900  0.986364     0.990950     0.981900  \n",
            "7  0.963801   0.981900  0.981900  0.981900     0.981900     0.981900  \n",
            "8  0.977376   0.995413  0.981900  0.988610     0.995475     0.981900  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(NearMiss)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Jn5FNj2PZJ"
      },
      "source": [
        "**TomekLinks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgmEhKfa48cO"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5R3UG3j2VM7"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZUvntCL2YS-",
        "outputId": "ac906829-c4f7-46b3-b52c-691dd8d0616c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.947368  0.623910   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.936032  0.533442   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.931984  0.472387   \n",
            "3                             KNeighborsClassifier()  0.938057  0.535662   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.982996  0.891603   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.981377  0.884385   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983401  0.894370   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.982996  0.891687   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.986235  0.913151   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.560389   1.000000  0.411765  0.583333     1.000000     0.411765  \n",
            "1  0.506785   0.760331  0.416290  0.538012     0.987105     0.416290  \n",
            "2  0.364877   1.000000  0.239819  0.386861     1.000000     0.239819  \n",
            "3  0.456981   0.959459  0.321267  0.481356     0.998666     0.321267  \n",
            "4  0.886367   0.994475  0.814480  0.895522     0.999555     0.814480  \n",
            "5  0.884284   0.906977  0.882353  0.894495     0.991107     0.882353  \n",
            "6  0.888825   1.000000  0.814480  0.897756     1.000000     0.814480  \n",
            "7  0.885860   1.000000  0.809955  0.895000     1.000000     0.809955  \n",
            "8  0.911924   0.965174  0.877828  0.919431     0.996888     0.877828  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(TomekLinks)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raDXKWeOVnJ2"
      },
      "source": [
        "**Ind-Test**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ts = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_ts.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_ts[columns]\n",
        "ytrain = df_ts[target]"
      ],
      "metadata": {
        "id": "gGZvou65EFyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEkq2vHzP-j2"
      },
      "outputs": [],
      "source": [
        "df_ts = pd.read_csv('/content/Re-FT-Ind.csv')\n",
        "columns = df_ts.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_ts[columns]\n",
        "ytest = df_ts[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ikpgbGZQEzl",
        "outputId": "991a01ec-13d9-4891-95cb-dd7411339ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3919275\ttotal: 149ms\tremaining: 6.58s\n",
            "1:\tlearn: 0.2686525\ttotal: 256ms\tremaining: 5.49s\n",
            "2:\tlearn: 0.2206487\ttotal: 359ms\tremaining: 5.03s\n",
            "3:\tlearn: 0.1813348\ttotal: 448ms\tremaining: 4.59s\n",
            "4:\tlearn: 0.1655488\ttotal: 554ms\tremaining: 4.43s\n",
            "5:\tlearn: 0.1488227\ttotal: 643ms\tremaining: 4.18s\n",
            "6:\tlearn: 0.1365108\ttotal: 750ms\tremaining: 4.07s\n",
            "7:\tlearn: 0.1226008\ttotal: 833ms\tremaining: 3.85s\n",
            "8:\tlearn: 0.1124686\ttotal: 961ms\tremaining: 3.85s\n",
            "9:\tlearn: 0.0997102\ttotal: 1.11s\tremaining: 3.88s\n",
            "10:\tlearn: 0.0915259\ttotal: 1.26s\tremaining: 3.88s\n",
            "11:\tlearn: 0.0824956\ttotal: 1.39s\tremaining: 3.82s\n",
            "12:\tlearn: 0.0797137\ttotal: 1.55s\tremaining: 3.81s\n",
            "13:\tlearn: 0.0729308\ttotal: 1.72s\tremaining: 3.81s\n",
            "14:\tlearn: 0.0626218\ttotal: 1.88s\tremaining: 3.77s\n",
            "15:\tlearn: 0.0578231\ttotal: 2.05s\tremaining: 3.71s\n",
            "16:\tlearn: 0.0555051\ttotal: 2.21s\tremaining: 3.64s\n",
            "17:\tlearn: 0.0507111\ttotal: 2.37s\tremaining: 3.55s\n",
            "18:\tlearn: 0.0472555\ttotal: 2.54s\tremaining: 3.48s\n",
            "19:\tlearn: 0.0435461\ttotal: 2.69s\tremaining: 3.36s\n",
            "20:\tlearn: 0.0409847\ttotal: 2.83s\tremaining: 3.23s\n",
            "21:\tlearn: 0.0379505\ttotal: 2.96s\tremaining: 3.09s\n",
            "22:\tlearn: 0.0349406\ttotal: 3.12s\tremaining: 2.99s\n",
            "23:\tlearn: 0.0330366\ttotal: 3.27s\tremaining: 2.86s\n",
            "24:\tlearn: 0.0314613\ttotal: 3.42s\tremaining: 2.73s\n",
            "25:\tlearn: 0.0302137\ttotal: 3.58s\tremaining: 2.62s\n",
            "26:\tlearn: 0.0276295\ttotal: 3.74s\tremaining: 2.49s\n",
            "27:\tlearn: 0.0256381\ttotal: 3.9s\tremaining: 2.37s\n",
            "28:\tlearn: 0.0235764\ttotal: 4.07s\tremaining: 2.24s\n",
            "29:\tlearn: 0.0225392\ttotal: 4.21s\tremaining: 2.1s\n",
            "30:\tlearn: 0.0212084\ttotal: 4.37s\tremaining: 1.98s\n",
            "31:\tlearn: 0.0197103\ttotal: 4.53s\tremaining: 1.84s\n",
            "32:\tlearn: 0.0185809\ttotal: 4.7s\tremaining: 1.71s\n",
            "33:\tlearn: 0.0173598\ttotal: 4.86s\tremaining: 1.57s\n",
            "34:\tlearn: 0.0165014\ttotal: 5.03s\tremaining: 1.44s\n",
            "35:\tlearn: 0.0155893\ttotal: 5.19s\tremaining: 1.3s\n",
            "36:\tlearn: 0.0145249\ttotal: 5.34s\tremaining: 1.15s\n",
            "37:\tlearn: 0.0138093\ttotal: 5.48s\tremaining: 1.01s\n",
            "38:\tlearn: 0.0133816\ttotal: 5.61s\tremaining: 863ms\n",
            "39:\tlearn: 0.0128713\ttotal: 5.7s\tremaining: 713ms\n",
            "40:\tlearn: 0.0121220\ttotal: 5.78s\tremaining: 564ms\n",
            "41:\tlearn: 0.0117594\ttotal: 5.89s\tremaining: 421ms\n",
            "42:\tlearn: 0.0107666\ttotal: 6s\tremaining: 279ms\n",
            "43:\tlearn: 0.0101733\ttotal: 6.13s\tremaining: 139ms\n",
            "44:\tlearn: 0.0098213\ttotal: 6.22s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 221, number of negative: 2249\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004281 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 2470, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089474 -> initscore=-2.320078\n",
            "[LightGBM] [Info] Start training from score -2.320078\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3919275\ttotal: 77.1ms\tremaining: 3.39s\n",
            "1:\tlearn: 0.2686525\ttotal: 135ms\tremaining: 2.9s\n",
            "2:\tlearn: 0.2206487\ttotal: 192ms\tremaining: 2.68s\n",
            "3:\tlearn: 0.1813348\ttotal: 249ms\tremaining: 2.55s\n",
            "4:\tlearn: 0.1655488\ttotal: 316ms\tremaining: 2.53s\n",
            "5:\tlearn: 0.1488227\ttotal: 384ms\tremaining: 2.49s\n",
            "6:\tlearn: 0.1365108\ttotal: 444ms\tremaining: 2.41s\n",
            "7:\tlearn: 0.1226008\ttotal: 501ms\tremaining: 2.32s\n",
            "8:\tlearn: 0.1124686\ttotal: 563ms\tremaining: 2.25s\n",
            "9:\tlearn: 0.0997102\ttotal: 622ms\tremaining: 2.18s\n",
            "10:\tlearn: 0.0915259\ttotal: 680ms\tremaining: 2.1s\n",
            "11:\tlearn: 0.0824956\ttotal: 738ms\tremaining: 2.03s\n",
            "12:\tlearn: 0.0797137\ttotal: 801ms\tremaining: 1.97s\n",
            "13:\tlearn: 0.0729308\ttotal: 857ms\tremaining: 1.9s\n",
            "14:\tlearn: 0.0626218\ttotal: 913ms\tremaining: 1.83s\n",
            "15:\tlearn: 0.0578231\ttotal: 970ms\tremaining: 1.76s\n",
            "16:\tlearn: 0.0555051\ttotal: 1.03s\tremaining: 1.7s\n",
            "17:\tlearn: 0.0507111\ttotal: 1.09s\tremaining: 1.64s\n",
            "18:\tlearn: 0.0472555\ttotal: 1.15s\tremaining: 1.58s\n",
            "19:\tlearn: 0.0435461\ttotal: 1.21s\tremaining: 1.51s\n",
            "20:\tlearn: 0.0409847\ttotal: 1.27s\tremaining: 1.45s\n",
            "21:\tlearn: 0.0379505\ttotal: 1.33s\tremaining: 1.39s\n",
            "22:\tlearn: 0.0349406\ttotal: 1.41s\tremaining: 1.35s\n",
            "23:\tlearn: 0.0330366\ttotal: 1.47s\tremaining: 1.28s\n",
            "24:\tlearn: 0.0314613\ttotal: 1.53s\tremaining: 1.22s\n",
            "25:\tlearn: 0.0302137\ttotal: 1.59s\tremaining: 1.16s\n",
            "26:\tlearn: 0.0276295\ttotal: 1.65s\tremaining: 1.1s\n",
            "27:\tlearn: 0.0256381\ttotal: 1.7s\tremaining: 1.03s\n",
            "28:\tlearn: 0.0235764\ttotal: 1.77s\tremaining: 976ms\n",
            "29:\tlearn: 0.0225392\ttotal: 1.83s\tremaining: 916ms\n",
            "30:\tlearn: 0.0212084\ttotal: 1.89s\tremaining: 855ms\n",
            "31:\tlearn: 0.0197103\ttotal: 1.95s\tremaining: 792ms\n",
            "32:\tlearn: 0.0185809\ttotal: 2.01s\tremaining: 730ms\n",
            "33:\tlearn: 0.0173598\ttotal: 2.08s\tremaining: 673ms\n",
            "34:\tlearn: 0.0165014\ttotal: 2.14s\tremaining: 611ms\n",
            "35:\tlearn: 0.0155893\ttotal: 2.19s\tremaining: 548ms\n",
            "36:\tlearn: 0.0145249\ttotal: 2.25s\tremaining: 487ms\n",
            "37:\tlearn: 0.0138093\ttotal: 2.31s\tremaining: 426ms\n",
            "38:\tlearn: 0.0133816\ttotal: 2.37s\tremaining: 365ms\n",
            "39:\tlearn: 0.0128713\ttotal: 2.44s\tremaining: 305ms\n",
            "40:\tlearn: 0.0121220\ttotal: 2.5s\tremaining: 244ms\n",
            "41:\tlearn: 0.0117594\ttotal: 2.56s\tremaining: 183ms\n",
            "42:\tlearn: 0.0107666\ttotal: 2.62s\tremaining: 122ms\n",
            "43:\tlearn: 0.0101733\ttotal: 2.68s\tremaining: 60.9ms\n",
            "44:\tlearn: 0.0098213\ttotal: 2.74s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 221, number of negative: 2249\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004322 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 2470, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089474 -> initscore=-2.320078\n",
            "[LightGBM] [Info] Start training from score -2.320078\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.4028347\ttotal: 140ms\tremaining: 6.16s\n",
            "1:\tlearn: 0.2798156\ttotal: 248ms\tremaining: 5.33s\n",
            "2:\tlearn: 0.2217853\ttotal: 358ms\tremaining: 5.01s\n",
            "3:\tlearn: 0.1832767\ttotal: 433ms\tremaining: 4.44s\n",
            "4:\tlearn: 0.1674533\ttotal: 492ms\tremaining: 3.93s\n",
            "5:\tlearn: 0.1454113\ttotal: 548ms\tremaining: 3.56s\n",
            "6:\tlearn: 0.1280727\ttotal: 614ms\tremaining: 3.33s\n",
            "7:\tlearn: 0.1201164\ttotal: 670ms\tremaining: 3.1s\n",
            "8:\tlearn: 0.1093300\ttotal: 727ms\tremaining: 2.91s\n",
            "9:\tlearn: 0.0991693\ttotal: 784ms\tremaining: 2.74s\n",
            "10:\tlearn: 0.0902838\ttotal: 844ms\tremaining: 2.61s\n",
            "11:\tlearn: 0.0811798\ttotal: 899ms\tremaining: 2.47s\n",
            "12:\tlearn: 0.0740452\ttotal: 957ms\tremaining: 2.35s\n",
            "13:\tlearn: 0.0678896\ttotal: 1.01s\tremaining: 2.24s\n",
            "14:\tlearn: 0.0623468\ttotal: 1.08s\tremaining: 2.16s\n",
            "15:\tlearn: 0.0554619\ttotal: 1.15s\tremaining: 2.08s\n",
            "16:\tlearn: 0.0530556\ttotal: 1.21s\tremaining: 2s\n",
            "17:\tlearn: 0.0496793\ttotal: 1.27s\tremaining: 1.91s\n",
            "18:\tlearn: 0.0458901\ttotal: 1.33s\tremaining: 1.82s\n",
            "19:\tlearn: 0.0429639\ttotal: 1.39s\tremaining: 1.73s\n",
            "20:\tlearn: 0.0414482\ttotal: 1.44s\tremaining: 1.65s\n",
            "21:\tlearn: 0.0390800\ttotal: 1.5s\tremaining: 1.57s\n",
            "22:\tlearn: 0.0371118\ttotal: 1.56s\tremaining: 1.49s\n",
            "23:\tlearn: 0.0331862\ttotal: 1.61s\tremaining: 1.41s\n",
            "24:\tlearn: 0.0308610\ttotal: 1.68s\tremaining: 1.34s\n",
            "25:\tlearn: 0.0296637\ttotal: 1.73s\tremaining: 1.27s\n",
            "26:\tlearn: 0.0276098\ttotal: 1.79s\tremaining: 1.2s\n",
            "27:\tlearn: 0.0263687\ttotal: 1.85s\tremaining: 1.12s\n",
            "28:\tlearn: 0.0248823\ttotal: 1.91s\tremaining: 1.05s\n",
            "29:\tlearn: 0.0224760\ttotal: 1.96s\tremaining: 982ms\n",
            "30:\tlearn: 0.0217509\ttotal: 2.03s\tremaining: 915ms\n",
            "31:\tlearn: 0.0212242\ttotal: 2.08s\tremaining: 847ms\n",
            "32:\tlearn: 0.0189930\ttotal: 2.15s\tremaining: 781ms\n",
            "33:\tlearn: 0.0177184\ttotal: 2.21s\tremaining: 715ms\n",
            "34:\tlearn: 0.0173402\ttotal: 2.28s\tremaining: 650ms\n",
            "35:\tlearn: 0.0163840\ttotal: 2.33s\tremaining: 584ms\n",
            "36:\tlearn: 0.0157148\ttotal: 2.4s\tremaining: 518ms\n",
            "37:\tlearn: 0.0150349\ttotal: 2.45s\tremaining: 452ms\n",
            "38:\tlearn: 0.0145550\ttotal: 2.51s\tremaining: 387ms\n",
            "39:\tlearn: 0.0138662\ttotal: 2.57s\tremaining: 322ms\n",
            "40:\tlearn: 0.0134136\ttotal: 2.63s\tremaining: 257ms\n",
            "41:\tlearn: 0.0130891\ttotal: 2.69s\tremaining: 192ms\n",
            "42:\tlearn: 0.0124787\ttotal: 2.75s\tremaining: 128ms\n",
            "43:\tlearn: 0.0120569\ttotal: 2.81s\tremaining: 63.9ms\n",
            "44:\tlearn: 0.0112857\ttotal: 2.87s\tremaining: 0us\n",
            "0:\tlearn: 0.3975581\ttotal: 83.6ms\tremaining: 3.68s\n",
            "1:\tlearn: 0.2717723\ttotal: 144ms\tremaining: 3.1s\n",
            "2:\tlearn: 0.2220027\ttotal: 210ms\tremaining: 2.94s\n",
            "3:\tlearn: 0.1842318\ttotal: 273ms\tremaining: 2.8s\n",
            "4:\tlearn: 0.1625447\ttotal: 336ms\tremaining: 2.69s\n",
            "5:\tlearn: 0.1444333\ttotal: 402ms\tremaining: 2.61s\n",
            "6:\tlearn: 0.1298646\ttotal: 463ms\tremaining: 2.51s\n",
            "7:\tlearn: 0.1185617\ttotal: 525ms\tremaining: 2.43s\n",
            "8:\tlearn: 0.1101126\ttotal: 590ms\tremaining: 2.36s\n",
            "9:\tlearn: 0.1045079\ttotal: 650ms\tremaining: 2.27s\n",
            "10:\tlearn: 0.0997345\ttotal: 710ms\tremaining: 2.19s\n",
            "11:\tlearn: 0.0948191\ttotal: 767ms\tremaining: 2.11s\n",
            "12:\tlearn: 0.0855796\ttotal: 828ms\tremaining: 2.04s\n",
            "13:\tlearn: 0.0811589\ttotal: 886ms\tremaining: 1.96s\n",
            "14:\tlearn: 0.0736584\ttotal: 956ms\tremaining: 1.91s\n",
            "15:\tlearn: 0.0704235\ttotal: 1.01s\tremaining: 1.84s\n",
            "16:\tlearn: 0.0672968\ttotal: 1.08s\tremaining: 1.78s\n",
            "17:\tlearn: 0.0602706\ttotal: 1.14s\tremaining: 1.71s\n",
            "18:\tlearn: 0.0554420\ttotal: 1.2s\tremaining: 1.64s\n",
            "19:\tlearn: 0.0514253\ttotal: 1.27s\tremaining: 1.58s\n",
            "20:\tlearn: 0.0496864\ttotal: 1.33s\tremaining: 1.52s\n",
            "21:\tlearn: 0.0468587\ttotal: 1.39s\tremaining: 1.45s\n",
            "22:\tlearn: 0.0450995\ttotal: 1.45s\tremaining: 1.39s\n",
            "23:\tlearn: 0.0389683\ttotal: 1.51s\tremaining: 1.32s\n",
            "24:\tlearn: 0.0383352\ttotal: 1.57s\tremaining: 1.26s\n",
            "25:\tlearn: 0.0361945\ttotal: 1.65s\tremaining: 1.21s\n",
            "26:\tlearn: 0.0345569\ttotal: 1.71s\tremaining: 1.14s\n",
            "27:\tlearn: 0.0316702\ttotal: 1.76s\tremaining: 1.07s\n",
            "28:\tlearn: 0.0310408\ttotal: 1.83s\tremaining: 1.01s\n",
            "29:\tlearn: 0.0281987\ttotal: 1.89s\tremaining: 944ms\n",
            "30:\tlearn: 0.0276685\ttotal: 1.94s\tremaining: 878ms\n",
            "31:\tlearn: 0.0258526\ttotal: 2s\tremaining: 813ms\n",
            "32:\tlearn: 0.0254031\ttotal: 2.06s\tremaining: 750ms\n",
            "33:\tlearn: 0.0237290\ttotal: 2.12s\tremaining: 686ms\n",
            "34:\tlearn: 0.0230105\ttotal: 2.18s\tremaining: 624ms\n",
            "35:\tlearn: 0.0221440\ttotal: 2.24s\tremaining: 560ms\n",
            "36:\tlearn: 0.0203303\ttotal: 2.32s\tremaining: 501ms\n",
            "37:\tlearn: 0.0191219\ttotal: 2.38s\tremaining: 438ms\n",
            "38:\tlearn: 0.0179162\ttotal: 2.44s\tremaining: 375ms\n",
            "39:\tlearn: 0.0168226\ttotal: 2.49s\tremaining: 312ms\n",
            "40:\tlearn: 0.0155814\ttotal: 2.55s\tremaining: 249ms\n",
            "41:\tlearn: 0.0147633\ttotal: 2.61s\tremaining: 186ms\n",
            "42:\tlearn: 0.0142178\ttotal: 2.67s\tremaining: 124ms\n",
            "43:\tlearn: 0.0132424\ttotal: 2.72s\tremaining: 61.9ms\n",
            "44:\tlearn: 0.0126415\ttotal: 2.79s\tremaining: 0us\n",
            "0:\tlearn: 0.3962569\ttotal: 79.5ms\tremaining: 3.5s\n",
            "1:\tlearn: 0.2733795\ttotal: 142ms\tremaining: 3.05s\n",
            "2:\tlearn: 0.2200753\ttotal: 202ms\tremaining: 2.83s\n",
            "3:\tlearn: 0.1778810\ttotal: 260ms\tremaining: 2.66s\n",
            "4:\tlearn: 0.1585188\ttotal: 316ms\tremaining: 2.53s\n",
            "5:\tlearn: 0.1425429\ttotal: 377ms\tremaining: 2.45s\n",
            "6:\tlearn: 0.1299266\ttotal: 449ms\tremaining: 2.44s\n",
            "7:\tlearn: 0.1195528\ttotal: 506ms\tremaining: 2.34s\n",
            "8:\tlearn: 0.1095768\ttotal: 565ms\tremaining: 2.26s\n",
            "9:\tlearn: 0.0996088\ttotal: 634ms\tremaining: 2.22s\n",
            "10:\tlearn: 0.0932411\ttotal: 694ms\tremaining: 2.14s\n",
            "11:\tlearn: 0.0813936\ttotal: 753ms\tremaining: 2.07s\n",
            "12:\tlearn: 0.0744232\ttotal: 817ms\tremaining: 2.01s\n",
            "13:\tlearn: 0.0682196\ttotal: 877ms\tremaining: 1.94s\n",
            "14:\tlearn: 0.0630092\ttotal: 934ms\tremaining: 1.87s\n",
            "15:\tlearn: 0.0579771\ttotal: 990ms\tremaining: 1.79s\n",
            "16:\tlearn: 0.0560618\ttotal: 1.05s\tremaining: 1.72s\n",
            "17:\tlearn: 0.0509458\ttotal: 1.11s\tremaining: 1.66s\n",
            "18:\tlearn: 0.0491457\ttotal: 1.17s\tremaining: 1.6s\n",
            "19:\tlearn: 0.0464032\ttotal: 1.23s\tremaining: 1.54s\n",
            "20:\tlearn: 0.0443827\ttotal: 1.29s\tremaining: 1.48s\n",
            "21:\tlearn: 0.0427102\ttotal: 1.35s\tremaining: 1.41s\n",
            "22:\tlearn: 0.0394480\ttotal: 1.41s\tremaining: 1.35s\n",
            "23:\tlearn: 0.0343731\ttotal: 1.48s\tremaining: 1.29s\n",
            "24:\tlearn: 0.0332252\ttotal: 1.54s\tremaining: 1.23s\n",
            "25:\tlearn: 0.0312277\ttotal: 1.6s\tremaining: 1.17s\n",
            "26:\tlearn: 0.0279599\ttotal: 1.66s\tremaining: 1.1s\n",
            "27:\tlearn: 0.0266439\ttotal: 1.72s\tremaining: 1.04s\n",
            "28:\tlearn: 0.0248444\ttotal: 1.77s\tremaining: 978ms\n",
            "29:\tlearn: 0.0212731\ttotal: 1.84s\tremaining: 919ms\n",
            "30:\tlearn: 0.0199621\ttotal: 1.9s\tremaining: 857ms\n",
            "31:\tlearn: 0.0190618\ttotal: 1.95s\tremaining: 794ms\n",
            "32:\tlearn: 0.0182673\ttotal: 2.01s\tremaining: 732ms\n",
            "33:\tlearn: 0.0163594\ttotal: 2.07s\tremaining: 671ms\n",
            "34:\tlearn: 0.0158492\ttotal: 2.13s\tremaining: 609ms\n",
            "35:\tlearn: 0.0151685\ttotal: 2.19s\tremaining: 548ms\n",
            "36:\tlearn: 0.0148539\ttotal: 2.25s\tremaining: 487ms\n",
            "37:\tlearn: 0.0134248\ttotal: 2.32s\tremaining: 427ms\n",
            "38:\tlearn: 0.0126889\ttotal: 2.38s\tremaining: 367ms\n",
            "39:\tlearn: 0.0119752\ttotal: 2.44s\tremaining: 306ms\n",
            "40:\tlearn: 0.0113584\ttotal: 2.52s\tremaining: 245ms\n",
            "41:\tlearn: 0.0112298\ttotal: 2.58s\tremaining: 184ms\n",
            "42:\tlearn: 0.0108435\ttotal: 2.63s\tremaining: 122ms\n",
            "43:\tlearn: 0.0105220\ttotal: 2.69s\tremaining: 61.2ms\n",
            "44:\tlearn: 0.0101213\ttotal: 2.76s\tremaining: 0us\n",
            "0:\tlearn: 0.3977143\ttotal: 79.7ms\tremaining: 3.51s\n",
            "1:\tlearn: 0.2748250\ttotal: 135ms\tremaining: 2.91s\n",
            "2:\tlearn: 0.2162197\ttotal: 202ms\tremaining: 2.83s\n",
            "3:\tlearn: 0.1756630\ttotal: 258ms\tremaining: 2.65s\n",
            "4:\tlearn: 0.1588756\ttotal: 321ms\tremaining: 2.57s\n",
            "5:\tlearn: 0.1413704\ttotal: 377ms\tremaining: 2.45s\n",
            "6:\tlearn: 0.1259661\ttotal: 433ms\tremaining: 2.35s\n",
            "7:\tlearn: 0.1125031\ttotal: 490ms\tremaining: 2.27s\n",
            "8:\tlearn: 0.1010231\ttotal: 550ms\tremaining: 2.2s\n",
            "9:\tlearn: 0.0953983\ttotal: 608ms\tremaining: 2.13s\n",
            "10:\tlearn: 0.0896149\ttotal: 676ms\tremaining: 2.09s\n",
            "11:\tlearn: 0.0790417\ttotal: 742ms\tremaining: 2.04s\n",
            "12:\tlearn: 0.0695057\ttotal: 802ms\tremaining: 1.97s\n",
            "13:\tlearn: 0.0656070\ttotal: 858ms\tremaining: 1.9s\n",
            "14:\tlearn: 0.0595756\ttotal: 918ms\tremaining: 1.84s\n",
            "15:\tlearn: 0.0534134\ttotal: 975ms\tremaining: 1.77s\n",
            "16:\tlearn: 0.0508948\ttotal: 1.03s\tremaining: 1.7s\n",
            "17:\tlearn: 0.0459470\ttotal: 1.09s\tremaining: 1.64s\n",
            "18:\tlearn: 0.0420855\ttotal: 1.15s\tremaining: 1.57s\n",
            "19:\tlearn: 0.0388817\ttotal: 1.2s\tremaining: 1.5s\n",
            "20:\tlearn: 0.0371292\ttotal: 1.26s\tremaining: 1.44s\n",
            "21:\tlearn: 0.0352446\ttotal: 1.33s\tremaining: 1.39s\n",
            "22:\tlearn: 0.0310756\ttotal: 1.38s\tremaining: 1.32s\n",
            "23:\tlearn: 0.0295820\ttotal: 1.44s\tremaining: 1.26s\n",
            "24:\tlearn: 0.0284333\ttotal: 1.5s\tremaining: 1.2s\n",
            "25:\tlearn: 0.0258708\ttotal: 1.55s\tremaining: 1.14s\n",
            "26:\tlearn: 0.0244667\ttotal: 1.61s\tremaining: 1.07s\n",
            "27:\tlearn: 0.0217961\ttotal: 1.7s\tremaining: 1.03s\n",
            "28:\tlearn: 0.0211976\ttotal: 1.81s\tremaining: 1s\n",
            "29:\tlearn: 0.0200851\ttotal: 1.92s\tremaining: 962ms\n",
            "30:\tlearn: 0.0192944\ttotal: 2.03s\tremaining: 918ms\n",
            "31:\tlearn: 0.0185195\ttotal: 2.15s\tremaining: 872ms\n",
            "32:\tlearn: 0.0181201\ttotal: 2.25s\tremaining: 819ms\n",
            "33:\tlearn: 0.0173562\ttotal: 2.37s\tremaining: 765ms\n",
            "34:\tlearn: 0.0169794\ttotal: 2.47s\tremaining: 707ms\n",
            "35:\tlearn: 0.0160357\ttotal: 2.59s\tremaining: 647ms\n",
            "36:\tlearn: 0.0150810\ttotal: 2.7s\tremaining: 585ms\n",
            "37:\tlearn: 0.0141966\ttotal: 2.8s\tremaining: 516ms\n",
            "38:\tlearn: 0.0138348\ttotal: 2.91s\tremaining: 448ms\n",
            "39:\tlearn: 0.0133002\ttotal: 3.02s\tremaining: 377ms\n",
            "40:\tlearn: 0.0124819\ttotal: 3.12s\tremaining: 305ms\n",
            "41:\tlearn: 0.0118977\ttotal: 3.24s\tremaining: 232ms\n",
            "42:\tlearn: 0.0114983\ttotal: 3.36s\tremaining: 156ms\n",
            "43:\tlearn: 0.0106239\ttotal: 3.46s\tremaining: 78.8ms\n",
            "44:\tlearn: 0.0098103\ttotal: 3.58s\tremaining: 0us\n",
            "0:\tlearn: 0.3945342\ttotal: 168ms\tremaining: 7.38s\n",
            "1:\tlearn: 0.2776138\ttotal: 277ms\tremaining: 5.96s\n",
            "2:\tlearn: 0.2243730\ttotal: 390ms\tremaining: 5.46s\n",
            "3:\tlearn: 0.1856379\ttotal: 498ms\tremaining: 5.11s\n",
            "4:\tlearn: 0.1613356\ttotal: 617ms\tremaining: 4.93s\n",
            "5:\tlearn: 0.1447999\ttotal: 724ms\tremaining: 4.71s\n",
            "6:\tlearn: 0.1308424\ttotal: 842ms\tremaining: 4.57s\n",
            "7:\tlearn: 0.1237581\ttotal: 949ms\tremaining: 4.39s\n",
            "8:\tlearn: 0.1093351\ttotal: 1.06s\tremaining: 4.26s\n",
            "9:\tlearn: 0.0996160\ttotal: 1.17s\tremaining: 4.11s\n",
            "10:\tlearn: 0.0907723\ttotal: 1.28s\tremaining: 3.96s\n",
            "11:\tlearn: 0.0787252\ttotal: 1.4s\tremaining: 3.84s\n",
            "12:\tlearn: 0.0677666\ttotal: 1.5s\tremaining: 3.7s\n",
            "13:\tlearn: 0.0621681\ttotal: 1.59s\tremaining: 3.51s\n",
            "14:\tlearn: 0.0534215\ttotal: 1.7s\tremaining: 3.39s\n",
            "15:\tlearn: 0.0500551\ttotal: 1.81s\tremaining: 3.29s\n",
            "16:\tlearn: 0.0477896\ttotal: 1.93s\tremaining: 3.17s\n",
            "17:\tlearn: 0.0443392\ttotal: 2.02s\tremaining: 3.04s\n",
            "18:\tlearn: 0.0411991\ttotal: 2.12s\tremaining: 2.9s\n",
            "19:\tlearn: 0.0395554\ttotal: 2.24s\tremaining: 2.8s\n",
            "20:\tlearn: 0.0366739\ttotal: 2.35s\tremaining: 2.68s\n",
            "21:\tlearn: 0.0334031\ttotal: 2.4s\tremaining: 2.51s\n",
            "22:\tlearn: 0.0320455\ttotal: 2.46s\tremaining: 2.36s\n",
            "23:\tlearn: 0.0310632\ttotal: 2.53s\tremaining: 2.22s\n",
            "24:\tlearn: 0.0278451\ttotal: 2.6s\tremaining: 2.08s\n",
            "25:\tlearn: 0.0267630\ttotal: 2.65s\tremaining: 1.94s\n",
            "26:\tlearn: 0.0253961\ttotal: 2.72s\tremaining: 1.81s\n",
            "27:\tlearn: 0.0248778\ttotal: 2.77s\tremaining: 1.69s\n",
            "28:\tlearn: 0.0238488\ttotal: 2.84s\tremaining: 1.56s\n",
            "29:\tlearn: 0.0224556\ttotal: 2.9s\tremaining: 1.45s\n",
            "30:\tlearn: 0.0217580\ttotal: 2.96s\tremaining: 1.34s\n",
            "31:\tlearn: 0.0207777\ttotal: 3.02s\tremaining: 1.23s\n",
            "32:\tlearn: 0.0196824\ttotal: 3.08s\tremaining: 1.12s\n",
            "33:\tlearn: 0.0181175\ttotal: 3.16s\tremaining: 1.02s\n",
            "34:\tlearn: 0.0175863\ttotal: 3.22s\tremaining: 920ms\n",
            "35:\tlearn: 0.0163675\ttotal: 3.27s\tremaining: 819ms\n",
            "36:\tlearn: 0.0155347\ttotal: 3.33s\tremaining: 721ms\n",
            "37:\tlearn: 0.0143781\ttotal: 3.39s\tremaining: 625ms\n",
            "38:\tlearn: 0.0140849\ttotal: 3.46s\tremaining: 532ms\n",
            "39:\tlearn: 0.0136044\ttotal: 3.52s\tremaining: 439ms\n",
            "40:\tlearn: 0.0133208\ttotal: 3.58s\tremaining: 349ms\n",
            "41:\tlearn: 0.0124082\ttotal: 3.64s\tremaining: 260ms\n",
            "42:\tlearn: 0.0119543\ttotal: 3.71s\tremaining: 173ms\n",
            "43:\tlearn: 0.0110734\ttotal: 3.77s\tremaining: 85.7ms\n",
            "44:\tlearn: 0.0100483\ttotal: 3.83s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 176, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 1976, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089069 -> initscore=-2.325058\n",
            "[LightGBM] [Info] Start training from score -2.325058\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1799\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003735 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 1976, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089575 -> initscore=-2.318837\n",
            "[LightGBM] [Info] Start training from score -2.318837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1799\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004277 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 1976, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089575 -> initscore=-2.318837\n",
            "[LightGBM] [Info] Start training from score -2.318837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1799\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003769 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 1976, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089575 -> initscore=-2.318837\n",
            "[LightGBM] [Info] Start training from score -2.318837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1799\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32640\n",
            "[LightGBM] [Info] Number of data points in the train set: 1976, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089575 -> initscore=-2.318837\n",
            "[LightGBM] [Info] Start training from score -2.318837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.959416  0.643223   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.959416  0.652602   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.957792  0.625543   \n",
            "3                             KNeighborsClassifier()  0.936688  0.365137   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.954545  0.588784   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.961039  0.673574   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.967532  0.725966   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.964286  0.693889   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.967532  0.725966   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.585308   1.000000  0.431818  0.603175     1.000000     0.431818  \n",
            "1  0.636929   0.827586  0.545455  0.657534     0.991259     0.545455  \n",
            "2  0.562500   1.000000  0.409091  0.580645     1.000000     0.409091  \n",
            "3  0.314070   0.666667  0.227273  0.338983     0.991259     0.227273  \n",
            "4  0.514851   1.000000  0.363636  0.533333     1.000000     0.363636  \n",
            "5  0.664000   0.812500  0.590909  0.684211     0.989510     0.590909  \n",
            "6  0.690265   1.000000  0.545455  0.705882     1.000000     0.545455  \n",
            "7  0.650000   1.000000  0.500000  0.666667     1.000000     0.500000  \n",
            "8  0.690265   1.000000  0.545455  0.705882     1.000000     0.545455  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-Ind).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAQehR4geKHc"
      },
      "source": [
        "# **LSA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OHHN6ERr7FL"
      },
      "source": [
        "**Imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75EByGT3eMEU"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4aJ6LOAePRE"
      },
      "outputs": [],
      "source": [
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNxV7lniedjd",
        "outputId": "8cc4e95b-ed20-41ae-a8d7-2a7c49df1d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.954288  0.683748   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.958738  0.720638   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.911003  0.090590   \n",
            "3                             KNeighborsClassifier()  0.963997  0.759146   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.995550  0.972524   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.994337  0.965039   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.993528  0.959883   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995955  0.975054   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996764  0.980091   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.637149   1.000000  0.490991  0.658610     1.000000     0.490991  \n",
            "1  0.705797   0.894737  0.612613  0.727273     0.992889     0.612613  \n",
            "2  0.016280   1.000000  0.009009  0.017857     1.000000     0.009009  \n",
            "3  0.731208   1.000000  0.599099  0.749296     1.000000     0.599099  \n",
            "4  0.972274   0.995305  0.954955  0.974713     0.999556     0.954955  \n",
            "5  0.964930   0.981481  0.954955  0.968037     0.998222     0.954955  \n",
            "6  0.959079   1.000000  0.927928  0.962617     1.000000     0.927928  \n",
            "7  0.974743   1.000000  0.954955  0.976959     1.000000     0.954955  \n",
            "8  0.980042   0.990826  0.972973  0.981818     0.999111     0.972973  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRQxBBIo2yxd"
      },
      "source": [
        "**ADASYN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BoRZyco4aME"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZPBUxGD23el"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NESeBrUM2_9j",
        "outputId": "e86bfc88-6d9e-46db-93b1-0f6c41311043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.986444  0.973247   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.900444  0.800894   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.969111  0.939916   \n",
            "3                             KNeighborsClassifier()  0.997778  0.995565   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.998000  0.996005   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.984000  0.968153   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.997556  0.995116   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.998222  0.996448   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.999333  0.998668   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.972889   1.000000  0.972889  0.986258     1.000000     0.972889  \n",
            "1  0.800889   0.901873  0.898667  0.900267     0.902222     0.898667  \n",
            "2  0.938222   0.999054  0.939111  0.968156     0.999111     0.939111  \n",
            "3  0.995556   0.995575  1.000000  0.997783     0.995556     1.000000  \n",
            "4  0.996000   0.996455  0.999556  0.998003     0.996444     0.999556  \n",
            "5  0.968000   0.975546  0.992889  0.984141     0.975111     0.992889  \n",
            "6  0.995111   0.996012  0.999111  0.997559     0.996000     0.999111  \n",
            "7  0.996444   0.996897  0.999556  0.998225     0.996889     0.999556  \n",
            "8  0.998667   0.998668  1.000000  0.999334     0.998667     1.000000  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(ADASYN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "eSAM3ffOjFoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "uwLN9TCDjI3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "10eFwROojOXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SoBgsjEjVT8",
        "outputId": "43bbdc6d-11a0-4316-f68b-2950d1cc0d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.972444  0.946327   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.976444  0.953492   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.954222  0.912276   \n",
            "3                             KNeighborsClassifier()  0.981778  0.964196   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.996889  0.993797   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.996222  0.992445   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.995778  0.991584   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996444  0.992914   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996444  0.992914   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.944889   1.000000  0.944889  0.971664     1.000000     0.944889  \n",
            "1  0.952889   0.994009  0.958667  0.976018     0.994222     0.958667  \n",
            "2  0.908444   1.000000  0.908444  0.952026     1.000000     0.908444  \n",
            "3  0.963556   1.000000  0.963556  0.981440     1.000000     0.963556  \n",
            "4  0.993778   1.000000  0.993778  0.996879     1.000000     0.993778  \n",
            "5  0.992444   0.996885  0.995556  0.996220     0.996889     0.995556  \n",
            "6  0.991556   0.999552  0.992000  0.995762     0.999556     0.992000  \n",
            "7  0.992889   1.000000  0.992889  0.996432     1.000000     0.992889  \n",
            "8  0.992889   1.000000  0.992889  0.996432     1.000000     0.992889  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qARyehv3RIj"
      },
      "source": [
        "**SMOTETomek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNwtYl5b4qqM"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S83WuLOU3Zh-"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTLwYeRk3ccL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09133bdf-ae1f-4601-8a50-f2bf46a79726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.989333  0.978889   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.898667  0.797387   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.978222  0.957353   \n",
            "3                             KNeighborsClassifier()  0.998889  0.997780   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.996889  0.993779   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.984889  0.969792   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.997111  0.994227   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.997556  0.995111   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.999556  0.999111   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.978667   1.000000  0.978667  0.989218     1.000000     0.978667  \n",
            "1  0.797333   0.894112  0.904444  0.899249     0.892889     0.904444  \n",
            "2  0.956444   1.000000  0.956444  0.977737     1.000000     0.956444  \n",
            "3  0.997778   0.997783  1.000000  0.998890     0.997778     1.000000  \n",
            "4  0.993778   0.996007  0.997778  0.996892     0.996000     0.997778  \n",
            "5  0.969778   0.982317  0.987556  0.984929     0.982222     0.987556  \n",
            "6  0.994222   0.995569  0.998667  0.997116     0.995556     0.998667  \n",
            "7  0.995111   0.997335  0.997778  0.997556     0.997333     0.997778  \n",
            "8  0.999111   0.999556  0.999556  0.999556     0.999556     0.999556  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(SMOTETomek)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRqWngh-3gob"
      },
      "source": [
        "**NearMiss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlUjQ8Dt4roc"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro4kO8Xa3k06"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEXEHnpI3np7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bc9736-99d4-4510-95ff-a57303085e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.986486  0.973329   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.966216  0.932518   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.950450  0.905357   \n",
            "3                             KNeighborsClassifier()  0.909910  0.833461   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988739  0.977567   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.988739  0.977567   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.977477  0.954994   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.986486  0.973329   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990991  0.982141   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.972973   1.000000  0.972973  0.986301     1.000000     0.972973  \n",
            "1  0.932432   0.972603  0.959459  0.965986     0.972973     0.959459  \n",
            "2  0.900901   1.000000  0.900901  0.947867     1.000000     0.900901  \n",
            "3  0.819820   1.000000  0.819820  0.900990     1.000000     0.819820  \n",
            "4  0.977477   0.995434  0.981982  0.988662     0.995495     0.981982  \n",
            "5  0.977477   0.995434  0.981982  0.988662     0.995495     0.981982  \n",
            "6  0.954955   0.981818  0.972973  0.977376     0.981982     0.972973  \n",
            "7  0.972973   1.000000  0.972973  0.986301     1.000000     0.972973  \n",
            "8  0.981982   1.000000  0.981982  0.990909     1.000000     0.981982  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-All-CV(NearMiss)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z16dJjE-3tiT"
      },
      "source": [
        "**TomekLinks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIjbSY6U4X1C"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKKHCtVF32rV"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCLnHbnP39pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3c4370-f7e8-4c8b-8c4e-eedaba8275ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.955502  0.693534   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.957524  0.712519   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.911408  0.110972   \n",
            "3                             KNeighborsClassifier()  0.963997  0.759146   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.995550  0.972524   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.994337  0.965039   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.993528  0.959883   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995955  0.975054   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996359  0.977621   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.649552   1.000000  0.504505  0.670659     1.000000     0.504505  \n",
            "1  0.699278   0.877419  0.612613  0.721485     0.991556     0.612613  \n",
            "2  0.024330   1.000000  0.013514  0.026667     1.000000     0.013514  \n",
            "3  0.731208   1.000000  0.599099  0.749296     1.000000     0.599099  \n",
            "4  0.972274   0.995305  0.954955  0.974713     0.999556     0.954955  \n",
            "5  0.964930   0.981481  0.954955  0.968037     0.998222     0.954955  \n",
            "6  0.959079   1.000000  0.927928  0.962617     1.000000     0.927928  \n",
            "7  0.974743   1.000000  0.954955  0.976959     1.000000     0.954955  \n",
            "8  0.977593   0.986301  0.972973  0.979592     0.998667     0.972973  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(TomekLinks)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "KGLpm4UjGDe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "NDW348pNGGiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/Re-LSA-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest= df_tr[target]"
      ],
      "metadata": {
        "id": "OvuiRQcXGLWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmjk0RkMGSXJ",
        "outputId": "9a835036-4d67-45d3-af5c-0edd0d0c4889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3618436\ttotal: 76.3ms\tremaining: 3.36s\n",
            "1:\tlearn: 0.2419361\ttotal: 127ms\tremaining: 2.74s\n",
            "2:\tlearn: 0.1750876\ttotal: 163ms\tremaining: 2.28s\n",
            "3:\tlearn: 0.1439314\ttotal: 210ms\tremaining: 2.16s\n",
            "4:\tlearn: 0.1160574\ttotal: 263ms\tremaining: 2.11s\n",
            "5:\tlearn: 0.0971383\ttotal: 307ms\tremaining: 1.99s\n",
            "6:\tlearn: 0.0868232\ttotal: 362ms\tremaining: 1.97s\n",
            "7:\tlearn: 0.0705775\ttotal: 417ms\tremaining: 1.93s\n",
            "8:\tlearn: 0.0636306\ttotal: 473ms\tremaining: 1.89s\n",
            "9:\tlearn: 0.0575239\ttotal: 529ms\tremaining: 1.85s\n",
            "10:\tlearn: 0.0497066\ttotal: 589ms\tremaining: 1.82s\n",
            "11:\tlearn: 0.0447669\ttotal: 629ms\tremaining: 1.73s\n",
            "12:\tlearn: 0.0406392\ttotal: 681ms\tremaining: 1.68s\n",
            "13:\tlearn: 0.0378796\ttotal: 742ms\tremaining: 1.64s\n",
            "14:\tlearn: 0.0336100\ttotal: 795ms\tremaining: 1.59s\n",
            "15:\tlearn: 0.0308282\ttotal: 853ms\tremaining: 1.54s\n",
            "16:\tlearn: 0.0271913\ttotal: 910ms\tremaining: 1.5s\n",
            "17:\tlearn: 0.0249951\ttotal: 961ms\tremaining: 1.44s\n",
            "18:\tlearn: 0.0222601\ttotal: 1.01s\tremaining: 1.38s\n",
            "19:\tlearn: 0.0200442\ttotal: 1.06s\tremaining: 1.33s\n",
            "20:\tlearn: 0.0192673\ttotal: 1.12s\tremaining: 1.28s\n",
            "21:\tlearn: 0.0171898\ttotal: 1.17s\tremaining: 1.23s\n",
            "22:\tlearn: 0.0158927\ttotal: 1.22s\tremaining: 1.16s\n",
            "23:\tlearn: 0.0148814\ttotal: 1.25s\tremaining: 1.09s\n",
            "24:\tlearn: 0.0141753\ttotal: 1.28s\tremaining: 1.03s\n",
            "25:\tlearn: 0.0127839\ttotal: 1.34s\tremaining: 977ms\n",
            "26:\tlearn: 0.0123372\ttotal: 1.39s\tremaining: 930ms\n",
            "27:\tlearn: 0.0110044\ttotal: 1.44s\tremaining: 877ms\n",
            "28:\tlearn: 0.0099644\ttotal: 1.49s\tremaining: 825ms\n",
            "29:\tlearn: 0.0093359\ttotal: 1.53s\tremaining: 766ms\n",
            "30:\tlearn: 0.0088232\ttotal: 1.57s\tremaining: 707ms\n",
            "31:\tlearn: 0.0080883\ttotal: 1.61s\tremaining: 653ms\n",
            "32:\tlearn: 0.0075977\ttotal: 1.65s\tremaining: 598ms\n",
            "33:\tlearn: 0.0072197\ttotal: 1.69s\tremaining: 547ms\n",
            "34:\tlearn: 0.0065782\ttotal: 1.75s\tremaining: 499ms\n",
            "35:\tlearn: 0.0061679\ttotal: 1.78s\tremaining: 445ms\n",
            "36:\tlearn: 0.0059063\ttotal: 1.82s\tremaining: 395ms\n",
            "37:\tlearn: 0.0054499\ttotal: 1.87s\tremaining: 345ms\n",
            "38:\tlearn: 0.0052253\ttotal: 1.91s\tremaining: 294ms\n",
            "39:\tlearn: 0.0049902\ttotal: 1.94s\tremaining: 243ms\n",
            "40:\tlearn: 0.0047669\ttotal: 1.99s\tremaining: 194ms\n",
            "41:\tlearn: 0.0045055\ttotal: 2.04s\tremaining: 146ms\n",
            "42:\tlearn: 0.0042776\ttotal: 2.09s\tremaining: 97.1ms\n",
            "43:\tlearn: 0.0039533\ttotal: 2.13s\tremaining: 48.4ms\n",
            "44:\tlearn: 0.0036742\ttotal: 2.17s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3618436\ttotal: 35.2ms\tremaining: 1.55s\n",
            "1:\tlearn: 0.2419361\ttotal: 62.7ms\tremaining: 1.35s\n",
            "2:\tlearn: 0.1750876\ttotal: 89.5ms\tremaining: 1.25s\n",
            "3:\tlearn: 0.1439314\ttotal: 117ms\tremaining: 1.2s\n",
            "4:\tlearn: 0.1160574\ttotal: 143ms\tremaining: 1.14s\n",
            "5:\tlearn: 0.0971383\ttotal: 170ms\tremaining: 1.11s\n",
            "6:\tlearn: 0.0868232\ttotal: 196ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.0705775\ttotal: 222ms\tremaining: 1.03s\n",
            "8:\tlearn: 0.0636306\ttotal: 252ms\tremaining: 1.01s\n",
            "9:\tlearn: 0.0575239\ttotal: 279ms\tremaining: 976ms\n",
            "10:\tlearn: 0.0497066\ttotal: 306ms\tremaining: 946ms\n",
            "11:\tlearn: 0.0447669\ttotal: 332ms\tremaining: 913ms\n",
            "12:\tlearn: 0.0406392\ttotal: 361ms\tremaining: 888ms\n",
            "13:\tlearn: 0.0378796\ttotal: 387ms\tremaining: 857ms\n",
            "14:\tlearn: 0.0336100\ttotal: 414ms\tremaining: 828ms\n",
            "15:\tlearn: 0.0308282\ttotal: 441ms\tremaining: 800ms\n",
            "16:\tlearn: 0.0271913\ttotal: 471ms\tremaining: 775ms\n",
            "17:\tlearn: 0.0249951\ttotal: 496ms\tremaining: 745ms\n",
            "18:\tlearn: 0.0222601\ttotal: 523ms\tremaining: 716ms\n",
            "19:\tlearn: 0.0200442\ttotal: 556ms\tremaining: 695ms\n",
            "20:\tlearn: 0.0192673\ttotal: 583ms\tremaining: 667ms\n",
            "21:\tlearn: 0.0171898\ttotal: 617ms\tremaining: 645ms\n",
            "22:\tlearn: 0.0158927\ttotal: 644ms\tremaining: 616ms\n",
            "23:\tlearn: 0.0148814\ttotal: 669ms\tremaining: 586ms\n",
            "24:\tlearn: 0.0141753\ttotal: 699ms\tremaining: 559ms\n",
            "25:\tlearn: 0.0127839\ttotal: 727ms\tremaining: 531ms\n",
            "26:\tlearn: 0.0123372\ttotal: 765ms\tremaining: 510ms\n",
            "27:\tlearn: 0.0110044\ttotal: 793ms\tremaining: 481ms\n",
            "28:\tlearn: 0.0099644\ttotal: 819ms\tremaining: 452ms\n",
            "29:\tlearn: 0.0093359\ttotal: 846ms\tremaining: 423ms\n",
            "30:\tlearn: 0.0088232\ttotal: 873ms\tremaining: 394ms\n",
            "31:\tlearn: 0.0080883\ttotal: 905ms\tremaining: 368ms\n",
            "32:\tlearn: 0.0075977\ttotal: 932ms\tremaining: 339ms\n",
            "33:\tlearn: 0.0072197\ttotal: 959ms\tremaining: 310ms\n",
            "34:\tlearn: 0.0065782\ttotal: 996ms\tremaining: 284ms\n",
            "35:\tlearn: 0.0061679\ttotal: 1.02s\tremaining: 255ms\n",
            "36:\tlearn: 0.0059063\ttotal: 1.05s\tremaining: 226ms\n",
            "37:\tlearn: 0.0054499\ttotal: 1.08s\tremaining: 198ms\n",
            "38:\tlearn: 0.0052253\ttotal: 1.1s\tremaining: 170ms\n",
            "39:\tlearn: 0.0049902\ttotal: 1.13s\tremaining: 142ms\n",
            "40:\tlearn: 0.0047669\ttotal: 1.16s\tremaining: 113ms\n",
            "41:\tlearn: 0.0045055\ttotal: 1.19s\tremaining: 84.7ms\n",
            "42:\tlearn: 0.0042776\ttotal: 1.22s\tremaining: 56.6ms\n",
            "43:\tlearn: 0.0039533\ttotal: 1.25s\tremaining: 28.3ms\n",
            "44:\tlearn: 0.0036742\ttotal: 1.28s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3764795\ttotal: 38.6ms\tremaining: 1.7s\n",
            "1:\tlearn: 0.2566271\ttotal: 64.3ms\tremaining: 1.38s\n",
            "2:\tlearn: 0.1811461\ttotal: 90.4ms\tremaining: 1.26s\n",
            "3:\tlearn: 0.1433284\ttotal: 116ms\tremaining: 1.19s\n",
            "4:\tlearn: 0.1206691\ttotal: 141ms\tremaining: 1.13s\n",
            "5:\tlearn: 0.0960608\ttotal: 167ms\tremaining: 1.08s\n",
            "6:\tlearn: 0.0830143\ttotal: 195ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.0745938\ttotal: 229ms\tremaining: 1.06s\n",
            "8:\tlearn: 0.0624843\ttotal: 260ms\tremaining: 1.04s\n",
            "9:\tlearn: 0.0558012\ttotal: 286ms\tremaining: 1s\n",
            "10:\tlearn: 0.0518252\ttotal: 311ms\tremaining: 961ms\n",
            "11:\tlearn: 0.0492650\ttotal: 336ms\tremaining: 925ms\n",
            "12:\tlearn: 0.0448598\ttotal: 362ms\tremaining: 890ms\n",
            "13:\tlearn: 0.0426777\ttotal: 387ms\tremaining: 857ms\n",
            "14:\tlearn: 0.0351051\ttotal: 412ms\tremaining: 825ms\n",
            "15:\tlearn: 0.0336612\ttotal: 437ms\tremaining: 792ms\n",
            "16:\tlearn: 0.0311128\ttotal: 465ms\tremaining: 766ms\n",
            "17:\tlearn: 0.0277673\ttotal: 489ms\tremaining: 734ms\n",
            "18:\tlearn: 0.0262649\ttotal: 515ms\tremaining: 705ms\n",
            "19:\tlearn: 0.0243068\ttotal: 542ms\tremaining: 677ms\n",
            "20:\tlearn: 0.0235434\ttotal: 567ms\tremaining: 648ms\n",
            "21:\tlearn: 0.0220802\ttotal: 595ms\tremaining: 622ms\n",
            "22:\tlearn: 0.0203343\ttotal: 620ms\tremaining: 593ms\n",
            "23:\tlearn: 0.0188314\ttotal: 676ms\tremaining: 592ms\n",
            "24:\tlearn: 0.0172484\ttotal: 727ms\tremaining: 582ms\n",
            "25:\tlearn: 0.0159463\ttotal: 778ms\tremaining: 569ms\n",
            "26:\tlearn: 0.0154601\ttotal: 828ms\tremaining: 552ms\n",
            "27:\tlearn: 0.0140539\ttotal: 880ms\tremaining: 534ms\n",
            "28:\tlearn: 0.0133713\ttotal: 928ms\tremaining: 512ms\n",
            "29:\tlearn: 0.0123125\ttotal: 979ms\tremaining: 490ms\n",
            "30:\tlearn: 0.0112656\ttotal: 1.02s\tremaining: 463ms\n",
            "31:\tlearn: 0.0102845\ttotal: 1.07s\tremaining: 437ms\n",
            "32:\tlearn: 0.0100140\ttotal: 1.13s\tremaining: 410ms\n",
            "33:\tlearn: 0.0096029\ttotal: 1.18s\tremaining: 382ms\n",
            "34:\tlearn: 0.0088913\ttotal: 1.23s\tremaining: 351ms\n",
            "35:\tlearn: 0.0084430\ttotal: 1.28s\tremaining: 321ms\n",
            "36:\tlearn: 0.0079869\ttotal: 1.33s\tremaining: 288ms\n",
            "37:\tlearn: 0.0075004\ttotal: 1.38s\tremaining: 255ms\n",
            "38:\tlearn: 0.0071311\ttotal: 1.44s\tremaining: 221ms\n",
            "39:\tlearn: 0.0063392\ttotal: 1.49s\tremaining: 186ms\n",
            "40:\tlearn: 0.0062151\ttotal: 1.55s\tremaining: 151ms\n",
            "41:\tlearn: 0.0059726\ttotal: 1.6s\tremaining: 114ms\n",
            "42:\tlearn: 0.0057984\ttotal: 1.65s\tremaining: 76.6ms\n",
            "43:\tlearn: 0.0055300\ttotal: 1.7s\tremaining: 38.6ms\n",
            "44:\tlearn: 0.0054071\ttotal: 1.75s\tremaining: 0us\n",
            "0:\tlearn: 0.3606349\ttotal: 61.8ms\tremaining: 2.72s\n",
            "1:\tlearn: 0.2382167\ttotal: 112ms\tremaining: 2.41s\n",
            "2:\tlearn: 0.1825268\ttotal: 163ms\tremaining: 2.28s\n",
            "3:\tlearn: 0.1389243\ttotal: 209ms\tremaining: 2.14s\n",
            "4:\tlearn: 0.1178399\ttotal: 260ms\tremaining: 2.08s\n",
            "5:\tlearn: 0.0951629\ttotal: 311ms\tremaining: 2.02s\n",
            "6:\tlearn: 0.0802028\ttotal: 366ms\tremaining: 1.99s\n",
            "7:\tlearn: 0.0686304\ttotal: 421ms\tremaining: 1.95s\n",
            "8:\tlearn: 0.0626880\ttotal: 474ms\tremaining: 1.9s\n",
            "9:\tlearn: 0.0570882\ttotal: 524ms\tremaining: 1.83s\n",
            "10:\tlearn: 0.0530610\ttotal: 589ms\tremaining: 1.82s\n",
            "11:\tlearn: 0.0502224\ttotal: 641ms\tremaining: 1.76s\n",
            "12:\tlearn: 0.0439160\ttotal: 690ms\tremaining: 1.7s\n",
            "13:\tlearn: 0.0412064\ttotal: 739ms\tremaining: 1.64s\n",
            "14:\tlearn: 0.0348272\ttotal: 787ms\tremaining: 1.57s\n",
            "15:\tlearn: 0.0319521\ttotal: 839ms\tremaining: 1.52s\n",
            "16:\tlearn: 0.0284605\ttotal: 888ms\tremaining: 1.46s\n",
            "17:\tlearn: 0.0256559\ttotal: 942ms\tremaining: 1.41s\n",
            "18:\tlearn: 0.0236470\ttotal: 996ms\tremaining: 1.36s\n",
            "19:\tlearn: 0.0217392\ttotal: 1.04s\tremaining: 1.29s\n",
            "20:\tlearn: 0.0209010\ttotal: 1.09s\tremaining: 1.24s\n",
            "21:\tlearn: 0.0198316\ttotal: 1.14s\tremaining: 1.19s\n",
            "22:\tlearn: 0.0183091\ttotal: 1.19s\tremaining: 1.14s\n",
            "23:\tlearn: 0.0173390\ttotal: 1.24s\tremaining: 1.09s\n",
            "24:\tlearn: 0.0157376\ttotal: 1.29s\tremaining: 1.03s\n",
            "25:\tlearn: 0.0150349\ttotal: 1.34s\tremaining: 983ms\n",
            "26:\tlearn: 0.0140152\ttotal: 1.4s\tremaining: 930ms\n",
            "27:\tlearn: 0.0118607\ttotal: 1.45s\tremaining: 881ms\n",
            "28:\tlearn: 0.0110499\ttotal: 1.5s\tremaining: 829ms\n",
            "29:\tlearn: 0.0103404\ttotal: 1.55s\tremaining: 776ms\n",
            "30:\tlearn: 0.0098076\ttotal: 1.6s\tremaining: 724ms\n",
            "31:\tlearn: 0.0094584\ttotal: 1.65s\tremaining: 670ms\n",
            "32:\tlearn: 0.0083214\ttotal: 1.7s\tremaining: 619ms\n",
            "33:\tlearn: 0.0078020\ttotal: 1.76s\tremaining: 568ms\n",
            "34:\tlearn: 0.0072396\ttotal: 1.81s\tremaining: 516ms\n",
            "35:\tlearn: 0.0070283\ttotal: 1.86s\tremaining: 465ms\n",
            "36:\tlearn: 0.0065263\ttotal: 1.91s\tremaining: 413ms\n",
            "37:\tlearn: 0.0062511\ttotal: 1.96s\tremaining: 361ms\n",
            "38:\tlearn: 0.0059612\ttotal: 2.01s\tremaining: 309ms\n",
            "39:\tlearn: 0.0057171\ttotal: 2.06s\tremaining: 257ms\n",
            "40:\tlearn: 0.0056228\ttotal: 2.11s\tremaining: 206ms\n",
            "41:\tlearn: 0.0053987\ttotal: 2.16s\tremaining: 154ms\n",
            "42:\tlearn: 0.0050171\ttotal: 2.21s\tremaining: 103ms\n",
            "43:\tlearn: 0.0046884\ttotal: 2.26s\tremaining: 51.5ms\n",
            "44:\tlearn: 0.0045989\ttotal: 2.31s\tremaining: 0us\n",
            "0:\tlearn: 0.3648227\ttotal: 69.9ms\tremaining: 3.08s\n",
            "1:\tlearn: 0.2497115\ttotal: 126ms\tremaining: 2.72s\n",
            "2:\tlearn: 0.1778237\ttotal: 177ms\tremaining: 2.47s\n",
            "3:\tlearn: 0.1358891\ttotal: 231ms\tremaining: 2.37s\n",
            "4:\tlearn: 0.1131040\ttotal: 284ms\tremaining: 2.27s\n",
            "5:\tlearn: 0.0944537\ttotal: 341ms\tremaining: 2.21s\n",
            "6:\tlearn: 0.0847705\ttotal: 391ms\tremaining: 2.12s\n",
            "7:\tlearn: 0.0738741\ttotal: 441ms\tremaining: 2.04s\n",
            "8:\tlearn: 0.0651063\ttotal: 494ms\tremaining: 1.98s\n",
            "9:\tlearn: 0.0598830\ttotal: 557ms\tremaining: 1.95s\n",
            "10:\tlearn: 0.0546524\ttotal: 612ms\tremaining: 1.89s\n",
            "11:\tlearn: 0.0493784\ttotal: 668ms\tremaining: 1.84s\n",
            "12:\tlearn: 0.0441822\ttotal: 701ms\tremaining: 1.73s\n",
            "13:\tlearn: 0.0395826\ttotal: 733ms\tremaining: 1.62s\n",
            "14:\tlearn: 0.0362125\ttotal: 762ms\tremaining: 1.52s\n",
            "15:\tlearn: 0.0340972\ttotal: 789ms\tremaining: 1.43s\n",
            "16:\tlearn: 0.0297811\ttotal: 814ms\tremaining: 1.34s\n",
            "17:\tlearn: 0.0278439\ttotal: 839ms\tremaining: 1.26s\n",
            "18:\tlearn: 0.0249150\ttotal: 866ms\tremaining: 1.19s\n",
            "19:\tlearn: 0.0225401\ttotal: 892ms\tremaining: 1.11s\n",
            "20:\tlearn: 0.0204489\ttotal: 917ms\tremaining: 1.05s\n",
            "21:\tlearn: 0.0187529\ttotal: 943ms\tremaining: 986ms\n",
            "22:\tlearn: 0.0175709\ttotal: 973ms\tremaining: 930ms\n",
            "23:\tlearn: 0.0164764\ttotal: 999ms\tremaining: 874ms\n",
            "24:\tlearn: 0.0145471\ttotal: 1.02s\tremaining: 819ms\n",
            "25:\tlearn: 0.0137268\ttotal: 1.05s\tremaining: 767ms\n",
            "26:\tlearn: 0.0132052\ttotal: 1.07s\tremaining: 717ms\n",
            "27:\tlearn: 0.0126970\ttotal: 1.11s\tremaining: 676ms\n",
            "28:\tlearn: 0.0123301\ttotal: 1.15s\tremaining: 635ms\n",
            "29:\tlearn: 0.0111638\ttotal: 1.18s\tremaining: 590ms\n",
            "30:\tlearn: 0.0102388\ttotal: 1.21s\tremaining: 544ms\n",
            "31:\tlearn: 0.0099772\ttotal: 1.23s\tremaining: 500ms\n",
            "32:\tlearn: 0.0096022\ttotal: 1.25s\tremaining: 457ms\n",
            "33:\tlearn: 0.0093428\ttotal: 1.28s\tremaining: 414ms\n",
            "34:\tlearn: 0.0082141\ttotal: 1.3s\tremaining: 373ms\n",
            "35:\tlearn: 0.0078663\ttotal: 1.33s\tremaining: 333ms\n",
            "36:\tlearn: 0.0074097\ttotal: 1.36s\tremaining: 295ms\n",
            "37:\tlearn: 0.0071245\ttotal: 1.39s\tremaining: 257ms\n",
            "38:\tlearn: 0.0068099\ttotal: 1.42s\tremaining: 219ms\n",
            "39:\tlearn: 0.0065992\ttotal: 1.45s\tremaining: 181ms\n",
            "40:\tlearn: 0.0060535\ttotal: 1.47s\tremaining: 144ms\n",
            "41:\tlearn: 0.0056857\ttotal: 1.5s\tremaining: 107ms\n",
            "42:\tlearn: 0.0053632\ttotal: 1.53s\tremaining: 71ms\n",
            "43:\tlearn: 0.0051381\ttotal: 1.55s\tremaining: 35.3ms\n",
            "44:\tlearn: 0.0049861\ttotal: 1.58s\tremaining: 0us\n",
            "0:\tlearn: 0.3614322\ttotal: 37.4ms\tremaining: 1.65s\n",
            "1:\tlearn: 0.2454236\ttotal: 63.5ms\tremaining: 1.36s\n",
            "2:\tlearn: 0.1789155\ttotal: 89.2ms\tremaining: 1.25s\n",
            "3:\tlearn: 0.1339645\ttotal: 116ms\tremaining: 1.19s\n",
            "4:\tlearn: 0.1142972\ttotal: 143ms\tremaining: 1.14s\n",
            "5:\tlearn: 0.0955271\ttotal: 168ms\tremaining: 1.09s\n",
            "6:\tlearn: 0.0847727\ttotal: 195ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.0706984\ttotal: 221ms\tremaining: 1.02s\n",
            "8:\tlearn: 0.0606202\ttotal: 257ms\tremaining: 1.03s\n",
            "9:\tlearn: 0.0556231\ttotal: 284ms\tremaining: 994ms\n",
            "10:\tlearn: 0.0502756\ttotal: 309ms\tremaining: 956ms\n",
            "11:\tlearn: 0.0469673\ttotal: 335ms\tremaining: 920ms\n",
            "12:\tlearn: 0.0432059\ttotal: 361ms\tremaining: 887ms\n",
            "13:\tlearn: 0.0383527\ttotal: 386ms\tremaining: 855ms\n",
            "14:\tlearn: 0.0323055\ttotal: 413ms\tremaining: 825ms\n",
            "15:\tlearn: 0.0307854\ttotal: 439ms\tremaining: 796ms\n",
            "16:\tlearn: 0.0284374\ttotal: 469ms\tremaining: 773ms\n",
            "17:\tlearn: 0.0254638\ttotal: 498ms\tremaining: 747ms\n",
            "18:\tlearn: 0.0235461\ttotal: 533ms\tremaining: 730ms\n",
            "19:\tlearn: 0.0217671\ttotal: 559ms\tremaining: 698ms\n",
            "20:\tlearn: 0.0203807\ttotal: 586ms\tremaining: 669ms\n",
            "21:\tlearn: 0.0197445\ttotal: 612ms\tremaining: 640ms\n",
            "22:\tlearn: 0.0185256\ttotal: 638ms\tremaining: 610ms\n",
            "23:\tlearn: 0.0174437\ttotal: 665ms\tremaining: 582ms\n",
            "24:\tlearn: 0.0156271\ttotal: 696ms\tremaining: 557ms\n",
            "25:\tlearn: 0.0137701\ttotal: 722ms\tremaining: 528ms\n",
            "26:\tlearn: 0.0130589\ttotal: 747ms\tremaining: 498ms\n",
            "27:\tlearn: 0.0121432\ttotal: 772ms\tremaining: 469ms\n",
            "28:\tlearn: 0.0114331\ttotal: 798ms\tremaining: 440ms\n",
            "29:\tlearn: 0.0107270\ttotal: 832ms\tremaining: 416ms\n",
            "30:\tlearn: 0.0103444\ttotal: 864ms\tremaining: 390ms\n",
            "31:\tlearn: 0.0095450\ttotal: 889ms\tremaining: 361ms\n",
            "32:\tlearn: 0.0085837\ttotal: 919ms\tremaining: 334ms\n",
            "33:\tlearn: 0.0082775\ttotal: 945ms\tremaining: 306ms\n",
            "34:\tlearn: 0.0078921\ttotal: 970ms\tremaining: 277ms\n",
            "35:\tlearn: 0.0074147\ttotal: 997ms\tremaining: 249ms\n",
            "36:\tlearn: 0.0069458\ttotal: 1.03s\tremaining: 222ms\n",
            "37:\tlearn: 0.0066799\ttotal: 1.05s\tremaining: 194ms\n",
            "38:\tlearn: 0.0064325\ttotal: 1.08s\tremaining: 166ms\n",
            "39:\tlearn: 0.0060543\ttotal: 1.1s\tremaining: 138ms\n",
            "40:\tlearn: 0.0058299\ttotal: 1.14s\tremaining: 111ms\n",
            "41:\tlearn: 0.0057171\ttotal: 1.16s\tremaining: 82.9ms\n",
            "42:\tlearn: 0.0053976\ttotal: 1.19s\tremaining: 55.1ms\n",
            "43:\tlearn: 0.0053170\ttotal: 1.21s\tremaining: 27.5ms\n",
            "44:\tlearn: 0.0050028\ttotal: 1.24s\tremaining: 0us\n",
            "0:\tlearn: 0.3749937\ttotal: 34.8ms\tremaining: 1.53s\n",
            "1:\tlearn: 0.2596487\ttotal: 65.6ms\tremaining: 1.41s\n",
            "2:\tlearn: 0.1849278\ttotal: 101ms\tremaining: 1.42s\n",
            "3:\tlearn: 0.1529191\ttotal: 129ms\tremaining: 1.32s\n",
            "4:\tlearn: 0.1269714\ttotal: 154ms\tremaining: 1.23s\n",
            "5:\tlearn: 0.1065282\ttotal: 180ms\tremaining: 1.17s\n",
            "6:\tlearn: 0.0857851\ttotal: 206ms\tremaining: 1.12s\n",
            "7:\tlearn: 0.0758588\ttotal: 234ms\tremaining: 1.08s\n",
            "8:\tlearn: 0.0632858\ttotal: 276ms\tremaining: 1.1s\n",
            "9:\tlearn: 0.0566718\ttotal: 304ms\tremaining: 1.06s\n",
            "10:\tlearn: 0.0516592\ttotal: 334ms\tremaining: 1.03s\n",
            "11:\tlearn: 0.0440674\ttotal: 359ms\tremaining: 988ms\n",
            "12:\tlearn: 0.0409414\ttotal: 386ms\tremaining: 951ms\n",
            "13:\tlearn: 0.0380706\ttotal: 411ms\tremaining: 911ms\n",
            "14:\tlearn: 0.0328979\ttotal: 438ms\tremaining: 877ms\n",
            "15:\tlearn: 0.0307418\ttotal: 464ms\tremaining: 841ms\n",
            "16:\tlearn: 0.0283791\ttotal: 492ms\tremaining: 811ms\n",
            "17:\tlearn: 0.0259793\ttotal: 518ms\tremaining: 777ms\n",
            "18:\tlearn: 0.0248275\ttotal: 544ms\tremaining: 744ms\n",
            "19:\tlearn: 0.0227878\ttotal: 571ms\tremaining: 714ms\n",
            "20:\tlearn: 0.0215205\ttotal: 595ms\tremaining: 680ms\n",
            "21:\tlearn: 0.0194821\ttotal: 620ms\tremaining: 648ms\n",
            "22:\tlearn: 0.0187538\ttotal: 652ms\tremaining: 623ms\n",
            "23:\tlearn: 0.0171480\ttotal: 677ms\tremaining: 593ms\n",
            "24:\tlearn: 0.0163215\ttotal: 707ms\tremaining: 566ms\n",
            "25:\tlearn: 0.0152537\ttotal: 736ms\tremaining: 538ms\n",
            "26:\tlearn: 0.0136171\ttotal: 763ms\tremaining: 508ms\n",
            "27:\tlearn: 0.0120939\ttotal: 788ms\tremaining: 479ms\n",
            "28:\tlearn: 0.0110809\ttotal: 818ms\tremaining: 451ms\n",
            "29:\tlearn: 0.0105391\ttotal: 844ms\tremaining: 422ms\n",
            "30:\tlearn: 0.0102767\ttotal: 880ms\tremaining: 397ms\n",
            "31:\tlearn: 0.0095865\ttotal: 907ms\tremaining: 368ms\n",
            "32:\tlearn: 0.0085731\ttotal: 934ms\tremaining: 340ms\n",
            "33:\tlearn: 0.0080481\ttotal: 960ms\tremaining: 311ms\n",
            "34:\tlearn: 0.0077077\ttotal: 985ms\tremaining: 281ms\n",
            "35:\tlearn: 0.0072827\ttotal: 1.01s\tremaining: 252ms\n",
            "36:\tlearn: 0.0068409\ttotal: 1.03s\tremaining: 224ms\n",
            "37:\tlearn: 0.0065636\ttotal: 1.06s\tremaining: 196ms\n",
            "38:\tlearn: 0.0063270\ttotal: 1.09s\tremaining: 168ms\n",
            "39:\tlearn: 0.0061729\ttotal: 1.12s\tremaining: 140ms\n",
            "40:\tlearn: 0.0056186\ttotal: 1.14s\tremaining: 112ms\n",
            "41:\tlearn: 0.0053949\ttotal: 1.17s\tremaining: 83.6ms\n",
            "42:\tlearn: 0.0051815\ttotal: 1.2s\tremaining: 55.8ms\n",
            "43:\tlearn: 0.0049513\ttotal: 1.23s\tremaining: 27.9ms\n",
            "44:\tlearn: 0.0046655\ttotal: 1.27s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14280\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.932039  0.468994   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.925566  0.389792   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.911003  0.000000   \n",
            "3                             KNeighborsClassifier()  0.922330  0.342453   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.911003  0.000000   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.948220  0.660661   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.911003  0.000000   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.911003  0.000000   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.911003  0.000000   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.360595   1.000000  0.236364  0.382353     1.000000     0.236364  \n",
            "1  0.299699   0.846154  0.200000  0.323529     0.996448     0.200000  \n",
            "2  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n",
            "3  0.209929   1.000000  0.127273  0.225806     1.000000     0.127273  \n",
            "4  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n",
            "5  0.658245   0.744681  0.636364  0.686275     0.978686     0.636364  \n",
            "6  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n",
            "7  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n",
            "8  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AAC**"
      ],
      "metadata": {
        "id": "A2voa3EakKVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "GA9NsInzkoPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "UJnLG7MQkMQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZctZMbykZhs",
        "outputId": "69bd8b1e-bfd7-4a35-acce-6f2c44aacc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.974919  0.837301   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.942557  0.599535   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932443  0.479668   \n",
            "3                             KNeighborsClassifier()  0.948220  0.639243   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907265   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.956311  0.715873   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987460  0.923781   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989887  0.937785   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990291  0.939987   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.830019   0.959770  0.752252  0.843434     0.996889     0.752252  \n",
            "1  0.584524   0.773973  0.509009  0.614130     0.985333     0.509009  \n",
            "2  0.378633   0.982456  0.252252  0.401434     0.999556     0.252252  \n",
            "3  0.620014   0.835714  0.527027  0.646409     0.989778     0.527027  \n",
            "4  0.907125   0.930233  0.900901  0.915332     0.993333     0.900901  \n",
            "5  0.712944   0.803191  0.680180  0.736585     0.983556     0.680180  \n",
            "6  0.923756   0.924444  0.936937  0.930649     0.992444     0.936937  \n",
            "7  0.937759   0.949772  0.936937  0.943311     0.995111     0.936937  \n",
            "8  0.939880   0.958333  0.932432  0.945205     0.996000     0.932432  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "ylZ8Hle0kuYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "vHqHB7DVkwpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "8mQJcOv_k4Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNz9FQVZk47M",
        "outputId": "5d081ec7-00dd-4189-b3bd-e13a7771c714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.988999  0.978218   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.861473  0.722915   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.876066  0.756998   \n",
            "3                             KNeighborsClassifier()  0.954198  0.912303   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989448  0.979097   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.914459  0.829004   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991917  0.983964   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989897  0.979978   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996857  0.993713   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.978000   0.978676  0.999546  0.989001     0.978667     0.999546  \n",
            "1  0.722894   0.862826  0.856171  0.859485     0.866667     0.856171  \n",
            "2  0.751807   0.924897  0.815789  0.866924     0.935111     0.815789  \n",
            "3  0.908474   0.915282  1.000000  0.955768     0.909333     1.000000  \n",
            "4  0.978898   0.979546  0.999546  0.989445     0.979556     0.999546  \n",
            "5  0.828924   0.907830  0.920599  0.914170     0.908444     0.920599  \n",
            "6  0.983836   0.983929  1.000000  0.991899     0.984000     1.000000  \n",
            "7  0.979795   0.980418  0.999546  0.989890     0.980444     0.999546  \n",
            "8  0.993713   0.996374  0.997278  0.996825     0.996444     0.997278  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "ReJ8WxHvk_Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "VmFEdp4ylB6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "5vh1IlOSlFS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqGYm-vElKkk",
        "outputId": "b911880b-ff13-40ec-993b-de59377fbd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.990444  0.980891   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953556  0.907671   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.974222  0.948482   \n",
            "3                             KNeighborsClassifier()  0.976000  0.952122   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988222  0.976449   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.976667  0.953349   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991778  0.983563   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.991778  0.983563   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988000  0.976139   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.980889   0.991537  0.989333  0.990434     0.991556     0.989333  \n",
            "1  0.907111   0.938171  0.971111  0.954357     0.936000     0.971111  \n",
            "2  0.948444   0.970044  0.978667  0.974336     0.969778     0.978667  \n",
            "3  0.952000   0.983740  0.968000  0.975806     0.984000     0.968000  \n",
            "4  0.976444   0.986708  0.989778  0.988241     0.986667     0.989778  \n",
            "5  0.953333   0.979437  0.973778  0.976599     0.979556     0.973778  \n",
            "6  0.983556   0.989819  0.993778  0.991794     0.989778     0.993778  \n",
            "7  0.983556   0.989819  0.993778  0.991794     0.989778     0.993778  \n",
            "8  0.976000   0.996383  0.979556  0.987898     0.996444     0.979556  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "1hGEPWadlQEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "4XGA6J5BlTe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "PS2troZolWP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd-5r-fSlb4U",
        "outputId": "8c4204fd-e5ba-4916-9ab3-0940a680cb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.985556  0.971123   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.901333  0.803078   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.898667  0.802063   \n",
            "3                             KNeighborsClassifier()  0.958000  0.919249   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989333  0.978754   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.919556  0.839138   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.990667  0.981421   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988000  0.976111   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.995778  0.991560   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.971111   0.983193  0.988000  0.985591     0.983111     0.988000  \n",
            "1  0.802667   0.888889  0.917333  0.902887     0.885333     0.917333  \n",
            "2  0.797333   0.947159  0.844444  0.892857     0.952889     0.844444  \n",
            "3  0.916000   0.922509  1.000000  0.959693     0.916000     1.000000  \n",
            "4  0.978667   0.982895  0.996000  0.989404     0.982667     0.996000  \n",
            "5  0.839111   0.922939  0.915556  0.919232     0.923556     0.915556  \n",
            "6  0.981333   0.984211  0.997333  0.990728     0.984000     0.997333  \n",
            "7  0.976000   0.980736  0.995556  0.988090     0.980444     0.995556  \n",
            "8  0.991556   0.994240  0.997333  0.995784     0.994222     0.997333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "qCkhzQaIlhGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "H_LTHp1LlsBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "IPMp7JNhlu5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PqZvO01l1dM",
        "outputId": "8862e9e6-bd8b-4b8f-91f6-25b499f892e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.950450  0.900937   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.921171  0.843378   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.916667  0.835787   \n",
            "3                             KNeighborsClassifier()  0.826577  0.659616   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.954955  0.909910   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.934685  0.871930   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.943694  0.888913   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.959459  0.918956   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.961712  0.924559   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.900901   0.946429  0.954955  0.950673     0.945946     0.954955  \n",
            "1  0.842342   0.943128  0.896396  0.919169     0.945946     0.896396  \n",
            "2  0.833333   0.951220  0.878378  0.913349     0.954955     0.878378  \n",
            "3  0.653153   0.879581  0.756757  0.813559     0.896396     0.756757  \n",
            "4  0.909910   0.954955  0.954955  0.954955     0.954955     0.954955  \n",
            "5  0.869369   0.903766  0.972973  0.937093     0.896396     0.972973  \n",
            "6  0.887387   0.919149  0.972973  0.945295     0.914414     0.972973  \n",
            "7  0.918919   0.955357  0.963964  0.959641     0.954955     0.963964  \n",
            "8  0.923423   0.985782  0.936937  0.960739     0.986486     0.936937  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "n6YO25x0l8NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "roioSspYl-Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "51PEl5fAmATr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUCSXP3SmF2D",
        "outputId": "569cadb7-a73a-4ac4-f958-05d75834744d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.973706  0.828727   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.943366  0.604509   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932039  0.475177   \n",
            "3                             KNeighborsClassifier()  0.948220  0.639243   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907265   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.956311  0.715873   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987460  0.923781   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989887  0.937785   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990291  0.939987   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.818944   0.970060  0.729730  0.832905     0.997778     0.729730  \n",
            "1  0.588400   0.784722  0.509009  0.617486     0.986222     0.509009  \n",
            "2  0.372998   0.982143  0.247748  0.395683     0.999556     0.247748  \n",
            "3  0.620014   0.835714  0.527027  0.646409     0.989778     0.527027  \n",
            "4  0.907125   0.930233  0.900901  0.915332     0.993333     0.900901  \n",
            "5  0.712944   0.803191  0.680180  0.736585     0.983556     0.680180  \n",
            "6  0.923756   0.924444  0.936937  0.930649     0.992444     0.936937  \n",
            "7  0.937759   0.949772  0.936937  0.943311     0.995111     0.936937  \n",
            "8  0.939880   0.958333  0.932432  0.945205     0.996000     0.932432  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "5lhzV8jx3xXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Hr_HeLHM3zqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "ah6zRD6032W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18itG_Gp37yk",
        "outputId": "ac0097b3-e8e3-473f-8657-3838562730f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3224236\ttotal: 71.2ms\tremaining: 3.13s\n",
            "1:\tlearn: 0.2005744\ttotal: 90.9ms\tremaining: 1.95s\n",
            "2:\tlearn: 0.1585602\ttotal: 110ms\tremaining: 1.54s\n",
            "3:\tlearn: 0.1292872\ttotal: 130ms\tremaining: 1.33s\n",
            "4:\tlearn: 0.1160448\ttotal: 150ms\tremaining: 1.2s\n",
            "5:\tlearn: 0.1088562\ttotal: 171ms\tremaining: 1.11s\n",
            "6:\tlearn: 0.0999704\ttotal: 189ms\tremaining: 1.03s\n",
            "7:\tlearn: 0.0913168\ttotal: 209ms\tremaining: 965ms\n",
            "8:\tlearn: 0.0864968\ttotal: 229ms\tremaining: 915ms\n",
            "9:\tlearn: 0.0826496\ttotal: 248ms\tremaining: 870ms\n",
            "10:\tlearn: 0.0755345\ttotal: 265ms\tremaining: 820ms\n",
            "11:\tlearn: 0.0741817\ttotal: 282ms\tremaining: 774ms\n",
            "12:\tlearn: 0.0669797\ttotal: 299ms\tremaining: 737ms\n",
            "13:\tlearn: 0.0605790\ttotal: 316ms\tremaining: 700ms\n",
            "14:\tlearn: 0.0589727\ttotal: 335ms\tremaining: 670ms\n",
            "15:\tlearn: 0.0538223\ttotal: 354ms\tremaining: 642ms\n",
            "16:\tlearn: 0.0506963\ttotal: 373ms\tremaining: 614ms\n",
            "17:\tlearn: 0.0468650\ttotal: 389ms\tremaining: 583ms\n",
            "18:\tlearn: 0.0442445\ttotal: 399ms\tremaining: 547ms\n",
            "19:\tlearn: 0.0407114\ttotal: 410ms\tremaining: 512ms\n",
            "20:\tlearn: 0.0386843\ttotal: 420ms\tremaining: 480ms\n",
            "21:\tlearn: 0.0354401\ttotal: 430ms\tremaining: 450ms\n",
            "22:\tlearn: 0.0332778\ttotal: 441ms\tremaining: 422ms\n",
            "23:\tlearn: 0.0319502\ttotal: 451ms\tremaining: 395ms\n",
            "24:\tlearn: 0.0303744\ttotal: 470ms\tremaining: 376ms\n",
            "25:\tlearn: 0.0297999\ttotal: 480ms\tremaining: 351ms\n",
            "26:\tlearn: 0.0295665\ttotal: 490ms\tremaining: 327ms\n",
            "27:\tlearn: 0.0270919\ttotal: 500ms\tremaining: 304ms\n",
            "28:\tlearn: 0.0266253\ttotal: 514ms\tremaining: 284ms\n",
            "29:\tlearn: 0.0231946\ttotal: 527ms\tremaining: 263ms\n",
            "30:\tlearn: 0.0221542\ttotal: 538ms\tremaining: 243ms\n",
            "31:\tlearn: 0.0202798\ttotal: 549ms\tremaining: 223ms\n",
            "32:\tlearn: 0.0193609\ttotal: 562ms\tremaining: 204ms\n",
            "33:\tlearn: 0.0192036\ttotal: 589ms\tremaining: 191ms\n",
            "34:\tlearn: 0.0181418\ttotal: 607ms\tremaining: 173ms\n",
            "35:\tlearn: 0.0168129\ttotal: 627ms\tremaining: 157ms\n",
            "36:\tlearn: 0.0165657\ttotal: 647ms\tremaining: 140ms\n",
            "37:\tlearn: 0.0159177\ttotal: 661ms\tremaining: 122ms\n",
            "38:\tlearn: 0.0158193\ttotal: 682ms\tremaining: 105ms\n",
            "39:\tlearn: 0.0149772\ttotal: 693ms\tremaining: 86.7ms\n",
            "40:\tlearn: 0.0149085\ttotal: 705ms\tremaining: 68.8ms\n",
            "41:\tlearn: 0.0143957\ttotal: 715ms\tremaining: 51.1ms\n",
            "42:\tlearn: 0.0139628\ttotal: 726ms\tremaining: 33.7ms\n",
            "43:\tlearn: 0.0135956\ttotal: 736ms\tremaining: 16.7ms\n",
            "44:\tlearn: 0.0129958\ttotal: 747ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3470\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3224236\ttotal: 11.7ms\tremaining: 515ms\n",
            "1:\tlearn: 0.2005744\ttotal: 20.7ms\tremaining: 445ms\n",
            "2:\tlearn: 0.1585602\ttotal: 29.3ms\tremaining: 410ms\n",
            "3:\tlearn: 0.1292872\ttotal: 38.2ms\tremaining: 392ms\n",
            "4:\tlearn: 0.1160448\ttotal: 55.5ms\tremaining: 444ms\n",
            "5:\tlearn: 0.1088562\ttotal: 66.6ms\tremaining: 433ms\n",
            "6:\tlearn: 0.0999704\ttotal: 75ms\tremaining: 407ms\n",
            "7:\tlearn: 0.0913168\ttotal: 83.2ms\tremaining: 385ms\n",
            "8:\tlearn: 0.0864968\ttotal: 94.5ms\tremaining: 378ms\n",
            "9:\tlearn: 0.0826496\ttotal: 104ms\tremaining: 365ms\n",
            "10:\tlearn: 0.0755345\ttotal: 112ms\tremaining: 348ms\n",
            "11:\tlearn: 0.0741817\ttotal: 118ms\tremaining: 324ms\n",
            "12:\tlearn: 0.0669797\ttotal: 126ms\tremaining: 311ms\n",
            "13:\tlearn: 0.0605790\ttotal: 135ms\tremaining: 298ms\n",
            "14:\tlearn: 0.0589727\ttotal: 143ms\tremaining: 286ms\n",
            "15:\tlearn: 0.0538223\ttotal: 152ms\tremaining: 275ms\n",
            "16:\tlearn: 0.0506963\ttotal: 160ms\tremaining: 264ms\n",
            "17:\tlearn: 0.0468650\ttotal: 168ms\tremaining: 253ms\n",
            "18:\tlearn: 0.0442445\ttotal: 177ms\tremaining: 242ms\n",
            "19:\tlearn: 0.0407114\ttotal: 185ms\tremaining: 232ms\n",
            "20:\tlearn: 0.0386843\ttotal: 193ms\tremaining: 221ms\n",
            "21:\tlearn: 0.0354401\ttotal: 202ms\tremaining: 211ms\n",
            "22:\tlearn: 0.0332778\ttotal: 216ms\tremaining: 206ms\n",
            "23:\tlearn: 0.0319502\ttotal: 225ms\tremaining: 196ms\n",
            "24:\tlearn: 0.0303744\ttotal: 233ms\tremaining: 187ms\n",
            "25:\tlearn: 0.0297999\ttotal: 242ms\tremaining: 177ms\n",
            "26:\tlearn: 0.0295665\ttotal: 250ms\tremaining: 167ms\n",
            "27:\tlearn: 0.0270919\ttotal: 259ms\tremaining: 157ms\n",
            "28:\tlearn: 0.0266253\ttotal: 268ms\tremaining: 148ms\n",
            "29:\tlearn: 0.0231946\ttotal: 276ms\tremaining: 138ms\n",
            "30:\tlearn: 0.0221542\ttotal: 285ms\tremaining: 129ms\n",
            "31:\tlearn: 0.0202798\ttotal: 294ms\tremaining: 119ms\n",
            "32:\tlearn: 0.0193609\ttotal: 302ms\tremaining: 110ms\n",
            "33:\tlearn: 0.0192036\ttotal: 311ms\tremaining: 101ms\n",
            "34:\tlearn: 0.0181418\ttotal: 319ms\tremaining: 91.3ms\n",
            "35:\tlearn: 0.0168129\ttotal: 328ms\tremaining: 81.9ms\n",
            "36:\tlearn: 0.0165657\ttotal: 336ms\tremaining: 72.6ms\n",
            "37:\tlearn: 0.0159177\ttotal: 345ms\tremaining: 63.5ms\n",
            "38:\tlearn: 0.0158193\ttotal: 353ms\tremaining: 54.3ms\n",
            "39:\tlearn: 0.0149772\ttotal: 362ms\tremaining: 45.2ms\n",
            "40:\tlearn: 0.0149085\ttotal: 370ms\tremaining: 36.1ms\n",
            "41:\tlearn: 0.0143957\ttotal: 378ms\tremaining: 27ms\n",
            "42:\tlearn: 0.0139628\ttotal: 387ms\tremaining: 18ms\n",
            "43:\tlearn: 0.0135956\ttotal: 395ms\tremaining: 8.98ms\n",
            "44:\tlearn: 0.0129958\ttotal: 404ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3470\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3388483\ttotal: 8.72ms\tremaining: 384ms\n",
            "1:\tlearn: 0.2082313\ttotal: 17.1ms\tremaining: 367ms\n",
            "2:\tlearn: 0.1504447\ttotal: 25.4ms\tremaining: 356ms\n",
            "3:\tlearn: 0.1222435\ttotal: 41.6ms\tremaining: 427ms\n",
            "4:\tlearn: 0.0993643\ttotal: 50.8ms\tremaining: 407ms\n",
            "5:\tlearn: 0.0843715\ttotal: 58.6ms\tremaining: 381ms\n",
            "6:\tlearn: 0.0800924\ttotal: 66.5ms\tremaining: 361ms\n",
            "7:\tlearn: 0.0762622\ttotal: 74.1ms\tremaining: 343ms\n",
            "8:\tlearn: 0.0694884\ttotal: 82ms\tremaining: 328ms\n",
            "9:\tlearn: 0.0645626\ttotal: 90ms\tremaining: 315ms\n",
            "10:\tlearn: 0.0579569\ttotal: 97.7ms\tremaining: 302ms\n",
            "11:\tlearn: 0.0557205\ttotal: 105ms\tremaining: 290ms\n",
            "12:\tlearn: 0.0533565\ttotal: 113ms\tremaining: 278ms\n",
            "13:\tlearn: 0.0489852\ttotal: 121ms\tremaining: 267ms\n",
            "14:\tlearn: 0.0456717\ttotal: 129ms\tremaining: 257ms\n",
            "15:\tlearn: 0.0445920\ttotal: 136ms\tremaining: 247ms\n",
            "16:\tlearn: 0.0427239\ttotal: 144ms\tremaining: 237ms\n",
            "17:\tlearn: 0.0400293\ttotal: 151ms\tremaining: 227ms\n",
            "18:\tlearn: 0.0382715\ttotal: 159ms\tremaining: 218ms\n",
            "19:\tlearn: 0.0374802\ttotal: 167ms\tremaining: 208ms\n",
            "20:\tlearn: 0.0338571\ttotal: 174ms\tremaining: 199ms\n",
            "21:\tlearn: 0.0314749\ttotal: 182ms\tremaining: 190ms\n",
            "22:\tlearn: 0.0301509\ttotal: 190ms\tremaining: 181ms\n",
            "23:\tlearn: 0.0289204\ttotal: 198ms\tremaining: 173ms\n",
            "24:\tlearn: 0.0275123\ttotal: 206ms\tremaining: 165ms\n",
            "25:\tlearn: 0.0272565\ttotal: 219ms\tremaining: 160ms\n",
            "26:\tlearn: 0.0268189\ttotal: 226ms\tremaining: 151ms\n",
            "27:\tlearn: 0.0265513\ttotal: 233ms\tremaining: 142ms\n",
            "28:\tlearn: 0.0257052\ttotal: 241ms\tremaining: 133ms\n",
            "29:\tlearn: 0.0234097\ttotal: 248ms\tremaining: 124ms\n",
            "30:\tlearn: 0.0217321\ttotal: 256ms\tremaining: 116ms\n",
            "31:\tlearn: 0.0216260\ttotal: 264ms\tremaining: 107ms\n",
            "32:\tlearn: 0.0201253\ttotal: 272ms\tremaining: 98.8ms\n",
            "33:\tlearn: 0.0197981\ttotal: 280ms\tremaining: 90.4ms\n",
            "34:\tlearn: 0.0184434\ttotal: 287ms\tremaining: 82.1ms\n",
            "35:\tlearn: 0.0177906\ttotal: 295ms\tremaining: 73.8ms\n",
            "36:\tlearn: 0.0166041\ttotal: 303ms\tremaining: 65.6ms\n",
            "37:\tlearn: 0.0164534\ttotal: 311ms\tremaining: 57.3ms\n",
            "38:\tlearn: 0.0163499\ttotal: 322ms\tremaining: 49.5ms\n",
            "39:\tlearn: 0.0159457\ttotal: 334ms\tremaining: 41.8ms\n",
            "40:\tlearn: 0.0158426\ttotal: 344ms\tremaining: 33.6ms\n",
            "41:\tlearn: 0.0156444\ttotal: 352ms\tremaining: 25.1ms\n",
            "42:\tlearn: 0.0150768\ttotal: 359ms\tremaining: 16.7ms\n",
            "43:\tlearn: 0.0148371\ttotal: 367ms\tremaining: 8.33ms\n",
            "44:\tlearn: 0.0142509\ttotal: 374ms\tremaining: 0us\n",
            "0:\tlearn: 0.3426287\ttotal: 12.6ms\tremaining: 555ms\n",
            "1:\tlearn: 0.2049162\ttotal: 21ms\tremaining: 452ms\n",
            "2:\tlearn: 0.1500935\ttotal: 29.2ms\tremaining: 409ms\n",
            "3:\tlearn: 0.1246548\ttotal: 37.3ms\tremaining: 383ms\n",
            "4:\tlearn: 0.1180691\ttotal: 45.3ms\tremaining: 362ms\n",
            "5:\tlearn: 0.1046524\ttotal: 53.3ms\tremaining: 346ms\n",
            "6:\tlearn: 0.0994616\ttotal: 60.9ms\tremaining: 331ms\n",
            "7:\tlearn: 0.0896329\ttotal: 68.7ms\tremaining: 318ms\n",
            "8:\tlearn: 0.0860106\ttotal: 76.6ms\tremaining: 306ms\n",
            "9:\tlearn: 0.0804533\ttotal: 84.4ms\tremaining: 295ms\n",
            "10:\tlearn: 0.0771256\ttotal: 94ms\tremaining: 291ms\n",
            "11:\tlearn: 0.0718392\ttotal: 102ms\tremaining: 280ms\n",
            "12:\tlearn: 0.0686428\ttotal: 109ms\tremaining: 269ms\n",
            "13:\tlearn: 0.0641499\ttotal: 117ms\tremaining: 259ms\n",
            "14:\tlearn: 0.0561381\ttotal: 124ms\tremaining: 249ms\n",
            "15:\tlearn: 0.0540872\ttotal: 135ms\tremaining: 245ms\n",
            "16:\tlearn: 0.0477171\ttotal: 143ms\tremaining: 235ms\n",
            "17:\tlearn: 0.0447360\ttotal: 151ms\tremaining: 227ms\n",
            "18:\tlearn: 0.0425428\ttotal: 159ms\tremaining: 217ms\n",
            "19:\tlearn: 0.0421695\ttotal: 167ms\tremaining: 208ms\n",
            "20:\tlearn: 0.0390140\ttotal: 175ms\tremaining: 200ms\n",
            "21:\tlearn: 0.0384148\ttotal: 182ms\tremaining: 191ms\n",
            "22:\tlearn: 0.0381429\ttotal: 190ms\tremaining: 182ms\n",
            "23:\tlearn: 0.0355570\ttotal: 198ms\tremaining: 174ms\n",
            "24:\tlearn: 0.0353879\ttotal: 206ms\tremaining: 165ms\n",
            "25:\tlearn: 0.0338939\ttotal: 218ms\tremaining: 159ms\n",
            "26:\tlearn: 0.0329696\ttotal: 226ms\tremaining: 151ms\n",
            "27:\tlearn: 0.0321842\ttotal: 242ms\tremaining: 147ms\n",
            "28:\tlearn: 0.0309503\ttotal: 250ms\tremaining: 138ms\n",
            "29:\tlearn: 0.0301467\ttotal: 258ms\tremaining: 129ms\n",
            "30:\tlearn: 0.0286400\ttotal: 266ms\tremaining: 120ms\n",
            "31:\tlearn: 0.0272251\ttotal: 274ms\tremaining: 111ms\n",
            "32:\tlearn: 0.0254870\ttotal: 282ms\tremaining: 103ms\n",
            "33:\tlearn: 0.0235230\ttotal: 290ms\tremaining: 93.9ms\n",
            "34:\tlearn: 0.0229044\ttotal: 298ms\tremaining: 85.1ms\n",
            "35:\tlearn: 0.0227764\ttotal: 306ms\tremaining: 76.4ms\n",
            "36:\tlearn: 0.0208931\ttotal: 321ms\tremaining: 69.5ms\n",
            "37:\tlearn: 0.0200993\ttotal: 333ms\tremaining: 61.4ms\n",
            "38:\tlearn: 0.0196729\ttotal: 341ms\tremaining: 52.4ms\n",
            "39:\tlearn: 0.0189460\ttotal: 349ms\tremaining: 43.6ms\n",
            "40:\tlearn: 0.0186589\ttotal: 356ms\tremaining: 34.7ms\n",
            "41:\tlearn: 0.0180212\ttotal: 364ms\tremaining: 26ms\n",
            "42:\tlearn: 0.0167792\ttotal: 371ms\tremaining: 17.3ms\n",
            "43:\tlearn: 0.0161972\ttotal: 379ms\tremaining: 8.61ms\n",
            "44:\tlearn: 0.0155338\ttotal: 386ms\tremaining: 0us\n",
            "0:\tlearn: 0.3372412\ttotal: 8.8ms\tremaining: 387ms\n",
            "1:\tlearn: 0.2038222\ttotal: 17.2ms\tremaining: 370ms\n",
            "2:\tlearn: 0.1530356\ttotal: 25.6ms\tremaining: 358ms\n",
            "3:\tlearn: 0.1346677\ttotal: 34ms\tremaining: 349ms\n",
            "4:\tlearn: 0.1246585\ttotal: 42.4ms\tremaining: 339ms\n",
            "5:\tlearn: 0.1065994\ttotal: 50.8ms\tremaining: 330ms\n",
            "6:\tlearn: 0.0940864\ttotal: 60.7ms\tremaining: 330ms\n",
            "7:\tlearn: 0.0866517\ttotal: 68.7ms\tremaining: 318ms\n",
            "8:\tlearn: 0.0768506\ttotal: 76.6ms\tremaining: 306ms\n",
            "9:\tlearn: 0.0744578\ttotal: 84.5ms\tremaining: 296ms\n",
            "10:\tlearn: 0.0671473\ttotal: 92.5ms\tremaining: 286ms\n",
            "11:\tlearn: 0.0631646\ttotal: 101ms\tremaining: 277ms\n",
            "12:\tlearn: 0.0601308\ttotal: 109ms\tremaining: 268ms\n",
            "13:\tlearn: 0.0541906\ttotal: 117ms\tremaining: 259ms\n",
            "14:\tlearn: 0.0497071\ttotal: 125ms\tremaining: 249ms\n",
            "15:\tlearn: 0.0470924\ttotal: 133ms\tremaining: 240ms\n",
            "16:\tlearn: 0.0426421\ttotal: 141ms\tremaining: 231ms\n",
            "17:\tlearn: 0.0415762\ttotal: 149ms\tremaining: 223ms\n",
            "18:\tlearn: 0.0392238\ttotal: 157ms\tremaining: 214ms\n",
            "19:\tlearn: 0.0358416\ttotal: 164ms\tremaining: 206ms\n",
            "20:\tlearn: 0.0332393\ttotal: 172ms\tremaining: 197ms\n",
            "21:\tlearn: 0.0327878\ttotal: 180ms\tremaining: 188ms\n",
            "22:\tlearn: 0.0314991\ttotal: 190ms\tremaining: 182ms\n",
            "23:\tlearn: 0.0304088\ttotal: 199ms\tremaining: 174ms\n",
            "24:\tlearn: 0.0281903\ttotal: 211ms\tremaining: 169ms\n",
            "25:\tlearn: 0.0269268\ttotal: 223ms\tremaining: 163ms\n",
            "26:\tlearn: 0.0268500\ttotal: 236ms\tremaining: 157ms\n",
            "27:\tlearn: 0.0257396\ttotal: 244ms\tremaining: 148ms\n",
            "28:\tlearn: 0.0247724\ttotal: 252ms\tremaining: 139ms\n",
            "29:\tlearn: 0.0240014\ttotal: 260ms\tremaining: 130ms\n",
            "30:\tlearn: 0.0234088\ttotal: 268ms\tremaining: 121ms\n",
            "31:\tlearn: 0.0218608\ttotal: 276ms\tremaining: 112ms\n",
            "32:\tlearn: 0.0213158\ttotal: 284ms\tremaining: 103ms\n",
            "33:\tlearn: 0.0199996\ttotal: 292ms\tremaining: 94.6ms\n",
            "34:\tlearn: 0.0197280\ttotal: 300ms\tremaining: 85.8ms\n",
            "35:\tlearn: 0.0183391\ttotal: 308ms\tremaining: 77.1ms\n",
            "36:\tlearn: 0.0180860\ttotal: 316ms\tremaining: 68.4ms\n",
            "37:\tlearn: 0.0177820\ttotal: 324ms\tremaining: 59.7ms\n",
            "38:\tlearn: 0.0174336\ttotal: 332ms\tremaining: 51.1ms\n",
            "39:\tlearn: 0.0169858\ttotal: 340ms\tremaining: 42.5ms\n",
            "40:\tlearn: 0.0169445\ttotal: 348ms\tremaining: 33.9ms\n",
            "41:\tlearn: 0.0167160\ttotal: 356ms\tremaining: 25.4ms\n",
            "42:\tlearn: 0.0152589\ttotal: 364ms\tremaining: 16.9ms\n",
            "43:\tlearn: 0.0147968\ttotal: 372ms\tremaining: 8.46ms\n",
            "44:\tlearn: 0.0140509\ttotal: 380ms\tremaining: 0us\n",
            "0:\tlearn: 0.3402337\ttotal: 11.3ms\tremaining: 499ms\n",
            "1:\tlearn: 0.2063704\ttotal: 19.9ms\tremaining: 428ms\n",
            "2:\tlearn: 0.1554320\ttotal: 28.3ms\tremaining: 396ms\n",
            "3:\tlearn: 0.1229654\ttotal: 36.6ms\tremaining: 375ms\n",
            "4:\tlearn: 0.1135994\ttotal: 44.5ms\tremaining: 356ms\n",
            "5:\tlearn: 0.1036457\ttotal: 53.2ms\tremaining: 346ms\n",
            "6:\tlearn: 0.0980659\ttotal: 61.2ms\tremaining: 332ms\n",
            "7:\tlearn: 0.0838168\ttotal: 69.2ms\tremaining: 320ms\n",
            "8:\tlearn: 0.0720267\ttotal: 77.4ms\tremaining: 309ms\n",
            "9:\tlearn: 0.0685977\ttotal: 85.4ms\tremaining: 299ms\n",
            "10:\tlearn: 0.0640804\ttotal: 93.7ms\tremaining: 290ms\n",
            "11:\tlearn: 0.0622709\ttotal: 102ms\tremaining: 281ms\n",
            "12:\tlearn: 0.0542931\ttotal: 110ms\tremaining: 272ms\n",
            "13:\tlearn: 0.0509066\ttotal: 118ms\tremaining: 262ms\n",
            "14:\tlearn: 0.0494153\ttotal: 126ms\tremaining: 252ms\n",
            "15:\tlearn: 0.0457865\ttotal: 134ms\tremaining: 243ms\n",
            "16:\tlearn: 0.0436968\ttotal: 144ms\tremaining: 238ms\n",
            "17:\tlearn: 0.0394935\ttotal: 152ms\tremaining: 229ms\n",
            "18:\tlearn: 0.0382694\ttotal: 160ms\tremaining: 220ms\n",
            "19:\tlearn: 0.0378485\ttotal: 169ms\tremaining: 211ms\n",
            "20:\tlearn: 0.0347098\ttotal: 177ms\tremaining: 202ms\n",
            "21:\tlearn: 0.0314099\ttotal: 187ms\tremaining: 196ms\n",
            "22:\tlearn: 0.0300513\ttotal: 235ms\tremaining: 225ms\n",
            "23:\tlearn: 0.0287374\ttotal: 258ms\tremaining: 226ms\n",
            "24:\tlearn: 0.0273364\ttotal: 289ms\tremaining: 231ms\n",
            "25:\tlearn: 0.0269714\ttotal: 315ms\tremaining: 230ms\n",
            "26:\tlearn: 0.0251185\ttotal: 338ms\tremaining: 225ms\n",
            "27:\tlearn: 0.0241374\ttotal: 374ms\tremaining: 227ms\n",
            "28:\tlearn: 0.0232535\ttotal: 402ms\tremaining: 222ms\n",
            "29:\tlearn: 0.0229686\ttotal: 439ms\tremaining: 219ms\n",
            "30:\tlearn: 0.0222496\ttotal: 462ms\tremaining: 209ms\n",
            "31:\tlearn: 0.0210694\ttotal: 515ms\tremaining: 209ms\n",
            "32:\tlearn: 0.0204929\ttotal: 541ms\tremaining: 197ms\n",
            "33:\tlearn: 0.0194461\ttotal: 584ms\tremaining: 189ms\n",
            "34:\tlearn: 0.0179687\ttotal: 603ms\tremaining: 172ms\n",
            "35:\tlearn: 0.0175680\ttotal: 645ms\tremaining: 161ms\n",
            "36:\tlearn: 0.0169747\ttotal: 666ms\tremaining: 144ms\n",
            "37:\tlearn: 0.0166781\ttotal: 694ms\tremaining: 128ms\n",
            "38:\tlearn: 0.0149895\ttotal: 712ms\tremaining: 109ms\n",
            "39:\tlearn: 0.0144416\ttotal: 735ms\tremaining: 91.9ms\n",
            "40:\tlearn: 0.0138832\ttotal: 760ms\tremaining: 74.2ms\n",
            "41:\tlearn: 0.0135563\ttotal: 783ms\tremaining: 55.9ms\n",
            "42:\tlearn: 0.0126458\ttotal: 810ms\tremaining: 37.7ms\n",
            "43:\tlearn: 0.0124428\ttotal: 832ms\tremaining: 18.9ms\n",
            "44:\tlearn: 0.0121883\ttotal: 856ms\tremaining: 0us\n",
            "0:\tlearn: 0.3645034\ttotal: 8.53ms\tremaining: 375ms\n",
            "1:\tlearn: 0.2149163\ttotal: 17ms\tremaining: 365ms\n",
            "2:\tlearn: 0.1597257\ttotal: 27.4ms\tremaining: 384ms\n",
            "3:\tlearn: 0.1324753\ttotal: 35.5ms\tremaining: 364ms\n",
            "4:\tlearn: 0.1130232\ttotal: 43.7ms\tremaining: 349ms\n",
            "5:\tlearn: 0.1027825\ttotal: 52.8ms\tremaining: 343ms\n",
            "6:\tlearn: 0.1001922\ttotal: 66.5ms\tremaining: 361ms\n",
            "7:\tlearn: 0.0929439\ttotal: 74.9ms\tremaining: 346ms\n",
            "8:\tlearn: 0.0846313\ttotal: 83ms\tremaining: 332ms\n",
            "9:\tlearn: 0.0791542\ttotal: 91.3ms\tremaining: 320ms\n",
            "10:\tlearn: 0.0727934\ttotal: 99.6ms\tremaining: 308ms\n",
            "11:\tlearn: 0.0698571\ttotal: 108ms\tremaining: 297ms\n",
            "12:\tlearn: 0.0643986\ttotal: 116ms\tremaining: 286ms\n",
            "13:\tlearn: 0.0562107\ttotal: 125ms\tremaining: 278ms\n",
            "14:\tlearn: 0.0547635\ttotal: 133ms\tremaining: 267ms\n",
            "15:\tlearn: 0.0514184\ttotal: 141ms\tremaining: 256ms\n",
            "16:\tlearn: 0.0498181\ttotal: 149ms\tremaining: 246ms\n",
            "17:\tlearn: 0.0472743\ttotal: 158ms\tremaining: 237ms\n",
            "18:\tlearn: 0.0463800\ttotal: 166ms\tremaining: 226ms\n",
            "19:\tlearn: 0.0441722\ttotal: 178ms\tremaining: 222ms\n",
            "20:\tlearn: 0.0408967\ttotal: 185ms\tremaining: 212ms\n",
            "21:\tlearn: 0.0392339\ttotal: 194ms\tremaining: 203ms\n",
            "22:\tlearn: 0.0365532\ttotal: 202ms\tremaining: 193ms\n",
            "23:\tlearn: 0.0360731\ttotal: 210ms\tremaining: 184ms\n",
            "24:\tlearn: 0.0352135\ttotal: 218ms\tremaining: 174ms\n",
            "25:\tlearn: 0.0334169\ttotal: 226ms\tremaining: 165ms\n",
            "26:\tlearn: 0.0295922\ttotal: 234ms\tremaining: 156ms\n",
            "27:\tlearn: 0.0286190\ttotal: 242ms\tremaining: 147ms\n",
            "28:\tlearn: 0.0274616\ttotal: 250ms\tremaining: 138ms\n",
            "29:\tlearn: 0.0269548\ttotal: 259ms\tremaining: 129ms\n",
            "30:\tlearn: 0.0253705\ttotal: 267ms\tremaining: 121ms\n",
            "31:\tlearn: 0.0246537\ttotal: 276ms\tremaining: 112ms\n",
            "32:\tlearn: 0.0232729\ttotal: 284ms\tremaining: 103ms\n",
            "33:\tlearn: 0.0226467\ttotal: 292ms\tremaining: 94.4ms\n",
            "34:\tlearn: 0.0215394\ttotal: 300ms\tremaining: 85.7ms\n",
            "35:\tlearn: 0.0203271\ttotal: 308ms\tremaining: 77ms\n",
            "36:\tlearn: 0.0200802\ttotal: 316ms\tremaining: 68.3ms\n",
            "37:\tlearn: 0.0199800\ttotal: 324ms\tremaining: 59.7ms\n",
            "38:\tlearn: 0.0184815\ttotal: 333ms\tremaining: 51.2ms\n",
            "39:\tlearn: 0.0178553\ttotal: 341ms\tremaining: 42.6ms\n",
            "40:\tlearn: 0.0170708\ttotal: 349ms\tremaining: 34ms\n",
            "41:\tlearn: 0.0161005\ttotal: 357ms\tremaining: 25.5ms\n",
            "42:\tlearn: 0.0154080\ttotal: 366ms\tremaining: 17ms\n",
            "43:\tlearn: 0.0153236\ttotal: 374ms\tremaining: 8.5ms\n",
            "44:\tlearn: 0.0144839\ttotal: 385ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2849\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2905\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3056\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3318\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.964401  0.763941   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.951456  0.683612   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.938511  0.548700   \n",
            "3                             KNeighborsClassifier()  0.956311  0.703040   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.970874  0.810871   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.951456  0.683612   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.967638  0.787554   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.967638  0.787554   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.967638  0.787887   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.747455   0.947368  0.642857  0.765957     0.996441     0.642857  \n",
            "1  0.679704   0.782609  0.642857  0.705882     0.982206     0.642857  \n",
            "2  0.462805   1.000000  0.321429  0.486486     1.000000     0.321429  \n",
            "3  0.681066   0.914286  0.571429  0.703297     0.994662     0.571429  \n",
            "4  0.793372   1.000000  0.678571  0.808511     1.000000     0.678571  \n",
            "5  0.679704   0.782609  0.642857  0.705882     0.982206     0.642857  \n",
            "6  0.774650   0.950000  0.678571  0.791667     0.996441     0.678571  \n",
            "7  0.774650   0.950000  0.678571  0.791667     0.996441     0.678571  \n",
            "8  0.766015   1.000000  0.642857  0.782609     1.000000     0.642857  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CTDC**"
      ],
      "metadata": {
        "id": "vFklypxYteEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "anV1VVLf58m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ivoj_mmttgRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C703JLHVtxFa",
        "outputId": "ad0890e0-0256-47d5-eafe-0ad0c0c97769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.967233  0.783627   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953074  0.679408   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.955097  0.689450   \n",
            "3                             KNeighborsClassifier()  0.948220  0.645854   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960761  0.745603   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987864  0.926077   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.987864  0.924955   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988269  0.926666   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.774376   0.922156  0.693694  0.791774     0.994222     0.693694  \n",
            "1  0.665416   0.848684  0.581081  0.689840     0.989778     0.581081  \n",
            "2  0.654493   0.958678  0.522523  0.676385     0.997778     0.522523  \n",
            "3  0.634265   0.801282  0.563063  0.661376     0.986222     0.563063  \n",
            "4  0.907506   0.926267  0.905405  0.915718     0.992889     0.905405  \n",
            "5  0.742742   0.830688  0.707207  0.763990     0.985778     0.707207  \n",
            "6  0.926066   0.928571  0.936937  0.932735     0.992889     0.936937  \n",
            "7  0.924850   0.944444  0.918919  0.931507     0.994667     0.918919  \n",
            "8  0.925986   0.966184  0.900901  0.932401     0.996889     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "j38w7F9Vt6Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "MYhjqz36t8P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "GcqRP1xSt-hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxUY-6_nuE3T",
        "outputId": "6b704303-95a0-40c2-849e-85bf47e89af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.974745  0.949608   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.807045  0.614906   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.844705  0.701414   \n",
            "3                             KNeighborsClassifier()  0.940408  0.887098   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985600  0.971577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.939521  0.880014   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.989809  0.979757   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988259  0.976710   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996899  0.993811   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.949487   0.967391  0.982774  0.975022     0.966667     0.982774  \n",
            "1  0.614022   0.792034  0.834364  0.812648     0.779556     0.834364  \n",
            "2  0.689584   0.922204  0.753975  0.829648     0.936000     0.753975  \n",
            "3  0.880770   0.893802  1.000000  0.943923     0.880444     1.000000  \n",
            "4  0.971198   0.972497  0.999558  0.985842     0.971556     0.999558  \n",
            "5  0.879024   0.919865  0.963339  0.941100     0.915556     0.963339  \n",
            "6  0.979618   0.981755  0.998233  0.989926     0.981333     0.998233  \n",
            "7  0.976516   0.978779  0.998233  0.988410     0.978222     0.998233  \n",
            "8  0.993797   0.994288  0.999558  0.996916     0.994222     0.999558  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "n6bX2r_XuMFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "iNDXhKKUuOnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "JRgu-1KTuQ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZBOBNNEuWVy",
        "outputId": "c7e08f61-6a16-4dda-9c4b-106ebb8ebfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.988444  0.976965   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.948444  0.896902   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.966000  0.933017   \n",
            "3                             KNeighborsClassifier()  0.976667  0.953541   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.990000  0.980001   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.982889  0.965799   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.992667  0.985333   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.993333  0.986667   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.978889  0.958495   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.976889   0.994599  0.982222  0.988372     0.994667     0.982222  \n",
            "1  0.896889   0.950849  0.945778  0.948307     0.951111     0.945778  \n",
            "2  0.932000   0.988811  0.942667  0.965188     0.989333     0.942667  \n",
            "3  0.953333   0.986836  0.966222  0.976420     0.987111     0.966222  \n",
            "4  0.980000   0.989348  0.990667  0.990007     0.989333     0.990667  \n",
            "5  0.965778   0.986130  0.979556  0.982832     0.986222     0.979556  \n",
            "6  0.985333   0.992448  0.992889  0.992668     0.992444     0.992889  \n",
            "7  0.986667   0.993772  0.992889  0.993330     0.993778     0.992889  \n",
            "8  0.957778   0.998151  0.959556  0.978473     0.998222     0.959556  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "k2KoYXwBuf-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ypXk0fKjuj26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "fypSM6GZul8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBeKGDwhuq1M",
        "outputId": "f32cf449-8353-4dd9-aca0-c587e0d3aeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.976667  0.953436   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.840000  0.680017   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.867111  0.750065   \n",
            "3                             KNeighborsClassifier()  0.947778  0.900230   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985556  0.971242   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.947111  0.894240   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.985778  0.971631   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988000  0.976031   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990444  0.980891   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.953333   0.983762  0.969333  0.976494     0.984000     0.969333  \n",
            "1  0.680000   0.842435  0.836444  0.839429     0.843556     0.836444  \n",
            "2  0.734222   0.961453  0.764889  0.851980     0.969333     0.764889  \n",
            "3  0.895556   0.906414  0.998667  0.950307     0.896889     0.998667  \n",
            "4  0.971111   0.977700  0.993778  0.985673     0.977333     0.993778  \n",
            "5  0.894222   0.944346  0.950222  0.947275     0.944000     0.950222  \n",
            "6  0.971556   0.979807  0.992000  0.985866     0.979556     0.992000  \n",
            "7  0.976000   0.984127  0.992000  0.988048     0.984000     0.992000  \n",
            "8  0.980889   0.991537  0.989333  0.990434     0.991556     0.989333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "hZOdhVTDuyx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "pJxI28Fiu070"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "13aFoQL9u3jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85FvUoEfu8Uy",
        "outputId": "2721faf1-117c-4f87-b34a-ee1c8e6aa991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.936937  0.875617   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.869369  0.741755   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.905405  0.821687   \n",
            "3                             KNeighborsClassifier()  0.869369  0.743094   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.961712  0.923508   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.943694  0.887396   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.952703  0.905415   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.963964  0.928079   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.961712  0.924559   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.873874   0.966346  0.905405  0.934884     0.968468     0.905405  \n",
            "1  0.738739   0.905941  0.824324  0.863208     0.914414     0.824324  \n",
            "2  0.810811   0.983871  0.824324  0.897059     0.986486     0.824324  \n",
            "3  0.738739   0.914141  0.815315  0.861905     0.923423     0.815315  \n",
            "4  0.923423   0.968037  0.954955  0.961451     0.968468     0.954955  \n",
            "5  0.887387   0.941704  0.945946  0.943820     0.941441     0.945946  \n",
            "6  0.905405   0.950673  0.954955  0.952809     0.950450     0.954955  \n",
            "7  0.927928   0.972477  0.954955  0.963636     0.972973     0.954955  \n",
            "8  0.923423   0.985782  0.936937  0.960739     0.986486     0.936937  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "AzQ0NEMnvATb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Z-PcIaJAvEVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "B-47KbOVvHIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4G4sPlhvLfq",
        "outputId": "e9d56326-b75a-40b0-b807-1805e552fc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.966828  0.780956   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953074  0.680076   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.954288  0.682944   \n",
            "3                             KNeighborsClassifier()  0.948220  0.645854   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960761  0.745603   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987864  0.926077   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.987864  0.924955   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.987864  0.924182   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.772112   0.916667  0.693694  0.789744     0.993778     0.693694  \n",
            "1  0.666992   0.844156  0.585586  0.691489     0.989333     0.585586  \n",
            "2  0.644638   0.965812  0.509009  0.666667     0.998222     0.509009  \n",
            "3  0.634265   0.801282  0.563063  0.661376     0.986222     0.563063  \n",
            "4  0.907506   0.926267  0.905405  0.915718     0.992889     0.905405  \n",
            "5  0.742742   0.830688  0.707207  0.763990     0.985778     0.707207  \n",
            "6  0.926066   0.928571  0.936937  0.932735     0.992889     0.936937  \n",
            "7  0.924850   0.944444  0.918919  0.931507     0.994667     0.918919  \n",
            "8  0.923594   0.961538  0.900901  0.930233     0.996444     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "FXbrWS565Lr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Tg4ndrjA5OHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "08F3_k8H5Q_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ohU8nHlHv3",
        "outputId": "684bc6d7-97a2-4407-a47a-a2b3123d96b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3586288\ttotal: 101ms\tremaining: 4.44s\n",
            "1:\tlearn: 0.2387314\ttotal: 133ms\tremaining: 2.86s\n",
            "2:\tlearn: 0.1838333\ttotal: 172ms\tremaining: 2.41s\n",
            "3:\tlearn: 0.1574430\ttotal: 209ms\tremaining: 2.14s\n",
            "4:\tlearn: 0.1386140\ttotal: 248ms\tremaining: 1.99s\n",
            "5:\tlearn: 0.1305302\ttotal: 289ms\tremaining: 1.88s\n",
            "6:\tlearn: 0.1233358\ttotal: 323ms\tremaining: 1.75s\n",
            "7:\tlearn: 0.1182270\ttotal: 359ms\tremaining: 1.66s\n",
            "8:\tlearn: 0.1038264\ttotal: 399ms\tremaining: 1.6s\n",
            "9:\tlearn: 0.0897411\ttotal: 430ms\tremaining: 1.5s\n",
            "10:\tlearn: 0.0825722\ttotal: 454ms\tremaining: 1.4s\n",
            "11:\tlearn: 0.0725579\ttotal: 479ms\tremaining: 1.32s\n",
            "12:\tlearn: 0.0647758\ttotal: 503ms\tremaining: 1.24s\n",
            "13:\tlearn: 0.0583320\ttotal: 533ms\tremaining: 1.18s\n",
            "14:\tlearn: 0.0535854\ttotal: 559ms\tremaining: 1.12s\n",
            "15:\tlearn: 0.0496486\ttotal: 599ms\tremaining: 1.09s\n",
            "16:\tlearn: 0.0474797\ttotal: 638ms\tremaining: 1.05s\n",
            "17:\tlearn: 0.0420768\ttotal: 680ms\tremaining: 1.02s\n",
            "18:\tlearn: 0.0381864\ttotal: 719ms\tremaining: 983ms\n",
            "19:\tlearn: 0.0366009\ttotal: 777ms\tremaining: 971ms\n",
            "20:\tlearn: 0.0353731\ttotal: 814ms\tremaining: 930ms\n",
            "21:\tlearn: 0.0346316\ttotal: 853ms\tremaining: 892ms\n",
            "22:\tlearn: 0.0336706\ttotal: 891ms\tremaining: 852ms\n",
            "23:\tlearn: 0.0315762\ttotal: 932ms\tremaining: 816ms\n",
            "24:\tlearn: 0.0305250\ttotal: 956ms\tremaining: 764ms\n",
            "25:\tlearn: 0.0269423\ttotal: 999ms\tremaining: 730ms\n",
            "26:\tlearn: 0.0248460\ttotal: 1.02s\tremaining: 683ms\n",
            "27:\tlearn: 0.0239162\ttotal: 1.05s\tremaining: 637ms\n",
            "28:\tlearn: 0.0224920\ttotal: 1.07s\tremaining: 592ms\n",
            "29:\tlearn: 0.0213980\ttotal: 1.11s\tremaining: 556ms\n",
            "30:\tlearn: 0.0197375\ttotal: 1.15s\tremaining: 518ms\n",
            "31:\tlearn: 0.0185057\ttotal: 1.18s\tremaining: 481ms\n",
            "32:\tlearn: 0.0176920\ttotal: 1.22s\tremaining: 445ms\n",
            "33:\tlearn: 0.0163918\ttotal: 1.26s\tremaining: 409ms\n",
            "34:\tlearn: 0.0150582\ttotal: 1.29s\tremaining: 369ms\n",
            "35:\tlearn: 0.0145251\ttotal: 1.33s\tremaining: 332ms\n",
            "36:\tlearn: 0.0139709\ttotal: 1.36s\tremaining: 293ms\n",
            "37:\tlearn: 0.0131429\ttotal: 1.39s\tremaining: 257ms\n",
            "38:\tlearn: 0.0127097\ttotal: 1.44s\tremaining: 221ms\n",
            "39:\tlearn: 0.0123042\ttotal: 1.47s\tremaining: 184ms\n",
            "40:\tlearn: 0.0119026\ttotal: 1.51s\tremaining: 147ms\n",
            "41:\tlearn: 0.0112949\ttotal: 1.53s\tremaining: 110ms\n",
            "42:\tlearn: 0.0105152\ttotal: 1.56s\tremaining: 72.8ms\n",
            "43:\tlearn: 0.0100410\ttotal: 1.6s\tremaining: 36.4ms\n",
            "44:\tlearn: 0.0098126\ttotal: 1.65s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9599\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3586288\ttotal: 52.8ms\tremaining: 2.32s\n",
            "1:\tlearn: 0.2387314\ttotal: 81.5ms\tremaining: 1.75s\n",
            "2:\tlearn: 0.1838333\ttotal: 120ms\tremaining: 1.69s\n",
            "3:\tlearn: 0.1574430\ttotal: 159ms\tremaining: 1.63s\n",
            "4:\tlearn: 0.1386140\ttotal: 197ms\tremaining: 1.57s\n",
            "5:\tlearn: 0.1305302\ttotal: 235ms\tremaining: 1.53s\n",
            "6:\tlearn: 0.1233358\ttotal: 267ms\tremaining: 1.45s\n",
            "7:\tlearn: 0.1182270\ttotal: 303ms\tremaining: 1.4s\n",
            "8:\tlearn: 0.1038264\ttotal: 343ms\tremaining: 1.37s\n",
            "9:\tlearn: 0.0897411\ttotal: 382ms\tremaining: 1.33s\n",
            "10:\tlearn: 0.0825722\ttotal: 421ms\tremaining: 1.3s\n",
            "11:\tlearn: 0.0725579\ttotal: 458ms\tremaining: 1.26s\n",
            "12:\tlearn: 0.0647758\ttotal: 504ms\tremaining: 1.24s\n",
            "13:\tlearn: 0.0583320\ttotal: 544ms\tremaining: 1.2s\n",
            "14:\tlearn: 0.0535854\ttotal: 581ms\tremaining: 1.16s\n",
            "15:\tlearn: 0.0496486\ttotal: 622ms\tremaining: 1.13s\n",
            "16:\tlearn: 0.0474797\ttotal: 658ms\tremaining: 1.08s\n",
            "17:\tlearn: 0.0420768\ttotal: 698ms\tremaining: 1.05s\n",
            "18:\tlearn: 0.0381864\ttotal: 744ms\tremaining: 1.02s\n",
            "19:\tlearn: 0.0366009\ttotal: 783ms\tremaining: 979ms\n",
            "20:\tlearn: 0.0353731\ttotal: 820ms\tremaining: 937ms\n",
            "21:\tlearn: 0.0346316\ttotal: 858ms\tremaining: 897ms\n",
            "22:\tlearn: 0.0336706\ttotal: 895ms\tremaining: 856ms\n",
            "23:\tlearn: 0.0315762\ttotal: 923ms\tremaining: 808ms\n",
            "24:\tlearn: 0.0305250\ttotal: 953ms\tremaining: 763ms\n",
            "25:\tlearn: 0.0269423\ttotal: 982ms\tremaining: 718ms\n",
            "26:\tlearn: 0.0248460\ttotal: 1.02s\tremaining: 680ms\n",
            "27:\tlearn: 0.0239162\ttotal: 1.06s\tremaining: 643ms\n",
            "28:\tlearn: 0.0224920\ttotal: 1.1s\tremaining: 605ms\n",
            "29:\tlearn: 0.0213980\ttotal: 1.14s\tremaining: 568ms\n",
            "30:\tlearn: 0.0197375\ttotal: 1.18s\tremaining: 533ms\n",
            "31:\tlearn: 0.0185057\ttotal: 1.22s\tremaining: 494ms\n",
            "32:\tlearn: 0.0176920\ttotal: 1.26s\tremaining: 460ms\n",
            "33:\tlearn: 0.0163918\ttotal: 1.29s\tremaining: 417ms\n",
            "34:\tlearn: 0.0150582\ttotal: 1.31s\tremaining: 375ms\n",
            "35:\tlearn: 0.0145251\ttotal: 1.34s\tremaining: 336ms\n",
            "36:\tlearn: 0.0139709\ttotal: 1.39s\tremaining: 300ms\n",
            "37:\tlearn: 0.0131429\ttotal: 1.43s\tremaining: 263ms\n",
            "38:\tlearn: 0.0127097\ttotal: 1.46s\tremaining: 224ms\n",
            "39:\tlearn: 0.0123042\ttotal: 1.48s\tremaining: 185ms\n",
            "40:\tlearn: 0.0119026\ttotal: 1.5s\tremaining: 146ms\n",
            "41:\tlearn: 0.0112949\ttotal: 1.52s\tremaining: 109ms\n",
            "42:\tlearn: 0.0105152\ttotal: 1.57s\tremaining: 72.9ms\n",
            "43:\tlearn: 0.0100410\ttotal: 1.61s\tremaining: 36.6ms\n",
            "44:\tlearn: 0.0098126\ttotal: 1.64s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9599\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3580301\ttotal: 25.8ms\tremaining: 1.13s\n",
            "1:\tlearn: 0.2429120\ttotal: 44.2ms\tremaining: 950ms\n",
            "2:\tlearn: 0.1882013\ttotal: 62.3ms\tremaining: 873ms\n",
            "3:\tlearn: 0.1612841\ttotal: 80.1ms\tremaining: 821ms\n",
            "4:\tlearn: 0.1437649\ttotal: 98.1ms\tremaining: 785ms\n",
            "5:\tlearn: 0.1257453\ttotal: 116ms\tremaining: 752ms\n",
            "6:\tlearn: 0.1089581\ttotal: 134ms\tremaining: 726ms\n",
            "7:\tlearn: 0.0984017\ttotal: 153ms\tremaining: 707ms\n",
            "8:\tlearn: 0.0910546\ttotal: 171ms\tremaining: 685ms\n",
            "9:\tlearn: 0.0844652\ttotal: 191ms\tremaining: 668ms\n",
            "10:\tlearn: 0.0759659\ttotal: 209ms\tremaining: 646ms\n",
            "11:\tlearn: 0.0724873\ttotal: 230ms\tremaining: 633ms\n",
            "12:\tlearn: 0.0669872\ttotal: 250ms\tremaining: 615ms\n",
            "13:\tlearn: 0.0655711\ttotal: 268ms\tremaining: 593ms\n",
            "14:\tlearn: 0.0616706\ttotal: 285ms\tremaining: 571ms\n",
            "15:\tlearn: 0.0565467\ttotal: 310ms\tremaining: 563ms\n",
            "16:\tlearn: 0.0525054\ttotal: 329ms\tremaining: 541ms\n",
            "17:\tlearn: 0.0489922\ttotal: 348ms\tremaining: 522ms\n",
            "18:\tlearn: 0.0454648\ttotal: 366ms\tremaining: 501ms\n",
            "19:\tlearn: 0.0404473\ttotal: 384ms\tremaining: 480ms\n",
            "20:\tlearn: 0.0385622\ttotal: 404ms\tremaining: 462ms\n",
            "21:\tlearn: 0.0351312\ttotal: 423ms\tremaining: 442ms\n",
            "22:\tlearn: 0.0321159\ttotal: 453ms\tremaining: 433ms\n",
            "23:\tlearn: 0.0306954\ttotal: 472ms\tremaining: 413ms\n",
            "24:\tlearn: 0.0285596\ttotal: 493ms\tremaining: 394ms\n",
            "25:\tlearn: 0.0270237\ttotal: 512ms\tremaining: 374ms\n",
            "26:\tlearn: 0.0261159\ttotal: 531ms\tremaining: 354ms\n",
            "27:\tlearn: 0.0242745\ttotal: 549ms\tremaining: 333ms\n",
            "28:\tlearn: 0.0241376\ttotal: 567ms\tremaining: 313ms\n",
            "29:\tlearn: 0.0237586\ttotal: 585ms\tremaining: 292ms\n",
            "30:\tlearn: 0.0226190\ttotal: 603ms\tremaining: 272ms\n",
            "31:\tlearn: 0.0213925\ttotal: 634ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0201158\ttotal: 656ms\tremaining: 238ms\n",
            "33:\tlearn: 0.0194989\ttotal: 674ms\tremaining: 218ms\n",
            "34:\tlearn: 0.0193273\ttotal: 691ms\tremaining: 197ms\n",
            "35:\tlearn: 0.0183704\ttotal: 709ms\tremaining: 177ms\n",
            "36:\tlearn: 0.0179158\ttotal: 727ms\tremaining: 157ms\n",
            "37:\tlearn: 0.0176732\ttotal: 745ms\tremaining: 137ms\n",
            "38:\tlearn: 0.0173469\ttotal: 764ms\tremaining: 117ms\n",
            "39:\tlearn: 0.0169115\ttotal: 782ms\tremaining: 97.7ms\n",
            "40:\tlearn: 0.0161948\ttotal: 800ms\tremaining: 78ms\n",
            "41:\tlearn: 0.0151240\ttotal: 818ms\tremaining: 58.4ms\n",
            "42:\tlearn: 0.0142486\ttotal: 836ms\tremaining: 38.9ms\n",
            "43:\tlearn: 0.0135549\ttotal: 854ms\tremaining: 19.4ms\n",
            "44:\tlearn: 0.0134990\ttotal: 876ms\tremaining: 0us\n",
            "0:\tlearn: 0.3581177\ttotal: 24.7ms\tremaining: 1.08s\n",
            "1:\tlearn: 0.2404813\ttotal: 43.8ms\tremaining: 942ms\n",
            "2:\tlearn: 0.1808769\ttotal: 65.7ms\tremaining: 920ms\n",
            "3:\tlearn: 0.1490260\ttotal: 83ms\tremaining: 851ms\n",
            "4:\tlearn: 0.1251307\ttotal: 101ms\tremaining: 805ms\n",
            "5:\tlearn: 0.1156475\ttotal: 118ms\tremaining: 766ms\n",
            "6:\tlearn: 0.1052872\ttotal: 136ms\tremaining: 738ms\n",
            "7:\tlearn: 0.0986180\ttotal: 162ms\tremaining: 749ms\n",
            "8:\tlearn: 0.0901084\ttotal: 180ms\tremaining: 720ms\n",
            "9:\tlearn: 0.0853232\ttotal: 199ms\tremaining: 695ms\n",
            "10:\tlearn: 0.0808490\ttotal: 217ms\tremaining: 672ms\n",
            "11:\tlearn: 0.0740693\ttotal: 236ms\tremaining: 648ms\n",
            "12:\tlearn: 0.0694011\ttotal: 259ms\tremaining: 639ms\n",
            "13:\tlearn: 0.0632936\ttotal: 283ms\tremaining: 626ms\n",
            "14:\tlearn: 0.0599668\ttotal: 301ms\tremaining: 602ms\n",
            "15:\tlearn: 0.0562174\ttotal: 319ms\tremaining: 578ms\n",
            "16:\tlearn: 0.0539855\ttotal: 347ms\tremaining: 572ms\n",
            "17:\tlearn: 0.0514032\ttotal: 371ms\tremaining: 556ms\n",
            "18:\tlearn: 0.0466942\ttotal: 389ms\tremaining: 533ms\n",
            "19:\tlearn: 0.0438356\ttotal: 408ms\tremaining: 510ms\n",
            "20:\tlearn: 0.0424533\ttotal: 426ms\tremaining: 487ms\n",
            "21:\tlearn: 0.0414160\ttotal: 444ms\tremaining: 464ms\n",
            "22:\tlearn: 0.0388852\ttotal: 462ms\tremaining: 442ms\n",
            "23:\tlearn: 0.0369552\ttotal: 480ms\tremaining: 420ms\n",
            "24:\tlearn: 0.0344024\ttotal: 499ms\tremaining: 399ms\n",
            "25:\tlearn: 0.0326347\ttotal: 517ms\tremaining: 378ms\n",
            "26:\tlearn: 0.0301244\ttotal: 536ms\tremaining: 357ms\n",
            "27:\tlearn: 0.0285723\ttotal: 556ms\tremaining: 338ms\n",
            "28:\tlearn: 0.0264187\ttotal: 579ms\tremaining: 319ms\n",
            "29:\tlearn: 0.0255267\ttotal: 597ms\tremaining: 299ms\n",
            "30:\tlearn: 0.0247788\ttotal: 615ms\tremaining: 278ms\n",
            "31:\tlearn: 0.0234462\ttotal: 633ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0229431\ttotal: 651ms\tremaining: 237ms\n",
            "33:\tlearn: 0.0220068\ttotal: 669ms\tremaining: 216ms\n",
            "34:\tlearn: 0.0209141\ttotal: 689ms\tremaining: 197ms\n",
            "35:\tlearn: 0.0200348\ttotal: 718ms\tremaining: 179ms\n",
            "36:\tlearn: 0.0193650\ttotal: 735ms\tremaining: 159ms\n",
            "37:\tlearn: 0.0184726\ttotal: 753ms\tremaining: 139ms\n",
            "38:\tlearn: 0.0177331\ttotal: 771ms\tremaining: 119ms\n",
            "39:\tlearn: 0.0160636\ttotal: 795ms\tremaining: 99.3ms\n",
            "40:\tlearn: 0.0151891\ttotal: 814ms\tremaining: 79.4ms\n",
            "41:\tlearn: 0.0146737\ttotal: 832ms\tremaining: 59.4ms\n",
            "42:\tlearn: 0.0136955\ttotal: 849ms\tremaining: 39.5ms\n",
            "43:\tlearn: 0.0136087\ttotal: 867ms\tremaining: 19.7ms\n",
            "44:\tlearn: 0.0127224\ttotal: 886ms\tremaining: 0us\n",
            "0:\tlearn: 0.3759563\ttotal: 27.4ms\tremaining: 1.21s\n",
            "1:\tlearn: 0.2490870\ttotal: 46ms\tremaining: 988ms\n",
            "2:\tlearn: 0.1873794\ttotal: 69.7ms\tremaining: 976ms\n",
            "3:\tlearn: 0.1659344\ttotal: 87.9ms\tremaining: 901ms\n",
            "4:\tlearn: 0.1426832\ttotal: 107ms\tremaining: 854ms\n",
            "5:\tlearn: 0.1309803\ttotal: 125ms\tremaining: 814ms\n",
            "6:\tlearn: 0.1232565\ttotal: 147ms\tremaining: 796ms\n",
            "7:\tlearn: 0.1166084\ttotal: 166ms\tremaining: 767ms\n",
            "8:\tlearn: 0.1080087\ttotal: 184ms\tremaining: 736ms\n",
            "9:\tlearn: 0.0989371\ttotal: 213ms\tremaining: 746ms\n",
            "10:\tlearn: 0.0938614\ttotal: 232ms\tremaining: 717ms\n",
            "11:\tlearn: 0.0854130\ttotal: 251ms\tremaining: 691ms\n",
            "12:\tlearn: 0.0765574\ttotal: 274ms\tremaining: 675ms\n",
            "13:\tlearn: 0.0685072\ttotal: 292ms\tremaining: 646ms\n",
            "14:\tlearn: 0.0632222\ttotal: 310ms\tremaining: 620ms\n",
            "15:\tlearn: 0.0583043\ttotal: 328ms\tremaining: 595ms\n",
            "16:\tlearn: 0.0504233\ttotal: 347ms\tremaining: 571ms\n",
            "17:\tlearn: 0.0476766\ttotal: 366ms\tremaining: 548ms\n",
            "18:\tlearn: 0.0461135\ttotal: 384ms\tremaining: 526ms\n",
            "19:\tlearn: 0.0409022\ttotal: 403ms\tremaining: 504ms\n",
            "20:\tlearn: 0.0391294\ttotal: 422ms\tremaining: 482ms\n",
            "21:\tlearn: 0.0381615\ttotal: 439ms\tremaining: 459ms\n",
            "22:\tlearn: 0.0343269\ttotal: 458ms\tremaining: 438ms\n",
            "23:\tlearn: 0.0334897\ttotal: 481ms\tremaining: 421ms\n",
            "24:\tlearn: 0.0319164\ttotal: 500ms\tremaining: 400ms\n",
            "25:\tlearn: 0.0295874\ttotal: 518ms\tremaining: 379ms\n",
            "26:\tlearn: 0.0282627\ttotal: 537ms\tremaining: 358ms\n",
            "27:\tlearn: 0.0273424\ttotal: 557ms\tremaining: 338ms\n",
            "28:\tlearn: 0.0266733\ttotal: 574ms\tremaining: 317ms\n",
            "29:\tlearn: 0.0263568\ttotal: 592ms\tremaining: 296ms\n",
            "30:\tlearn: 0.0256254\ttotal: 615ms\tremaining: 278ms\n",
            "31:\tlearn: 0.0230975\ttotal: 633ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0212591\ttotal: 652ms\tremaining: 237ms\n",
            "33:\tlearn: 0.0203518\ttotal: 670ms\tremaining: 217ms\n",
            "34:\tlearn: 0.0195848\ttotal: 694ms\tremaining: 198ms\n",
            "35:\tlearn: 0.0188137\ttotal: 711ms\tremaining: 178ms\n",
            "36:\tlearn: 0.0178416\ttotal: 730ms\tremaining: 158ms\n",
            "37:\tlearn: 0.0167930\ttotal: 748ms\tremaining: 138ms\n",
            "38:\tlearn: 0.0156024\ttotal: 778ms\tremaining: 120ms\n",
            "39:\tlearn: 0.0152886\ttotal: 797ms\tremaining: 99.6ms\n",
            "40:\tlearn: 0.0149545\ttotal: 814ms\tremaining: 79.5ms\n",
            "41:\tlearn: 0.0141503\ttotal: 832ms\tremaining: 59.4ms\n",
            "42:\tlearn: 0.0136034\ttotal: 850ms\tremaining: 39.5ms\n",
            "43:\tlearn: 0.0132373\ttotal: 870ms\tremaining: 19.8ms\n",
            "44:\tlearn: 0.0125890\ttotal: 888ms\tremaining: 0us\n",
            "0:\tlearn: 0.3709012\ttotal: 25.3ms\tremaining: 1.11s\n",
            "1:\tlearn: 0.2346238\ttotal: 44.2ms\tremaining: 951ms\n",
            "2:\tlearn: 0.1770783\ttotal: 62.1ms\tremaining: 869ms\n",
            "3:\tlearn: 0.1522849\ttotal: 81.7ms\tremaining: 838ms\n",
            "4:\tlearn: 0.1303747\ttotal: 99.2ms\tremaining: 793ms\n",
            "5:\tlearn: 0.1225885\ttotal: 118ms\tremaining: 765ms\n",
            "6:\tlearn: 0.1131574\ttotal: 135ms\tremaining: 735ms\n",
            "7:\tlearn: 0.1061087\ttotal: 153ms\tremaining: 709ms\n",
            "8:\tlearn: 0.0940950\ttotal: 172ms\tremaining: 689ms\n",
            "9:\tlearn: 0.0877181\ttotal: 191ms\tremaining: 667ms\n",
            "10:\tlearn: 0.0840612\ttotal: 209ms\tremaining: 646ms\n",
            "11:\tlearn: 0.0766950\ttotal: 232ms\tremaining: 639ms\n",
            "12:\tlearn: 0.0677780\ttotal: 252ms\tremaining: 621ms\n",
            "13:\tlearn: 0.0620937\ttotal: 270ms\tremaining: 599ms\n",
            "14:\tlearn: 0.0579948\ttotal: 289ms\tremaining: 578ms\n",
            "15:\tlearn: 0.0551115\ttotal: 309ms\tremaining: 559ms\n",
            "16:\tlearn: 0.0513568\ttotal: 327ms\tremaining: 539ms\n",
            "17:\tlearn: 0.0484354\ttotal: 346ms\tremaining: 520ms\n",
            "18:\tlearn: 0.0462616\ttotal: 365ms\tremaining: 499ms\n",
            "19:\tlearn: 0.0439989\ttotal: 383ms\tremaining: 479ms\n",
            "20:\tlearn: 0.0417022\ttotal: 401ms\tremaining: 458ms\n",
            "21:\tlearn: 0.0398838\ttotal: 419ms\tremaining: 438ms\n",
            "22:\tlearn: 0.0375260\ttotal: 442ms\tremaining: 423ms\n",
            "23:\tlearn: 0.0358054\ttotal: 460ms\tremaining: 403ms\n",
            "24:\tlearn: 0.0329369\ttotal: 478ms\tremaining: 382ms\n",
            "25:\tlearn: 0.0299109\ttotal: 497ms\tremaining: 363ms\n",
            "26:\tlearn: 0.0269845\ttotal: 515ms\tremaining: 343ms\n",
            "27:\tlearn: 0.0262457\ttotal: 533ms\tremaining: 323ms\n",
            "28:\tlearn: 0.0239024\ttotal: 550ms\tremaining: 304ms\n",
            "29:\tlearn: 0.0234416\ttotal: 568ms\tremaining: 284ms\n",
            "30:\tlearn: 0.0227592\ttotal: 586ms\tremaining: 265ms\n",
            "31:\tlearn: 0.0219604\ttotal: 604ms\tremaining: 246ms\n",
            "32:\tlearn: 0.0214849\ttotal: 623ms\tremaining: 227ms\n",
            "33:\tlearn: 0.0203568\ttotal: 645ms\tremaining: 209ms\n",
            "34:\tlearn: 0.0184978\ttotal: 668ms\tremaining: 191ms\n",
            "35:\tlearn: 0.0179673\ttotal: 692ms\tremaining: 173ms\n",
            "36:\tlearn: 0.0169672\ttotal: 710ms\tremaining: 154ms\n",
            "37:\tlearn: 0.0163208\ttotal: 728ms\tremaining: 134ms\n",
            "38:\tlearn: 0.0161161\ttotal: 746ms\tremaining: 115ms\n",
            "39:\tlearn: 0.0156345\ttotal: 765ms\tremaining: 95.6ms\n",
            "40:\tlearn: 0.0141953\ttotal: 790ms\tremaining: 77.1ms\n",
            "41:\tlearn: 0.0136019\ttotal: 810ms\tremaining: 57.9ms\n",
            "42:\tlearn: 0.0129384\ttotal: 832ms\tremaining: 38.7ms\n",
            "43:\tlearn: 0.0126822\ttotal: 864ms\tremaining: 19.6ms\n",
            "44:\tlearn: 0.0122900\ttotal: 883ms\tremaining: 0us\n",
            "0:\tlearn: 0.3637753\ttotal: 26ms\tremaining: 1.14s\n",
            "1:\tlearn: 0.2347715\ttotal: 45.6ms\tremaining: 980ms\n",
            "2:\tlearn: 0.1829685\ttotal: 63.5ms\tremaining: 889ms\n",
            "3:\tlearn: 0.1516314\ttotal: 81.3ms\tremaining: 833ms\n",
            "4:\tlearn: 0.1392544\ttotal: 99.5ms\tremaining: 796ms\n",
            "5:\tlearn: 0.1296885\ttotal: 117ms\tremaining: 761ms\n",
            "6:\tlearn: 0.1195466\ttotal: 140ms\tremaining: 760ms\n",
            "7:\tlearn: 0.1088423\ttotal: 163ms\tremaining: 756ms\n",
            "8:\tlearn: 0.1009076\ttotal: 181ms\tremaining: 724ms\n",
            "9:\tlearn: 0.0966029\ttotal: 199ms\tremaining: 695ms\n",
            "10:\tlearn: 0.0911841\ttotal: 216ms\tremaining: 668ms\n",
            "11:\tlearn: 0.0847459\ttotal: 234ms\tremaining: 643ms\n",
            "12:\tlearn: 0.0797987\ttotal: 251ms\tremaining: 619ms\n",
            "13:\tlearn: 0.0702344\ttotal: 270ms\tremaining: 597ms\n",
            "14:\tlearn: 0.0644793\ttotal: 288ms\tremaining: 576ms\n",
            "15:\tlearn: 0.0579673\ttotal: 306ms\tremaining: 554ms\n",
            "16:\tlearn: 0.0561784\ttotal: 324ms\tremaining: 534ms\n",
            "17:\tlearn: 0.0534578\ttotal: 342ms\tremaining: 513ms\n",
            "18:\tlearn: 0.0488479\ttotal: 370ms\tremaining: 507ms\n",
            "19:\tlearn: 0.0457838\ttotal: 393ms\tremaining: 491ms\n",
            "20:\tlearn: 0.0439936\ttotal: 411ms\tremaining: 470ms\n",
            "21:\tlearn: 0.0405462\ttotal: 430ms\tremaining: 449ms\n",
            "22:\tlearn: 0.0363988\ttotal: 448ms\tremaining: 429ms\n",
            "23:\tlearn: 0.0348939\ttotal: 467ms\tremaining: 408ms\n",
            "24:\tlearn: 0.0324656\ttotal: 485ms\tremaining: 388ms\n",
            "25:\tlearn: 0.0311903\ttotal: 505ms\tremaining: 369ms\n",
            "26:\tlearn: 0.0278019\ttotal: 524ms\tremaining: 349ms\n",
            "27:\tlearn: 0.0270423\ttotal: 542ms\tremaining: 329ms\n",
            "28:\tlearn: 0.0252397\ttotal: 560ms\tremaining: 309ms\n",
            "29:\tlearn: 0.0238219\ttotal: 584ms\tremaining: 292ms\n",
            "30:\tlearn: 0.0233651\ttotal: 603ms\tremaining: 272ms\n",
            "31:\tlearn: 0.0229280\ttotal: 622ms\tremaining: 253ms\n",
            "32:\tlearn: 0.0214437\ttotal: 642ms\tremaining: 233ms\n",
            "33:\tlearn: 0.0197893\ttotal: 660ms\tremaining: 214ms\n",
            "34:\tlearn: 0.0187118\ttotal: 678ms\tremaining: 194ms\n",
            "35:\tlearn: 0.0177485\ttotal: 696ms\tremaining: 174ms\n",
            "36:\tlearn: 0.0168183\ttotal: 717ms\tremaining: 155ms\n",
            "37:\tlearn: 0.0156311\ttotal: 735ms\tremaining: 135ms\n",
            "38:\tlearn: 0.0152557\ttotal: 754ms\tremaining: 116ms\n",
            "39:\tlearn: 0.0149229\ttotal: 772ms\tremaining: 96.5ms\n",
            "40:\tlearn: 0.0143682\ttotal: 795ms\tremaining: 77.6ms\n",
            "41:\tlearn: 0.0138352\ttotal: 813ms\tremaining: 58.1ms\n",
            "42:\tlearn: 0.0136601\ttotal: 832ms\tremaining: 38.7ms\n",
            "43:\tlearn: 0.0132779\ttotal: 851ms\tremaining: 19.3ms\n",
            "44:\tlearn: 0.0125731\ttotal: 870ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9520\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9543\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9560\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9573\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9557\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.961165  0.739754   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.957929  0.714933   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.957929  0.715560   \n",
            "3                             KNeighborsClassifier()  0.956311  0.706269   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.964401  0.763941   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.964401  0.769515   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.964401  0.764376   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.961165  0.741733   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.954693  0.690124   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.719219   0.944444  0.607143  0.739130     0.996441     0.607143  \n",
            "1  0.689879   0.941176  0.571429  0.711111     0.996441     0.571429  \n",
            "2  0.677272   1.000000  0.535714  0.697674     1.000000     0.535714  \n",
            "3  0.692945   0.871795  0.607143  0.715789     0.991103     0.607143  \n",
            "4  0.747455   0.947368  0.642857  0.765957     0.996441     0.642857  \n",
            "5  0.765116   0.869565  0.714286  0.784314     0.989324     0.714286  \n",
            "6  0.737590   1.000000  0.607143  0.755556     1.000000     0.607143  \n",
            "7  0.729580   0.900000  0.642857  0.750000     0.992883     0.642857  \n",
            "8  0.645235   1.000000  0.500000  0.666667     1.000000     0.500000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GDPC**"
      ],
      "metadata": {
        "id": "VZobnVY14S_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "ecs4kPAM4oAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "RA_PIkMj4cGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbKYxrSj4qJZ",
        "outputId": "ff666d1f-322f-4235-abd7-a5fef6a5df01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.961974  0.744471   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.934871  0.537537   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.927994  0.427229   \n",
            "3                             KNeighborsClassifier()  0.937298  0.579366   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.980987  0.882159   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.954288  0.701120   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983819  0.901432   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.984628  0.906361   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.985437  0.909633   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.730149   0.915584  0.635135  0.750000     0.994222     0.635135  \n",
            "1  0.520882   0.719424  0.450450  0.554017     0.982667     0.450450  \n",
            "2  0.327439   0.923077  0.216216  0.350365     0.998222     0.216216  \n",
            "3  0.574091   0.693642  0.540541  0.607595     0.976444     0.540541  \n",
            "4  0.882023   0.906977  0.878378  0.892449     0.991111     0.878378  \n",
            "5  0.697677   0.794595  0.662162  0.722359     0.983111     0.662162  \n",
            "6  0.901421   0.906250  0.914414  0.910314     0.990667     0.914414  \n",
            "7  0.906350   0.910714  0.918919  0.914798     0.991111     0.918919  \n",
            "8  0.909448   0.934579  0.900901  0.917431     0.993778     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "BNUDC1dB4ySc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "p8422GQf40M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "U_IVSuxs42QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-3sc9gl473y",
        "outputId": "952ba557-af11-4371-ae81-03c6ae5bf5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.981531  0.963418   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.820427  0.661764   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.869826  0.741879   \n",
            "3                             KNeighborsClassifier()  0.930797  0.869989   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988652  0.977466   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.922563  0.845974   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.990209  0.980518   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.990877  0.981847   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993992  0.987996   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.963063   0.968764  0.995098  0.981754     0.968000     0.995098  \n",
            "1  0.640973   0.756333  0.944742  0.840103     0.696444     0.944742  \n",
            "2  0.739625   0.900918  0.830660  0.864364     0.908889     0.830660  \n",
            "3  0.861619   0.878278  1.000000  0.935195     0.861778     1.000000  \n",
            "4  0.977304   0.979869  0.997772  0.988739     0.979556     0.997772  \n",
            "5  0.845136   0.904437  0.944742  0.924150     0.900444     0.944742  \n",
            "6  0.980419   0.983304  0.997326  0.990265     0.983111     0.997326  \n",
            "7  0.981754   0.984176  0.997772  0.990927     0.984000     0.997772  \n",
            "8  0.987984   0.991574  0.996435  0.993999     0.991556     0.996435  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "DqmKDj5I5Aoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "aQnr5ttn5CRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "5xtzVgou5EUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4O5Kxg75LPa",
        "outputId": "3ab5c770-0d99-4d46-9e09-c8d547e22cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.984667  0.969345   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.945778  0.891832   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.948889  0.897813   \n",
            "3                             KNeighborsClassifier()  0.964667  0.929341   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.986222  0.972445   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.973778  0.947580   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.989556  0.979116   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.991111  0.982224   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.975556  0.951807   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.969333   0.982309  0.987111  0.984704     0.982222     0.987111  \n",
            "1  0.891556   0.934952  0.958222  0.946444     0.933333     0.958222  \n",
            "2  0.897778   0.944934  0.953333  0.949115     0.944444     0.953333  \n",
            "3  0.929333   0.966533  0.962667  0.964596     0.966667     0.962667  \n",
            "4  0.972444   0.985790  0.986667  0.986228     0.985778     0.986667  \n",
            "5  0.947556   0.977171  0.970222  0.973684     0.977333     0.970222  \n",
            "6  0.979111   0.988037  0.991111  0.989572     0.988000     0.991111  \n",
            "7  0.982222   0.990240  0.992000  0.991119     0.990222     0.992000  \n",
            "8  0.951111   0.994455  0.956444  0.975079     0.994667     0.956444  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "H4YoJYpJ5QBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "pXw5ANO15SSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "J9ytFTKX5UOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSqr5tg85ZF5",
        "outputId": "f1b12579-5278-408d-ca14-f1fe5fd2cae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.977333  0.954685   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.834222  0.668482   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.892000  0.786635   \n",
            "3                             KNeighborsClassifier()  0.937333  0.881619   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.987778  0.975687   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.928667  0.857649   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991111  0.982310   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.990222  0.980510   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993333  0.986681   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.954667   0.974382  0.980444  0.977404     0.974222     0.980444  \n",
            "1  0.668444   0.837826  0.828889  0.833333     0.839556     0.828889  \n",
            "2  0.784000   0.926912  0.851111  0.887396     0.932889     0.851111  \n",
            "3  0.874667   0.888626  1.000000  0.941029     0.874667     1.000000  \n",
            "4  0.975556   0.979886  0.996000  0.987877     0.979556     0.996000  \n",
            "5  0.857333   0.917352  0.942222  0.929621     0.915111     0.942222  \n",
            "6  0.982222   0.984649  0.997778  0.991170     0.984444     0.997778  \n",
            "7  0.980444   0.984622  0.996000  0.990278     0.984444     0.996000  \n",
            "8  0.986667   0.990716  0.996000  0.993351     0.990667     0.996000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "QoN9DVFb5c_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "h6UM-A0e5eyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "LNV0_J-r5hb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo6yTJ5h5mbi",
        "outputId": "f891a006-33c5-43ad-9251-e6a24a5126fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.912162  0.824400   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.885135  0.770904   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.891892  0.783911   \n",
            "3                             KNeighborsClassifier()  0.795045  0.593283   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.909910  0.820353   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.914414  0.829132   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.907658  0.815986   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.909910  0.820353   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.914414  0.829368   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.824324   0.906667  0.918919  0.912752     0.905405     0.918919  \n",
            "1  0.770270   0.901408  0.864865  0.882759     0.905405     0.864865  \n",
            "2  0.783784   0.899083  0.882883  0.890909     0.900901     0.882883  \n",
            "3  0.590090   0.829146  0.743243  0.783848     0.846847     0.743243  \n",
            "4  0.819820   0.895652  0.927928  0.911504     0.891892     0.927928  \n",
            "5  0.828829   0.903509  0.927928  0.915556     0.900901     0.927928  \n",
            "6  0.815315   0.891775  0.927928  0.909492     0.887387     0.927928  \n",
            "7  0.819820   0.895652  0.927928  0.911504     0.891892     0.927928  \n",
            "8  0.828829   0.929907  0.896396  0.912844     0.932432     0.896396  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "dV9Xj1SH5q0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ytrnqX1X5stj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "da87gVNo5vD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KoN_z065zbj",
        "outputId": "b521dd7d-d384-4127-ebd6-99a2ad60c463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.962379  0.747538   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.934466  0.535179   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.927994  0.427229   \n",
            "3                             KNeighborsClassifier()  0.937298  0.579366   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.980987  0.882159   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.954288  0.701120   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983819  0.901432   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.984628  0.906361   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.984628  0.904913   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.733647   0.916129  0.639640  0.753316     0.994222     0.639640  \n",
            "1  0.519080   0.714286  0.450450  0.552486     0.982222     0.450450  \n",
            "2  0.327439   0.923077  0.216216  0.350365     0.998222     0.216216  \n",
            "3  0.574091   0.693642  0.540541  0.607595     0.976444     0.540541  \n",
            "4  0.882023   0.906977  0.878378  0.892449     0.991111     0.878378  \n",
            "5  0.697677   0.794595  0.662162  0.722359     0.983111     0.662162  \n",
            "6  0.901421   0.906250  0.914414  0.910314     0.990667     0.914414  \n",
            "7  0.906350   0.910714  0.918919  0.914798     0.991111     0.918919  \n",
            "8  0.904811   0.925926  0.900901  0.913242     0.992889     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "V_qzWolfCiey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "B_AllsNtCl2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest= df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "RpsPGIZCCoth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI769vCoCxKK",
        "outputId": "76ac3da0-f60e-43da-aef7-5693473784ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3375109\ttotal: 77.6ms\tremaining: 3.42s\n",
            "1:\tlearn: 0.2176891\ttotal: 99.8ms\tremaining: 2.15s\n",
            "2:\tlearn: 0.1674932\ttotal: 119ms\tremaining: 1.67s\n",
            "3:\tlearn: 0.1458531\ttotal: 138ms\tremaining: 1.42s\n",
            "4:\tlearn: 0.1277541\ttotal: 159ms\tremaining: 1.27s\n",
            "5:\tlearn: 0.1210375\ttotal: 176ms\tremaining: 1.15s\n",
            "6:\tlearn: 0.1151019\ttotal: 195ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.1081074\ttotal: 218ms\tremaining: 1.01s\n",
            "8:\tlearn: 0.1020136\ttotal: 238ms\tremaining: 952ms\n",
            "9:\tlearn: 0.0970428\ttotal: 261ms\tremaining: 913ms\n",
            "10:\tlearn: 0.0860568\ttotal: 289ms\tremaining: 894ms\n",
            "11:\tlearn: 0.0795166\ttotal: 311ms\tremaining: 854ms\n",
            "12:\tlearn: 0.0741892\ttotal: 331ms\tremaining: 815ms\n",
            "13:\tlearn: 0.0665348\ttotal: 352ms\tremaining: 780ms\n",
            "14:\tlearn: 0.0634794\ttotal: 374ms\tremaining: 748ms\n",
            "15:\tlearn: 0.0622037\ttotal: 397ms\tremaining: 720ms\n",
            "16:\tlearn: 0.0590992\ttotal: 419ms\tremaining: 691ms\n",
            "17:\tlearn: 0.0569823\ttotal: 439ms\tremaining: 659ms\n",
            "18:\tlearn: 0.0554606\ttotal: 454ms\tremaining: 621ms\n",
            "19:\tlearn: 0.0531405\ttotal: 471ms\tremaining: 589ms\n",
            "20:\tlearn: 0.0488269\ttotal: 489ms\tremaining: 559ms\n",
            "21:\tlearn: 0.0474172\ttotal: 501ms\tremaining: 524ms\n",
            "22:\tlearn: 0.0459131\ttotal: 513ms\tremaining: 491ms\n",
            "23:\tlearn: 0.0448672\ttotal: 526ms\tremaining: 460ms\n",
            "24:\tlearn: 0.0420708\ttotal: 538ms\tremaining: 430ms\n",
            "25:\tlearn: 0.0409108\ttotal: 549ms\tremaining: 401ms\n",
            "26:\tlearn: 0.0393012\ttotal: 561ms\tremaining: 374ms\n",
            "27:\tlearn: 0.0379897\ttotal: 573ms\tremaining: 348ms\n",
            "28:\tlearn: 0.0347955\ttotal: 592ms\tremaining: 326ms\n",
            "29:\tlearn: 0.0316232\ttotal: 612ms\tremaining: 306ms\n",
            "30:\tlearn: 0.0296974\ttotal: 634ms\tremaining: 286ms\n",
            "31:\tlearn: 0.0276197\ttotal: 657ms\tremaining: 267ms\n",
            "32:\tlearn: 0.0274195\ttotal: 677ms\tremaining: 246ms\n",
            "33:\tlearn: 0.0258432\ttotal: 703ms\tremaining: 228ms\n",
            "34:\tlearn: 0.0244146\ttotal: 726ms\tremaining: 207ms\n",
            "35:\tlearn: 0.0232285\ttotal: 748ms\tremaining: 187ms\n",
            "36:\tlearn: 0.0220336\ttotal: 766ms\tremaining: 166ms\n",
            "37:\tlearn: 0.0208506\ttotal: 785ms\tremaining: 145ms\n",
            "38:\tlearn: 0.0200129\ttotal: 808ms\tremaining: 124ms\n",
            "39:\tlearn: 0.0193279\ttotal: 828ms\tremaining: 103ms\n",
            "40:\tlearn: 0.0185371\ttotal: 850ms\tremaining: 82.9ms\n",
            "41:\tlearn: 0.0177718\ttotal: 872ms\tremaining: 62.3ms\n",
            "42:\tlearn: 0.0168416\ttotal: 892ms\tremaining: 41.5ms\n",
            "43:\tlearn: 0.0161007\ttotal: 917ms\tremaining: 20.8ms\n",
            "44:\tlearn: 0.0152464\ttotal: 931ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3209\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3375109\ttotal: 28.1ms\tremaining: 1.24s\n",
            "1:\tlearn: 0.2176891\ttotal: 49.1ms\tremaining: 1.05s\n",
            "2:\tlearn: 0.1674932\ttotal: 71.8ms\tremaining: 1s\n",
            "3:\tlearn: 0.1458531\ttotal: 95.3ms\tremaining: 977ms\n",
            "4:\tlearn: 0.1277541\ttotal: 118ms\tremaining: 945ms\n",
            "5:\tlearn: 0.1210375\ttotal: 136ms\tremaining: 887ms\n",
            "6:\tlearn: 0.1151019\ttotal: 159ms\tremaining: 864ms\n",
            "7:\tlearn: 0.1081074\ttotal: 182ms\tremaining: 841ms\n",
            "8:\tlearn: 0.1020136\ttotal: 201ms\tremaining: 806ms\n",
            "9:\tlearn: 0.0970428\ttotal: 213ms\tremaining: 747ms\n",
            "10:\tlearn: 0.0860568\ttotal: 233ms\tremaining: 719ms\n",
            "11:\tlearn: 0.0795166\ttotal: 245ms\tremaining: 673ms\n",
            "12:\tlearn: 0.0741892\ttotal: 257ms\tremaining: 631ms\n",
            "13:\tlearn: 0.0665348\ttotal: 268ms\tremaining: 593ms\n",
            "14:\tlearn: 0.0634794\ttotal: 289ms\tremaining: 577ms\n",
            "15:\tlearn: 0.0622037\ttotal: 312ms\tremaining: 565ms\n",
            "16:\tlearn: 0.0590992\ttotal: 342ms\tremaining: 564ms\n",
            "17:\tlearn: 0.0569823\ttotal: 373ms\tremaining: 560ms\n",
            "18:\tlearn: 0.0554606\ttotal: 402ms\tremaining: 551ms\n",
            "19:\tlearn: 0.0531405\ttotal: 427ms\tremaining: 533ms\n",
            "20:\tlearn: 0.0488269\ttotal: 455ms\tremaining: 520ms\n",
            "21:\tlearn: 0.0474172\ttotal: 480ms\tremaining: 502ms\n",
            "22:\tlearn: 0.0459131\ttotal: 503ms\tremaining: 481ms\n",
            "23:\tlearn: 0.0448672\ttotal: 522ms\tremaining: 456ms\n",
            "24:\tlearn: 0.0420708\ttotal: 545ms\tremaining: 436ms\n",
            "25:\tlearn: 0.0409108\ttotal: 570ms\tremaining: 417ms\n",
            "26:\tlearn: 0.0393012\ttotal: 593ms\tremaining: 395ms\n",
            "27:\tlearn: 0.0379897\ttotal: 624ms\tremaining: 379ms\n",
            "28:\tlearn: 0.0347955\ttotal: 660ms\tremaining: 364ms\n",
            "29:\tlearn: 0.0316232\ttotal: 694ms\tremaining: 347ms\n",
            "30:\tlearn: 0.0296974\ttotal: 727ms\tremaining: 328ms\n",
            "31:\tlearn: 0.0276197\ttotal: 754ms\tremaining: 307ms\n",
            "32:\tlearn: 0.0274195\ttotal: 781ms\tremaining: 284ms\n",
            "33:\tlearn: 0.0258432\ttotal: 811ms\tremaining: 262ms\n",
            "34:\tlearn: 0.0244146\ttotal: 839ms\tremaining: 240ms\n",
            "35:\tlearn: 0.0232285\ttotal: 872ms\tremaining: 218ms\n",
            "36:\tlearn: 0.0220336\ttotal: 898ms\tremaining: 194ms\n",
            "37:\tlearn: 0.0208506\ttotal: 929ms\tremaining: 171ms\n",
            "38:\tlearn: 0.0200129\ttotal: 957ms\tremaining: 147ms\n",
            "39:\tlearn: 0.0193279\ttotal: 990ms\tremaining: 124ms\n",
            "40:\tlearn: 0.0185371\ttotal: 1.02s\tremaining: 99.7ms\n",
            "41:\tlearn: 0.0177718\ttotal: 1.05s\tremaining: 75.4ms\n",
            "42:\tlearn: 0.0168416\ttotal: 1.08s\tremaining: 50.5ms\n",
            "43:\tlearn: 0.0161007\ttotal: 1.11s\tremaining: 25.3ms\n",
            "44:\tlearn: 0.0152464\ttotal: 1.14s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3209\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3427439\ttotal: 13ms\tremaining: 573ms\n",
            "1:\tlearn: 0.2145218\ttotal: 24.3ms\tremaining: 523ms\n",
            "2:\tlearn: 0.1689906\ttotal: 33.8ms\tremaining: 473ms\n",
            "3:\tlearn: 0.1475432\ttotal: 42.9ms\tremaining: 439ms\n",
            "4:\tlearn: 0.1316782\ttotal: 51.9ms\tremaining: 415ms\n",
            "5:\tlearn: 0.1220640\ttotal: 60.9ms\tremaining: 396ms\n",
            "6:\tlearn: 0.1114936\ttotal: 70ms\tremaining: 380ms\n",
            "7:\tlearn: 0.1076156\ttotal: 79.4ms\tremaining: 367ms\n",
            "8:\tlearn: 0.0997450\ttotal: 89.3ms\tremaining: 357ms\n",
            "9:\tlearn: 0.0943125\ttotal: 109ms\tremaining: 383ms\n",
            "10:\tlearn: 0.0857051\ttotal: 124ms\tremaining: 384ms\n",
            "11:\tlearn: 0.0805959\ttotal: 137ms\tremaining: 376ms\n",
            "12:\tlearn: 0.0767948\ttotal: 146ms\tremaining: 361ms\n",
            "13:\tlearn: 0.0714441\ttotal: 155ms\tremaining: 344ms\n",
            "14:\tlearn: 0.0686166\ttotal: 164ms\tremaining: 328ms\n",
            "15:\tlearn: 0.0648519\ttotal: 173ms\tremaining: 313ms\n",
            "16:\tlearn: 0.0615071\ttotal: 182ms\tremaining: 300ms\n",
            "17:\tlearn: 0.0572561\ttotal: 191ms\tremaining: 287ms\n",
            "18:\tlearn: 0.0544884\ttotal: 202ms\tremaining: 276ms\n",
            "19:\tlearn: 0.0509123\ttotal: 212ms\tremaining: 265ms\n",
            "20:\tlearn: 0.0492362\ttotal: 226ms\tremaining: 259ms\n",
            "21:\tlearn: 0.0448815\ttotal: 235ms\tremaining: 246ms\n",
            "22:\tlearn: 0.0425944\ttotal: 245ms\tremaining: 234ms\n",
            "23:\tlearn: 0.0414056\ttotal: 253ms\tremaining: 222ms\n",
            "24:\tlearn: 0.0397840\ttotal: 262ms\tremaining: 210ms\n",
            "25:\tlearn: 0.0373513\ttotal: 274ms\tremaining: 200ms\n",
            "26:\tlearn: 0.0343745\ttotal: 284ms\tremaining: 189ms\n",
            "27:\tlearn: 0.0332783\ttotal: 293ms\tremaining: 178ms\n",
            "28:\tlearn: 0.0330218\ttotal: 302ms\tremaining: 167ms\n",
            "29:\tlearn: 0.0313443\ttotal: 315ms\tremaining: 157ms\n",
            "30:\tlearn: 0.0304942\ttotal: 324ms\tremaining: 146ms\n",
            "31:\tlearn: 0.0294333\ttotal: 333ms\tremaining: 135ms\n",
            "32:\tlearn: 0.0284563\ttotal: 341ms\tremaining: 124ms\n",
            "33:\tlearn: 0.0268455\ttotal: 351ms\tremaining: 113ms\n",
            "34:\tlearn: 0.0246594\ttotal: 361ms\tremaining: 103ms\n",
            "35:\tlearn: 0.0242822\ttotal: 369ms\tremaining: 92.3ms\n",
            "36:\tlearn: 0.0232366\ttotal: 379ms\tremaining: 81.8ms\n",
            "37:\tlearn: 0.0230477\ttotal: 387ms\tremaining: 71.4ms\n",
            "38:\tlearn: 0.0217319\ttotal: 396ms\tremaining: 61ms\n",
            "39:\tlearn: 0.0198762\ttotal: 406ms\tremaining: 50.7ms\n",
            "40:\tlearn: 0.0197294\ttotal: 421ms\tremaining: 41.1ms\n",
            "41:\tlearn: 0.0188853\ttotal: 431ms\tremaining: 30.8ms\n",
            "42:\tlearn: 0.0169937\ttotal: 440ms\tremaining: 20.5ms\n",
            "43:\tlearn: 0.0167462\ttotal: 450ms\tremaining: 10.2ms\n",
            "44:\tlearn: 0.0162331\ttotal: 459ms\tremaining: 0us\n",
            "0:\tlearn: 0.3426847\ttotal: 10ms\tremaining: 440ms\n",
            "1:\tlearn: 0.2231983\ttotal: 18.7ms\tremaining: 403ms\n",
            "2:\tlearn: 0.1746699\ttotal: 30.1ms\tremaining: 421ms\n",
            "3:\tlearn: 0.1485142\ttotal: 40.1ms\tremaining: 411ms\n",
            "4:\tlearn: 0.1393710\ttotal: 49.1ms\tremaining: 393ms\n",
            "5:\tlearn: 0.1302300\ttotal: 57.7ms\tremaining: 375ms\n",
            "6:\tlearn: 0.1238051\ttotal: 66.4ms\tremaining: 361ms\n",
            "7:\tlearn: 0.1138519\ttotal: 75ms\tremaining: 347ms\n",
            "8:\tlearn: 0.1085171\ttotal: 83.5ms\tremaining: 334ms\n",
            "9:\tlearn: 0.1048904\ttotal: 93.9ms\tremaining: 329ms\n",
            "10:\tlearn: 0.0944177\ttotal: 103ms\tremaining: 317ms\n",
            "11:\tlearn: 0.0880679\ttotal: 111ms\tremaining: 306ms\n",
            "12:\tlearn: 0.0859471\ttotal: 124ms\tremaining: 304ms\n",
            "13:\tlearn: 0.0784929\ttotal: 133ms\tremaining: 294ms\n",
            "14:\tlearn: 0.0764983\ttotal: 142ms\tremaining: 283ms\n",
            "15:\tlearn: 0.0727936\ttotal: 150ms\tremaining: 272ms\n",
            "16:\tlearn: 0.0689096\ttotal: 159ms\tremaining: 262ms\n",
            "17:\tlearn: 0.0657597\ttotal: 168ms\tremaining: 251ms\n",
            "18:\tlearn: 0.0616969\ttotal: 177ms\tremaining: 242ms\n",
            "19:\tlearn: 0.0584334\ttotal: 185ms\tremaining: 231ms\n",
            "20:\tlearn: 0.0540995\ttotal: 194ms\tremaining: 222ms\n",
            "21:\tlearn: 0.0507504\ttotal: 202ms\tremaining: 212ms\n",
            "22:\tlearn: 0.0475492\ttotal: 211ms\tremaining: 202ms\n",
            "23:\tlearn: 0.0455451\ttotal: 220ms\tremaining: 192ms\n",
            "24:\tlearn: 0.0443469\ttotal: 228ms\tremaining: 183ms\n",
            "25:\tlearn: 0.0438724\ttotal: 237ms\tremaining: 173ms\n",
            "26:\tlearn: 0.0398617\ttotal: 246ms\tremaining: 164ms\n",
            "27:\tlearn: 0.0396607\ttotal: 254ms\tremaining: 154ms\n",
            "28:\tlearn: 0.0379253\ttotal: 263ms\tremaining: 145ms\n",
            "29:\tlearn: 0.0364779\ttotal: 274ms\tremaining: 137ms\n",
            "30:\tlearn: 0.0349501\ttotal: 283ms\tremaining: 128ms\n",
            "31:\tlearn: 0.0330412\ttotal: 292ms\tremaining: 118ms\n",
            "32:\tlearn: 0.0329241\ttotal: 300ms\tremaining: 109ms\n",
            "33:\tlearn: 0.0316933\ttotal: 309ms\tremaining: 99.9ms\n",
            "34:\tlearn: 0.0309293\ttotal: 318ms\tremaining: 90.7ms\n",
            "35:\tlearn: 0.0287118\ttotal: 336ms\tremaining: 83.9ms\n",
            "36:\tlearn: 0.0270029\ttotal: 345ms\tremaining: 74.6ms\n",
            "37:\tlearn: 0.0264056\ttotal: 355ms\tremaining: 65.4ms\n",
            "38:\tlearn: 0.0252036\ttotal: 364ms\tremaining: 56ms\n",
            "39:\tlearn: 0.0243834\ttotal: 373ms\tremaining: 46.6ms\n",
            "40:\tlearn: 0.0239067\ttotal: 381ms\tremaining: 37.2ms\n",
            "41:\tlearn: 0.0238153\ttotal: 390ms\tremaining: 27.8ms\n",
            "42:\tlearn: 0.0231949\ttotal: 398ms\tremaining: 18.5ms\n",
            "43:\tlearn: 0.0226752\ttotal: 406ms\tremaining: 9.24ms\n",
            "44:\tlearn: 0.0220857\ttotal: 415ms\tremaining: 0us\n",
            "0:\tlearn: 0.3433914\ttotal: 9.46ms\tremaining: 416ms\n",
            "1:\tlearn: 0.2179278\ttotal: 17.7ms\tremaining: 380ms\n",
            "2:\tlearn: 0.1773329\ttotal: 26.4ms\tremaining: 369ms\n",
            "3:\tlearn: 0.1595308\ttotal: 37.7ms\tremaining: 387ms\n",
            "4:\tlearn: 0.1409975\ttotal: 46.3ms\tremaining: 370ms\n",
            "5:\tlearn: 0.1320427\ttotal: 54.9ms\tremaining: 357ms\n",
            "6:\tlearn: 0.1227302\ttotal: 63.3ms\tremaining: 343ms\n",
            "7:\tlearn: 0.1147946\ttotal: 71.7ms\tremaining: 332ms\n",
            "8:\tlearn: 0.1051975\ttotal: 84.5ms\tremaining: 338ms\n",
            "9:\tlearn: 0.1013870\ttotal: 96ms\tremaining: 336ms\n",
            "10:\tlearn: 0.0965643\ttotal: 107ms\tremaining: 330ms\n",
            "11:\tlearn: 0.0903135\ttotal: 115ms\tremaining: 317ms\n",
            "12:\tlearn: 0.0820153\ttotal: 125ms\tremaining: 307ms\n",
            "13:\tlearn: 0.0759272\ttotal: 141ms\tremaining: 313ms\n",
            "14:\tlearn: 0.0712368\ttotal: 155ms\tremaining: 310ms\n",
            "15:\tlearn: 0.0685806\ttotal: 163ms\tremaining: 296ms\n",
            "16:\tlearn: 0.0619722\ttotal: 172ms\tremaining: 283ms\n",
            "17:\tlearn: 0.0588157\ttotal: 181ms\tremaining: 272ms\n",
            "18:\tlearn: 0.0570650\ttotal: 190ms\tremaining: 260ms\n",
            "19:\tlearn: 0.0543861\ttotal: 209ms\tremaining: 261ms\n",
            "20:\tlearn: 0.0524746\ttotal: 220ms\tremaining: 252ms\n",
            "21:\tlearn: 0.0512782\ttotal: 235ms\tremaining: 246ms\n",
            "22:\tlearn: 0.0503718\ttotal: 242ms\tremaining: 232ms\n",
            "23:\tlearn: 0.0475548\ttotal: 251ms\tremaining: 220ms\n",
            "24:\tlearn: 0.0459208\ttotal: 259ms\tremaining: 207ms\n",
            "25:\tlearn: 0.0447111\ttotal: 268ms\tremaining: 196ms\n",
            "26:\tlearn: 0.0443746\ttotal: 277ms\tremaining: 184ms\n",
            "27:\tlearn: 0.0418852\ttotal: 290ms\tremaining: 176ms\n",
            "28:\tlearn: 0.0407047\ttotal: 299ms\tremaining: 165ms\n",
            "29:\tlearn: 0.0368519\ttotal: 307ms\tremaining: 154ms\n",
            "30:\tlearn: 0.0334279\ttotal: 317ms\tremaining: 143ms\n",
            "31:\tlearn: 0.0333184\ttotal: 325ms\tremaining: 132ms\n",
            "32:\tlearn: 0.0307065\ttotal: 334ms\tremaining: 121ms\n",
            "33:\tlearn: 0.0299994\ttotal: 342ms\tremaining: 111ms\n",
            "34:\tlearn: 0.0295010\ttotal: 351ms\tremaining: 100ms\n",
            "35:\tlearn: 0.0288136\ttotal: 359ms\tremaining: 89.8ms\n",
            "36:\tlearn: 0.0285320\ttotal: 368ms\tremaining: 79.5ms\n",
            "37:\tlearn: 0.0275638\ttotal: 377ms\tremaining: 69.4ms\n",
            "38:\tlearn: 0.0260299\ttotal: 386ms\tremaining: 59.4ms\n",
            "39:\tlearn: 0.0247051\ttotal: 395ms\tremaining: 49.3ms\n",
            "40:\tlearn: 0.0246334\ttotal: 404ms\tremaining: 39.4ms\n",
            "41:\tlearn: 0.0236343\ttotal: 413ms\tremaining: 29.5ms\n",
            "42:\tlearn: 0.0229493\ttotal: 422ms\tremaining: 19.6ms\n",
            "43:\tlearn: 0.0227376\ttotal: 430ms\tremaining: 9.78ms\n",
            "44:\tlearn: 0.0226913\ttotal: 439ms\tremaining: 0us\n",
            "0:\tlearn: 0.3431901\ttotal: 14.1ms\tremaining: 620ms\n",
            "1:\tlearn: 0.2192930\ttotal: 23.4ms\tremaining: 503ms\n",
            "2:\tlearn: 0.1731057\ttotal: 32ms\tremaining: 447ms\n",
            "3:\tlearn: 0.1513922\ttotal: 40.6ms\tremaining: 416ms\n",
            "4:\tlearn: 0.1368336\ttotal: 49.5ms\tremaining: 396ms\n",
            "5:\tlearn: 0.1293557\ttotal: 59.8ms\tremaining: 389ms\n",
            "6:\tlearn: 0.1150403\ttotal: 69.8ms\tremaining: 379ms\n",
            "7:\tlearn: 0.1074266\ttotal: 78.8ms\tremaining: 364ms\n",
            "8:\tlearn: 0.1023948\ttotal: 87.7ms\tremaining: 351ms\n",
            "9:\tlearn: 0.0981962\ttotal: 96.2ms\tremaining: 337ms\n",
            "10:\tlearn: 0.0893434\ttotal: 105ms\tremaining: 325ms\n",
            "11:\tlearn: 0.0826279\ttotal: 114ms\tremaining: 312ms\n",
            "12:\tlearn: 0.0792929\ttotal: 122ms\tremaining: 300ms\n",
            "13:\tlearn: 0.0748216\ttotal: 131ms\tremaining: 290ms\n",
            "14:\tlearn: 0.0709660\ttotal: 140ms\tremaining: 279ms\n",
            "15:\tlearn: 0.0679487\ttotal: 148ms\tremaining: 269ms\n",
            "16:\tlearn: 0.0638423\ttotal: 157ms\tremaining: 259ms\n",
            "17:\tlearn: 0.0600235\ttotal: 166ms\tremaining: 250ms\n",
            "18:\tlearn: 0.0567800\ttotal: 175ms\tremaining: 240ms\n",
            "19:\tlearn: 0.0542438\ttotal: 186ms\tremaining: 232ms\n",
            "20:\tlearn: 0.0515795\ttotal: 200ms\tremaining: 229ms\n",
            "21:\tlearn: 0.0490214\ttotal: 209ms\tremaining: 219ms\n",
            "22:\tlearn: 0.0441175\ttotal: 222ms\tremaining: 213ms\n",
            "23:\tlearn: 0.0434470\ttotal: 232ms\tremaining: 203ms\n",
            "24:\tlearn: 0.0429407\ttotal: 241ms\tremaining: 192ms\n",
            "25:\tlearn: 0.0407942\ttotal: 249ms\tremaining: 182ms\n",
            "26:\tlearn: 0.0402757\ttotal: 258ms\tremaining: 172ms\n",
            "27:\tlearn: 0.0377500\ttotal: 267ms\tremaining: 162ms\n",
            "28:\tlearn: 0.0353398\ttotal: 276ms\tremaining: 152ms\n",
            "29:\tlearn: 0.0345122\ttotal: 285ms\tremaining: 143ms\n",
            "30:\tlearn: 0.0333013\ttotal: 294ms\tremaining: 133ms\n",
            "31:\tlearn: 0.0322262\ttotal: 303ms\tremaining: 123ms\n",
            "32:\tlearn: 0.0317857\ttotal: 312ms\tremaining: 113ms\n",
            "33:\tlearn: 0.0306564\ttotal: 321ms\tremaining: 104ms\n",
            "34:\tlearn: 0.0302940\ttotal: 330ms\tremaining: 94.2ms\n",
            "35:\tlearn: 0.0294239\ttotal: 338ms\tremaining: 84.6ms\n",
            "36:\tlearn: 0.0286111\ttotal: 347ms\tremaining: 75.1ms\n",
            "37:\tlearn: 0.0277723\ttotal: 357ms\tremaining: 65.7ms\n",
            "38:\tlearn: 0.0267440\ttotal: 366ms\tremaining: 56.3ms\n",
            "39:\tlearn: 0.0264700\ttotal: 375ms\tremaining: 46.9ms\n",
            "40:\tlearn: 0.0246159\ttotal: 385ms\tremaining: 37.6ms\n",
            "41:\tlearn: 0.0239892\ttotal: 395ms\tremaining: 28.2ms\n",
            "42:\tlearn: 0.0237922\ttotal: 404ms\tremaining: 18.8ms\n",
            "43:\tlearn: 0.0234816\ttotal: 413ms\tremaining: 9.39ms\n",
            "44:\tlearn: 0.0230912\ttotal: 427ms\tremaining: 0us\n",
            "0:\tlearn: 0.3402991\ttotal: 9.53ms\tremaining: 419ms\n",
            "1:\tlearn: 0.2231404\ttotal: 18.2ms\tremaining: 392ms\n",
            "2:\tlearn: 0.1759218\ttotal: 30.2ms\tremaining: 423ms\n",
            "3:\tlearn: 0.1515803\ttotal: 42.5ms\tremaining: 435ms\n",
            "4:\tlearn: 0.1369999\ttotal: 51.9ms\tremaining: 415ms\n",
            "5:\tlearn: 0.1300142\ttotal: 62.2ms\tremaining: 404ms\n",
            "6:\tlearn: 0.1223263\ttotal: 70.8ms\tremaining: 384ms\n",
            "7:\tlearn: 0.1095727\ttotal: 79.5ms\tremaining: 368ms\n",
            "8:\tlearn: 0.1046594\ttotal: 88.3ms\tremaining: 353ms\n",
            "9:\tlearn: 0.1001246\ttotal: 97.6ms\tremaining: 342ms\n",
            "10:\tlearn: 0.0947474\ttotal: 107ms\tremaining: 330ms\n",
            "11:\tlearn: 0.0866883\ttotal: 120ms\tremaining: 331ms\n",
            "12:\tlearn: 0.0845025\ttotal: 131ms\tremaining: 322ms\n",
            "13:\tlearn: 0.0790414\ttotal: 141ms\tremaining: 313ms\n",
            "14:\tlearn: 0.0752014\ttotal: 151ms\tremaining: 302ms\n",
            "15:\tlearn: 0.0720376\ttotal: 165ms\tremaining: 299ms\n",
            "16:\tlearn: 0.0690210\ttotal: 183ms\tremaining: 302ms\n",
            "17:\tlearn: 0.0644226\ttotal: 199ms\tremaining: 299ms\n",
            "18:\tlearn: 0.0605009\ttotal: 211ms\tremaining: 288ms\n",
            "19:\tlearn: 0.0587194\ttotal: 223ms\tremaining: 278ms\n",
            "20:\tlearn: 0.0570225\ttotal: 231ms\tremaining: 264ms\n",
            "21:\tlearn: 0.0546859\ttotal: 240ms\tremaining: 251ms\n",
            "22:\tlearn: 0.0514577\ttotal: 249ms\tremaining: 238ms\n",
            "23:\tlearn: 0.0482000\ttotal: 258ms\tremaining: 226ms\n",
            "24:\tlearn: 0.0467094\ttotal: 267ms\tremaining: 214ms\n",
            "25:\tlearn: 0.0432172\ttotal: 276ms\tremaining: 202ms\n",
            "26:\tlearn: 0.0414340\ttotal: 285ms\tremaining: 190ms\n",
            "27:\tlearn: 0.0386684\ttotal: 294ms\tremaining: 179ms\n",
            "28:\tlearn: 0.0381396\ttotal: 303ms\tremaining: 167ms\n",
            "29:\tlearn: 0.0355582\ttotal: 312ms\tremaining: 156ms\n",
            "30:\tlearn: 0.0346826\ttotal: 321ms\tremaining: 145ms\n",
            "31:\tlearn: 0.0315669\ttotal: 330ms\tremaining: 134ms\n",
            "32:\tlearn: 0.0313656\ttotal: 339ms\tremaining: 123ms\n",
            "33:\tlearn: 0.0303227\ttotal: 347ms\tremaining: 112ms\n",
            "34:\tlearn: 0.0287261\ttotal: 356ms\tremaining: 102ms\n",
            "35:\tlearn: 0.0276237\ttotal: 371ms\tremaining: 92.8ms\n",
            "36:\tlearn: 0.0257261\ttotal: 380ms\tremaining: 82.3ms\n",
            "37:\tlearn: 0.0246158\ttotal: 389ms\tremaining: 71.7ms\n",
            "38:\tlearn: 0.0232443\ttotal: 398ms\tremaining: 61.2ms\n",
            "39:\tlearn: 0.0231279\ttotal: 407ms\tremaining: 50.9ms\n",
            "40:\tlearn: 0.0216461\ttotal: 416ms\tremaining: 40.6ms\n",
            "41:\tlearn: 0.0199874\ttotal: 424ms\tremaining: 30.3ms\n",
            "42:\tlearn: 0.0190831\ttotal: 433ms\tremaining: 20.1ms\n",
            "43:\tlearn: 0.0188735\ttotal: 441ms\tremaining: 10ms\n",
            "44:\tlearn: 0.0185279\ttotal: 450ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2877\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2933\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3098\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.962783  0.752634   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.943366  0.622615   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.922330  0.362789   \n",
            "3                             KNeighborsClassifier()  0.933657  0.526758   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.966019  0.775682   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.953074  0.685916   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.969256  0.799849   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.964401  0.763941   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.959547  0.727335   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.738434   0.923077  0.642857  0.757895     0.994662     0.642857  \n",
            "1  0.616258   0.744186  0.571429  0.646465     0.980427     0.571429  \n",
            "2  0.232616   1.000000  0.142857  0.250000     1.000000     0.142857  \n",
            "3  0.506140   0.727273  0.428571  0.539326     0.983986     0.428571  \n",
            "4  0.756647   0.972973  0.642857  0.774194     0.998221     0.642857  \n",
            "5  0.676229   0.829268  0.607143  0.701031     0.987544     0.607143  \n",
            "6  0.791683   0.930233  0.714286  0.808081     0.994662     0.714286  \n",
            "7  0.747455   0.947368  0.642857  0.765957     0.996441     0.642857  \n",
            "8  0.698866   0.969697  0.571429  0.719101     0.998221     0.571429  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}