{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVkpw5b_DPw6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vx95u-dFsBx",
        "outputId": "987f9116-fc54-47c1-c1e7-66b71e0a121a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3C6HBGyFs6G"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAXBHqfFw9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5rkGmusF1Qs"
      },
      "outputs": [],
      "source": [
        "estimator = [('RF', RandomForestClassifier(n_estimators = 450, max_depth = 9)), ('XGB', XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1)),\n",
        "             ('Cat', CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35)), ('LGBM', LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50)),\n",
        "             ('ETC', ExtraTreesClassifier(n_estimators = 450, max_depth = 7)),('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
        "             ('ADB', AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50))]\n",
        "Stacking = StackingClassifier( estimators=estimator, final_estimator= XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X7dcTDneAxU"
      },
      "source": [
        "# **FastText**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gY63zhgSJKK"
      },
      "source": [
        "**Imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJhc0y_av66D"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcmhpOeZv7yj",
        "outputId": "a627c856-9616-4783-f644-d5653cf0e837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.947773  0.627461   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.935628  0.528320   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.931579  0.467813   \n",
            "3                             KNeighborsClassifier()  0.938057  0.535662   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.982996  0.891603   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.981377  0.884385   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983401  0.894370   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.982996  0.891687   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.985830  0.910625   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.564978   1.000000  0.416290  0.587859     1.000000     0.416290  \n",
            "1  0.499818   0.762712  0.407240  0.530973     0.987550     0.407240  \n",
            "2  0.359107   1.000000  0.235294  0.380952     1.000000     0.235294  \n",
            "3  0.456981   0.959459  0.321267  0.481356     0.998666     0.321267  \n",
            "4  0.886367   0.994475  0.814480  0.895522     0.999555     0.814480  \n",
            "5  0.884284   0.906977  0.882353  0.894495     0.991107     0.882353  \n",
            "6  0.888825   1.000000  0.814480  0.897756     1.000000     0.814480  \n",
            "7  0.885860   1.000000  0.809955  0.895000     1.000000     0.809955  \n",
            "8  0.909526   0.960396  0.877828  0.917258     0.996443     0.877828  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total metrics(FT-CV).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io3c-HQQVWnW"
      },
      "source": [
        "**ADASYN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tasr1hZ24x-S"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoADQ0q6VcRQ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN(random_state=42)\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4mxq7S1Vstf",
        "outputId": "9c9ebd14-dcbd-470a-e555-ac513761e6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.987033  0.974390   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.830315  0.660917   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.788732  0.636056   \n",
            "3                             KNeighborsClassifier()  0.835010  0.710252   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989269  0.978538   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.957299  0.915184   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.997317  0.994635   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996647  0.993295   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.997988  0.995981   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.974062   1.000000  0.973921  0.986788     1.000000     0.973921  \n",
            "1  0.660672   0.820569  0.843076  0.831670     0.817697     0.843076  \n",
            "2  0.576453   0.999219  0.575540  0.730385     0.999555     0.575540  \n",
            "3  0.670617   0.750844  1.000000  0.857694     0.671854     1.000000  \n",
            "4  0.978537   0.989649  0.988759  0.989204     0.989773     0.988759  \n",
            "5  0.914613   0.941381  0.974820  0.957809     0.939973     0.974820  \n",
            "6  0.994634   0.997750  0.996853  0.997301     0.997777     0.996853  \n",
            "7  0.993293   0.997747  0.995504  0.996624     0.997777     0.995504  \n",
            "8  0.995976   0.996414  0.999550  0.997980     0.996443     0.999550  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(ADASYN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgOf9Y5O5f8T"
      },
      "source": [
        "**SMOTEN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf5G-CAj45RF"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUJ4mLrJ5lZP"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DI8ytRS5w0K",
        "outputId": "8eddce73-814f-4bab-cb1e-eacaed39f723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.977546  0.956056   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.931525  0.863281   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.937750  0.882365   \n",
            "3                             KNeighborsClassifier()  0.975100  0.950322   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.994664  0.989360   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.991774  0.983565   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.995109  0.990243   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995331  0.990706   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993997  0.988023   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.955091   1.000000  0.955091  0.977030     1.000000     0.955091  \n",
            "1  0.863050   0.941739  0.919964  0.930724     0.943086     0.919964  \n",
            "2  0.875500   1.000000  0.875500  0.933618     1.000000     0.875500  \n",
            "3  0.950200   0.982829  0.967096  0.974899     0.983104     0.967096  \n",
            "4  0.989329   0.998655  0.990663  0.994643     0.998666     0.990663  \n",
            "5  0.983548   0.988948  0.994664  0.991798     0.988884     0.994664  \n",
            "6  0.990218   0.998657  0.991552  0.995091     0.998666     0.991552  \n",
            "7  0.990663   1.000000  0.990663  0.995309     1.000000     0.990663  \n",
            "8  0.987995   0.997760  0.990218  0.993975     0.997777     0.990218  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(SMOTEN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12nyQiuNrIP"
      },
      "source": [
        "**SMOTETomek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxR-J65q46ZN"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qarUdpJdNsUX"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek(random_state=42)\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DT1z0BbOKbg",
        "outputId": "ce23dd9e-16e7-472c-dd82-18524b0f6601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.985549  0.971479   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.805691  0.612439   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.819031  0.684467   \n",
            "3                             KNeighborsClassifier()  0.841263  0.719761   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.991774  0.983553   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960427  0.921326   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.996221  0.992444   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996888  0.993777   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.998666  0.997332   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.971098   0.999543  0.971543  0.985344     0.999555     0.971543  \n",
            "1  0.611383   0.824752  0.776345  0.799817     0.835038     0.776345  \n",
            "2  0.638061   1.000000  0.638061  0.779045     1.000000     0.638061  \n",
            "3  0.682526   0.759028  1.000000  0.863008     0.682526     1.000000  \n",
            "4  0.983548   0.990248  0.993330  0.991787     0.990218     0.993330  \n",
            "5  0.920854   0.946144  0.976434  0.961050     0.944420     0.976434  \n",
            "6  0.992441   0.997326  0.995109  0.996216     0.997332     0.995109  \n",
            "7  0.993775   0.997773  0.995998  0.996885     0.997777     0.995998  \n",
            "8  0.997332   0.998666  0.998666  0.998666     0.998666     0.998666  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"FastText-CV(SMOTETomek.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WqNyX8B2AZF"
      },
      "source": [
        "**NearMiss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK61E1Tc47js"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrAY5z3h2FBj"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiYfdLVM2HfO",
        "outputId": "724b599c-cfdc-40fa-b666-4cf57ddcf27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.984163  0.968574   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.832579  0.666908   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932127  0.871275   \n",
            "3                             KNeighborsClassifier()  0.685520  0.472860   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.986425  0.973209   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.968326  0.936690   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.986425  0.972891   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.981900  0.963801   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988688  0.977466   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.968326   0.995370  0.972851  0.983982     0.995475     0.972851  \n",
            "1  0.665158   0.858537  0.796380  0.826291     0.868778     0.796380  \n",
            "2  0.864253   0.994819  0.868778  0.927536     0.995475     0.868778  \n",
            "3  0.371041   0.988095  0.375566  0.544262     0.995475     0.375566  \n",
            "4  0.972851   1.000000  0.972851  0.986239     1.000000     0.972851  \n",
            "5  0.936652   0.964126  0.972851  0.968468     0.963801     0.972851  \n",
            "6  0.972851   0.990868  0.981900  0.986364     0.990950     0.981900  \n",
            "7  0.963801   0.981900  0.981900  0.981900     0.981900     0.981900  \n",
            "8  0.977376   0.995413  0.981900  0.988610     0.995475     0.981900  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(NearMiss)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Jn5FNj2PZJ"
      },
      "source": [
        "**TomekLinks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgmEhKfa48cO"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5R3UG3j2VM7"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZUvntCL2YS-",
        "outputId": "ac906829-c4f7-46b3-b52c-691dd8d0616c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.947368  0.623910   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.936032  0.533442   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.931984  0.472387   \n",
            "3                             KNeighborsClassifier()  0.938057  0.535662   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.982996  0.891603   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.981377  0.884385   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983401  0.894370   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.982996  0.891687   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.986235  0.913151   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.560389   1.000000  0.411765  0.583333     1.000000     0.411765  \n",
            "1  0.506785   0.760331  0.416290  0.538012     0.987105     0.416290  \n",
            "2  0.364877   1.000000  0.239819  0.386861     1.000000     0.239819  \n",
            "3  0.456981   0.959459  0.321267  0.481356     0.998666     0.321267  \n",
            "4  0.886367   0.994475  0.814480  0.895522     0.999555     0.814480  \n",
            "5  0.884284   0.906977  0.882353  0.894495     0.991107     0.882353  \n",
            "6  0.888825   1.000000  0.814480  0.897756     1.000000     0.814480  \n",
            "7  0.885860   1.000000  0.809955  0.895000     1.000000     0.809955  \n",
            "8  0.911924   0.965174  0.877828  0.919431     0.996888     0.877828  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-CV(TomekLinks)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raDXKWeOVnJ2"
      },
      "source": [
        "**Ind-Test**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ts = pd.read_csv('/content/FT-Tr.csv')\n",
        "columns = df_ts.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_ts[columns]\n",
        "ytrain = df_ts[target]"
      ],
      "metadata": {
        "id": "gGZvou65EFyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEkq2vHzP-j2"
      },
      "outputs": [],
      "source": [
        "df_ts = pd.read_csv('/content/FT-Ind.csv')\n",
        "columns = df_ts.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_ts[columns]\n",
        "ytest = df_ts[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ikpgbGZQEzl",
        "outputId": "c45da38d-29c1-4af0-d7cc-07c7d2fcd494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.5659424\ttotal: 134ms\tremaining: 5.9s\n",
            "1:\tlearn: 0.4713996\ttotal: 190ms\tremaining: 4.08s\n",
            "2:\tlearn: 0.3960924\ttotal: 248ms\tremaining: 3.46s\n",
            "3:\tlearn: 0.3398098\ttotal: 304ms\tremaining: 3.12s\n",
            "4:\tlearn: 0.2898371\ttotal: 364ms\tremaining: 2.92s\n",
            "5:\tlearn: 0.2510332\ttotal: 420ms\tremaining: 2.73s\n",
            "6:\tlearn: 0.2095736\ttotal: 476ms\tremaining: 2.58s\n",
            "7:\tlearn: 0.1811296\ttotal: 530ms\tremaining: 2.45s\n",
            "8:\tlearn: 0.1602000\ttotal: 588ms\tremaining: 2.35s\n",
            "9:\tlearn: 0.1410579\ttotal: 644ms\tremaining: 2.25s\n",
            "10:\tlearn: 0.1237693\ttotal: 703ms\tremaining: 2.17s\n",
            "11:\tlearn: 0.1100287\ttotal: 766ms\tremaining: 2.11s\n",
            "12:\tlearn: 0.0976714\ttotal: 838ms\tremaining: 2.06s\n",
            "13:\tlearn: 0.0896341\ttotal: 893ms\tremaining: 1.98s\n",
            "14:\tlearn: 0.0780015\ttotal: 949ms\tremaining: 1.9s\n",
            "15:\tlearn: 0.0708234\ttotal: 1s\tremaining: 1.82s\n",
            "16:\tlearn: 0.0639043\ttotal: 1.07s\tremaining: 1.76s\n",
            "17:\tlearn: 0.0577000\ttotal: 1.12s\tremaining: 1.68s\n",
            "18:\tlearn: 0.0519515\ttotal: 1.18s\tremaining: 1.61s\n",
            "19:\tlearn: 0.0466108\ttotal: 1.23s\tremaining: 1.54s\n",
            "20:\tlearn: 0.0418480\ttotal: 1.29s\tremaining: 1.47s\n",
            "21:\tlearn: 0.0380527\ttotal: 1.34s\tremaining: 1.41s\n",
            "22:\tlearn: 0.0342117\ttotal: 1.4s\tremaining: 1.34s\n",
            "23:\tlearn: 0.0301295\ttotal: 1.46s\tremaining: 1.27s\n",
            "24:\tlearn: 0.0279103\ttotal: 1.51s\tremaining: 1.21s\n",
            "25:\tlearn: 0.0245330\ttotal: 1.57s\tremaining: 1.15s\n",
            "26:\tlearn: 0.0222610\ttotal: 1.63s\tremaining: 1.09s\n",
            "27:\tlearn: 0.0197147\ttotal: 1.69s\tremaining: 1.03s\n",
            "28:\tlearn: 0.0183356\ttotal: 1.75s\tremaining: 966ms\n",
            "29:\tlearn: 0.0165088\ttotal: 1.81s\tremaining: 907ms\n",
            "30:\tlearn: 0.0151059\ttotal: 1.89s\tremaining: 852ms\n",
            "31:\tlearn: 0.0137220\ttotal: 1.95s\tremaining: 790ms\n",
            "32:\tlearn: 0.0125582\ttotal: 2s\tremaining: 728ms\n",
            "33:\tlearn: 0.0115120\ttotal: 2.06s\tremaining: 666ms\n",
            "34:\tlearn: 0.0105818\ttotal: 2.12s\tremaining: 605ms\n",
            "35:\tlearn: 0.0098281\ttotal: 2.17s\tremaining: 544ms\n",
            "36:\tlearn: 0.0090095\ttotal: 2.23s\tremaining: 483ms\n",
            "37:\tlearn: 0.0082649\ttotal: 2.29s\tremaining: 422ms\n",
            "38:\tlearn: 0.0077145\ttotal: 2.34s\tremaining: 361ms\n",
            "39:\tlearn: 0.0072016\ttotal: 2.4s\tremaining: 300ms\n",
            "40:\tlearn: 0.0067475\ttotal: 2.46s\tremaining: 240ms\n",
            "41:\tlearn: 0.0063943\ttotal: 2.51s\tremaining: 179ms\n",
            "42:\tlearn: 0.0061016\ttotal: 2.57s\tremaining: 119ms\n",
            "43:\tlearn: 0.0056535\ttotal: 2.62s\tremaining: 59.6ms\n",
            "44:\tlearn: 0.0053571\ttotal: 2.68s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2224, number of negative: 2249\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008877 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32637\n",
            "[LightGBM] [Info] Number of data points in the train set: 4473, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497205 -> initscore=-0.011178\n",
            "[LightGBM] [Info] Start training from score -0.011178\n",
            "0:\tlearn: 0.5659424\ttotal: 76.1ms\tremaining: 3.35s\n",
            "1:\tlearn: 0.4713996\ttotal: 134ms\tremaining: 2.89s\n",
            "2:\tlearn: 0.3960924\ttotal: 194ms\tremaining: 2.71s\n",
            "3:\tlearn: 0.3398098\ttotal: 251ms\tremaining: 2.57s\n",
            "4:\tlearn: 0.2898371\ttotal: 314ms\tremaining: 2.51s\n",
            "5:\tlearn: 0.2510332\ttotal: 372ms\tremaining: 2.42s\n",
            "6:\tlearn: 0.2095736\ttotal: 433ms\tremaining: 2.35s\n",
            "7:\tlearn: 0.1811296\ttotal: 493ms\tremaining: 2.28s\n",
            "8:\tlearn: 0.1602000\ttotal: 574ms\tremaining: 2.29s\n",
            "9:\tlearn: 0.1410579\ttotal: 633ms\tremaining: 2.22s\n",
            "10:\tlearn: 0.1237693\ttotal: 693ms\tremaining: 2.14s\n",
            "11:\tlearn: 0.1100287\ttotal: 750ms\tremaining: 2.06s\n",
            "12:\tlearn: 0.0976714\ttotal: 811ms\tremaining: 2s\n",
            "13:\tlearn: 0.0896341\ttotal: 870ms\tremaining: 1.93s\n",
            "14:\tlearn: 0.0780015\ttotal: 927ms\tremaining: 1.85s\n",
            "15:\tlearn: 0.0708234\ttotal: 984ms\tremaining: 1.78s\n",
            "16:\tlearn: 0.0639043\ttotal: 1.04s\tremaining: 1.72s\n",
            "17:\tlearn: 0.0577000\ttotal: 1.1s\tremaining: 1.65s\n",
            "18:\tlearn: 0.0519515\ttotal: 1.17s\tremaining: 1.59s\n",
            "19:\tlearn: 0.0466108\ttotal: 1.22s\tremaining: 1.53s\n",
            "20:\tlearn: 0.0418480\ttotal: 1.28s\tremaining: 1.47s\n",
            "21:\tlearn: 0.0380527\ttotal: 1.34s\tremaining: 1.4s\n",
            "22:\tlearn: 0.0342117\ttotal: 1.4s\tremaining: 1.34s\n",
            "23:\tlearn: 0.0301295\ttotal: 1.46s\tremaining: 1.28s\n",
            "24:\tlearn: 0.0279103\ttotal: 1.52s\tremaining: 1.21s\n",
            "25:\tlearn: 0.0245330\ttotal: 1.58s\tremaining: 1.16s\n",
            "26:\tlearn: 0.0222610\ttotal: 1.65s\tremaining: 1.1s\n",
            "27:\tlearn: 0.0197147\ttotal: 1.71s\tremaining: 1.03s\n",
            "28:\tlearn: 0.0183356\ttotal: 1.76s\tremaining: 974ms\n",
            "29:\tlearn: 0.0165088\ttotal: 1.82s\tremaining: 911ms\n",
            "30:\tlearn: 0.0151059\ttotal: 1.88s\tremaining: 850ms\n",
            "31:\tlearn: 0.0137220\ttotal: 1.94s\tremaining: 789ms\n",
            "32:\tlearn: 0.0125582\ttotal: 2s\tremaining: 727ms\n",
            "33:\tlearn: 0.0115120\ttotal: 2.06s\tremaining: 665ms\n",
            "34:\tlearn: 0.0105818\ttotal: 2.11s\tremaining: 604ms\n",
            "35:\tlearn: 0.0098281\ttotal: 2.17s\tremaining: 542ms\n",
            "36:\tlearn: 0.0090095\ttotal: 2.23s\tremaining: 482ms\n",
            "37:\tlearn: 0.0082649\ttotal: 2.29s\tremaining: 421ms\n",
            "38:\tlearn: 0.0077145\ttotal: 2.34s\tremaining: 360ms\n",
            "39:\tlearn: 0.0072016\ttotal: 2.4s\tremaining: 300ms\n",
            "40:\tlearn: 0.0067475\ttotal: 2.46s\tremaining: 240ms\n",
            "41:\tlearn: 0.0063943\ttotal: 2.54s\tremaining: 181ms\n",
            "42:\tlearn: 0.0061016\ttotal: 2.65s\tremaining: 123ms\n",
            "43:\tlearn: 0.0056535\ttotal: 2.74s\tremaining: 62.3ms\n",
            "44:\tlearn: 0.0053571\ttotal: 2.83s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2224, number of negative: 2249\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011487 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32637\n",
            "[LightGBM] [Info] Number of data points in the train set: 4473, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497205 -> initscore=-0.011178\n",
            "[LightGBM] [Info] Start training from score -0.011178\n",
            "0:\tlearn: 0.5757716\ttotal: 60.3ms\tremaining: 2.65s\n",
            "1:\tlearn: 0.4807482\ttotal: 135ms\tremaining: 2.91s\n",
            "2:\tlearn: 0.4015769\ttotal: 191ms\tremaining: 2.68s\n",
            "3:\tlearn: 0.3446290\ttotal: 249ms\tremaining: 2.55s\n",
            "4:\tlearn: 0.2845920\ttotal: 311ms\tremaining: 2.48s\n",
            "5:\tlearn: 0.2462170\ttotal: 366ms\tremaining: 2.38s\n",
            "6:\tlearn: 0.2174718\ttotal: 427ms\tremaining: 2.32s\n",
            "7:\tlearn: 0.1917029\ttotal: 486ms\tremaining: 2.25s\n",
            "8:\tlearn: 0.1666980\ttotal: 544ms\tremaining: 2.18s\n",
            "9:\tlearn: 0.1502195\ttotal: 599ms\tremaining: 2.1s\n",
            "10:\tlearn: 0.1338056\ttotal: 655ms\tremaining: 2.02s\n",
            "11:\tlearn: 0.1164244\ttotal: 715ms\tremaining: 1.97s\n",
            "12:\tlearn: 0.1055491\ttotal: 775ms\tremaining: 1.91s\n",
            "13:\tlearn: 0.0926007\ttotal: 833ms\tremaining: 1.84s\n",
            "14:\tlearn: 0.0799184\ttotal: 888ms\tremaining: 1.77s\n",
            "15:\tlearn: 0.0714646\ttotal: 946ms\tremaining: 1.71s\n",
            "16:\tlearn: 0.0628258\ttotal: 1s\tremaining: 1.66s\n",
            "17:\tlearn: 0.0570287\ttotal: 1.06s\tremaining: 1.59s\n",
            "18:\tlearn: 0.0515208\ttotal: 1.12s\tremaining: 1.54s\n",
            "19:\tlearn: 0.0458840\ttotal: 1.2s\tremaining: 1.5s\n",
            "20:\tlearn: 0.0408204\ttotal: 1.26s\tremaining: 1.44s\n",
            "21:\tlearn: 0.0373247\ttotal: 1.31s\tremaining: 1.37s\n",
            "22:\tlearn: 0.0333561\ttotal: 1.37s\tremaining: 1.31s\n",
            "23:\tlearn: 0.0294865\ttotal: 1.43s\tremaining: 1.25s\n",
            "24:\tlearn: 0.0273371\ttotal: 1.49s\tremaining: 1.19s\n",
            "25:\tlearn: 0.0246873\ttotal: 1.55s\tremaining: 1.13s\n",
            "26:\tlearn: 0.0226163\ttotal: 1.61s\tremaining: 1.07s\n",
            "27:\tlearn: 0.0206529\ttotal: 1.67s\tremaining: 1.01s\n",
            "28:\tlearn: 0.0188924\ttotal: 1.73s\tremaining: 954ms\n",
            "29:\tlearn: 0.0170702\ttotal: 1.79s\tremaining: 896ms\n",
            "30:\tlearn: 0.0159255\ttotal: 1.85s\tremaining: 835ms\n",
            "31:\tlearn: 0.0143986\ttotal: 1.91s\tremaining: 774ms\n",
            "32:\tlearn: 0.0133420\ttotal: 1.97s\tremaining: 716ms\n",
            "33:\tlearn: 0.0122011\ttotal: 2.02s\tremaining: 655ms\n",
            "34:\tlearn: 0.0112440\ttotal: 2.08s\tremaining: 595ms\n",
            "35:\tlearn: 0.0103774\ttotal: 2.14s\tremaining: 535ms\n",
            "36:\tlearn: 0.0096636\ttotal: 2.22s\tremaining: 480ms\n",
            "37:\tlearn: 0.0089741\ttotal: 2.28s\tremaining: 420ms\n",
            "38:\tlearn: 0.0083823\ttotal: 2.34s\tremaining: 360ms\n",
            "39:\tlearn: 0.0078311\ttotal: 2.39s\tremaining: 299ms\n",
            "40:\tlearn: 0.0073349\ttotal: 2.45s\tremaining: 239ms\n",
            "41:\tlearn: 0.0069558\ttotal: 2.51s\tremaining: 179ms\n",
            "42:\tlearn: 0.0064475\ttotal: 2.57s\tremaining: 119ms\n",
            "43:\tlearn: 0.0060177\ttotal: 2.62s\tremaining: 59.6ms\n",
            "44:\tlearn: 0.0056793\ttotal: 2.68s\tremaining: 0us\n",
            "0:\tlearn: 0.5706176\ttotal: 56.8ms\tremaining: 2.5s\n",
            "1:\tlearn: 0.4943381\ttotal: 116ms\tremaining: 2.49s\n",
            "2:\tlearn: 0.3995481\ttotal: 174ms\tremaining: 2.43s\n",
            "3:\tlearn: 0.3399414\ttotal: 231ms\tremaining: 2.37s\n",
            "4:\tlearn: 0.2840422\ttotal: 289ms\tremaining: 2.31s\n",
            "5:\tlearn: 0.2403693\ttotal: 359ms\tremaining: 2.33s\n",
            "6:\tlearn: 0.2122500\ttotal: 427ms\tremaining: 2.32s\n",
            "7:\tlearn: 0.1864533\ttotal: 497ms\tremaining: 2.3s\n",
            "8:\tlearn: 0.1544220\ttotal: 555ms\tremaining: 2.22s\n",
            "9:\tlearn: 0.1385412\ttotal: 613ms\tremaining: 2.15s\n",
            "10:\tlearn: 0.1223444\ttotal: 671ms\tremaining: 2.07s\n",
            "11:\tlearn: 0.1096203\ttotal: 728ms\tremaining: 2s\n",
            "12:\tlearn: 0.0974738\ttotal: 784ms\tremaining: 1.93s\n",
            "13:\tlearn: 0.0861075\ttotal: 845ms\tremaining: 1.87s\n",
            "14:\tlearn: 0.0767425\ttotal: 909ms\tremaining: 1.82s\n",
            "15:\tlearn: 0.0679647\ttotal: 971ms\tremaining: 1.76s\n",
            "16:\tlearn: 0.0623500\ttotal: 1.03s\tremaining: 1.7s\n",
            "17:\tlearn: 0.0553740\ttotal: 1.09s\tremaining: 1.64s\n",
            "18:\tlearn: 0.0497516\ttotal: 1.16s\tremaining: 1.59s\n",
            "19:\tlearn: 0.0445823\ttotal: 1.23s\tremaining: 1.53s\n",
            "20:\tlearn: 0.0394489\ttotal: 1.28s\tremaining: 1.46s\n",
            "21:\tlearn: 0.0355044\ttotal: 1.35s\tremaining: 1.41s\n",
            "22:\tlearn: 0.0326773\ttotal: 1.47s\tremaining: 1.4s\n",
            "23:\tlearn: 0.0292035\ttotal: 1.59s\tremaining: 1.39s\n",
            "24:\tlearn: 0.0258511\ttotal: 1.69s\tremaining: 1.35s\n",
            "25:\tlearn: 0.0236354\ttotal: 1.8s\tremaining: 1.32s\n",
            "26:\tlearn: 0.0213013\ttotal: 1.9s\tremaining: 1.27s\n",
            "27:\tlearn: 0.0191862\ttotal: 2.03s\tremaining: 1.23s\n",
            "28:\tlearn: 0.0175568\ttotal: 2.15s\tremaining: 1.19s\n",
            "29:\tlearn: 0.0161044\ttotal: 2.27s\tremaining: 1.14s\n",
            "30:\tlearn: 0.0148254\ttotal: 2.39s\tremaining: 1.08s\n",
            "31:\tlearn: 0.0136812\ttotal: 2.5s\tremaining: 1.01s\n",
            "32:\tlearn: 0.0126865\ttotal: 2.61s\tremaining: 951ms\n",
            "33:\tlearn: 0.0116260\ttotal: 2.73s\tremaining: 884ms\n",
            "34:\tlearn: 0.0108079\ttotal: 2.85s\tremaining: 813ms\n",
            "35:\tlearn: 0.0102040\ttotal: 3.06s\tremaining: 764ms\n",
            "36:\tlearn: 0.0094821\ttotal: 3.34s\tremaining: 722ms\n",
            "37:\tlearn: 0.0088569\ttotal: 3.68s\tremaining: 678ms\n",
            "38:\tlearn: 0.0083200\ttotal: 3.94s\tremaining: 606ms\n",
            "39:\tlearn: 0.0077888\ttotal: 4.08s\tremaining: 510ms\n",
            "40:\tlearn: 0.0072254\ttotal: 4.18s\tremaining: 408ms\n",
            "41:\tlearn: 0.0067433\ttotal: 4.29s\tremaining: 306ms\n",
            "42:\tlearn: 0.0064418\ttotal: 4.39s\tremaining: 204ms\n",
            "43:\tlearn: 0.0060371\ttotal: 4.45s\tremaining: 101ms\n",
            "44:\tlearn: 0.0057374\ttotal: 4.5s\tremaining: 0us\n",
            "0:\tlearn: 0.5877511\ttotal: 55.8ms\tremaining: 2.46s\n",
            "1:\tlearn: 0.5021761\ttotal: 140ms\tremaining: 3s\n",
            "2:\tlearn: 0.4160948\ttotal: 196ms\tremaining: 2.75s\n",
            "3:\tlearn: 0.3428848\ttotal: 253ms\tremaining: 2.59s\n",
            "4:\tlearn: 0.2832478\ttotal: 318ms\tremaining: 2.54s\n",
            "5:\tlearn: 0.2399362\ttotal: 378ms\tremaining: 2.45s\n",
            "6:\tlearn: 0.2119485\ttotal: 435ms\tremaining: 2.36s\n",
            "7:\tlearn: 0.1789293\ttotal: 491ms\tremaining: 2.27s\n",
            "8:\tlearn: 0.1588291\ttotal: 552ms\tremaining: 2.21s\n",
            "9:\tlearn: 0.1424038\ttotal: 611ms\tremaining: 2.14s\n",
            "10:\tlearn: 0.1242521\ttotal: 667ms\tremaining: 2.06s\n",
            "11:\tlearn: 0.1096228\ttotal: 725ms\tremaining: 1.99s\n",
            "12:\tlearn: 0.0994220\ttotal: 787ms\tremaining: 1.94s\n",
            "13:\tlearn: 0.0879103\ttotal: 852ms\tremaining: 1.89s\n",
            "14:\tlearn: 0.0792002\ttotal: 909ms\tremaining: 1.82s\n",
            "15:\tlearn: 0.0713359\ttotal: 964ms\tremaining: 1.75s\n",
            "16:\tlearn: 0.0642725\ttotal: 1.02s\tremaining: 1.68s\n",
            "17:\tlearn: 0.0567897\ttotal: 1.08s\tremaining: 1.62s\n",
            "18:\tlearn: 0.0513323\ttotal: 1.14s\tremaining: 1.56s\n",
            "19:\tlearn: 0.0467233\ttotal: 1.21s\tremaining: 1.51s\n",
            "20:\tlearn: 0.0416855\ttotal: 1.27s\tremaining: 1.46s\n",
            "21:\tlearn: 0.0370685\ttotal: 1.34s\tremaining: 1.4s\n",
            "22:\tlearn: 0.0336224\ttotal: 1.39s\tremaining: 1.33s\n",
            "23:\tlearn: 0.0307495\ttotal: 1.45s\tremaining: 1.27s\n",
            "24:\tlearn: 0.0285118\ttotal: 1.51s\tremaining: 1.21s\n",
            "25:\tlearn: 0.0259927\ttotal: 1.56s\tremaining: 1.14s\n",
            "26:\tlearn: 0.0229841\ttotal: 1.62s\tremaining: 1.08s\n",
            "27:\tlearn: 0.0212838\ttotal: 1.68s\tremaining: 1.02s\n",
            "28:\tlearn: 0.0191792\ttotal: 1.74s\tremaining: 960ms\n",
            "29:\tlearn: 0.0169258\ttotal: 1.8s\tremaining: 899ms\n",
            "30:\tlearn: 0.0157520\ttotal: 1.85s\tremaining: 838ms\n",
            "31:\tlearn: 0.0143532\ttotal: 1.91s\tremaining: 777ms\n",
            "32:\tlearn: 0.0132797\ttotal: 1.97s\tremaining: 716ms\n",
            "33:\tlearn: 0.0123385\ttotal: 2.02s\tremaining: 655ms\n",
            "34:\tlearn: 0.0112745\ttotal: 2.08s\tremaining: 595ms\n",
            "35:\tlearn: 0.0105176\ttotal: 2.14s\tremaining: 534ms\n",
            "36:\tlearn: 0.0095990\ttotal: 2.21s\tremaining: 478ms\n",
            "37:\tlearn: 0.0088231\ttotal: 2.28s\tremaining: 419ms\n",
            "38:\tlearn: 0.0081512\ttotal: 2.34s\tremaining: 360ms\n",
            "39:\tlearn: 0.0075737\ttotal: 2.39s\tremaining: 299ms\n",
            "40:\tlearn: 0.0069996\ttotal: 2.45s\tremaining: 239ms\n",
            "41:\tlearn: 0.0066005\ttotal: 2.51s\tremaining: 180ms\n",
            "42:\tlearn: 0.0062391\ttotal: 2.57s\tremaining: 120ms\n",
            "43:\tlearn: 0.0058429\ttotal: 2.63s\tremaining: 59.8ms\n",
            "44:\tlearn: 0.0054895\ttotal: 2.69s\tremaining: 0us\n",
            "0:\tlearn: 0.5530888\ttotal: 64.5ms\tremaining: 2.84s\n",
            "1:\tlearn: 0.4614118\ttotal: 123ms\tremaining: 2.64s\n",
            "2:\tlearn: 0.3791631\ttotal: 182ms\tremaining: 2.54s\n",
            "3:\tlearn: 0.3225305\ttotal: 239ms\tremaining: 2.45s\n",
            "4:\tlearn: 0.2817934\ttotal: 296ms\tremaining: 2.37s\n",
            "5:\tlearn: 0.2368430\ttotal: 358ms\tremaining: 2.32s\n",
            "6:\tlearn: 0.2064441\ttotal: 415ms\tremaining: 2.25s\n",
            "7:\tlearn: 0.1754212\ttotal: 493ms\tremaining: 2.28s\n",
            "8:\tlearn: 0.1527993\ttotal: 564ms\tremaining: 2.25s\n",
            "9:\tlearn: 0.1387541\ttotal: 625ms\tremaining: 2.19s\n",
            "10:\tlearn: 0.1222180\ttotal: 682ms\tremaining: 2.11s\n",
            "11:\tlearn: 0.1088613\ttotal: 742ms\tremaining: 2.04s\n",
            "12:\tlearn: 0.0940397\ttotal: 803ms\tremaining: 1.98s\n",
            "13:\tlearn: 0.0852003\ttotal: 858ms\tremaining: 1.9s\n",
            "14:\tlearn: 0.0757152\ttotal: 916ms\tremaining: 1.83s\n",
            "15:\tlearn: 0.0664674\ttotal: 976ms\tremaining: 1.77s\n",
            "16:\tlearn: 0.0577379\ttotal: 1.04s\tremaining: 1.71s\n",
            "17:\tlearn: 0.0525807\ttotal: 1.1s\tremaining: 1.65s\n",
            "18:\tlearn: 0.0458991\ttotal: 1.16s\tremaining: 1.58s\n",
            "19:\tlearn: 0.0432406\ttotal: 1.22s\tremaining: 1.52s\n",
            "20:\tlearn: 0.0388196\ttotal: 1.28s\tremaining: 1.46s\n",
            "21:\tlearn: 0.0345873\ttotal: 1.34s\tremaining: 1.4s\n",
            "22:\tlearn: 0.0315717\ttotal: 1.39s\tremaining: 1.33s\n",
            "23:\tlearn: 0.0283476\ttotal: 1.45s\tremaining: 1.27s\n",
            "24:\tlearn: 0.0264374\ttotal: 1.52s\tremaining: 1.22s\n",
            "25:\tlearn: 0.0236175\ttotal: 1.59s\tremaining: 1.16s\n",
            "26:\tlearn: 0.0213479\ttotal: 1.65s\tremaining: 1.1s\n",
            "27:\tlearn: 0.0193054\ttotal: 1.7s\tremaining: 1.03s\n",
            "28:\tlearn: 0.0179858\ttotal: 1.76s\tremaining: 974ms\n",
            "29:\tlearn: 0.0166976\ttotal: 1.82s\tremaining: 911ms\n",
            "30:\tlearn: 0.0153781\ttotal: 1.88s\tremaining: 849ms\n",
            "31:\tlearn: 0.0139925\ttotal: 1.94s\tremaining: 788ms\n",
            "32:\tlearn: 0.0128542\ttotal: 2s\tremaining: 729ms\n",
            "33:\tlearn: 0.0117935\ttotal: 2.06s\tremaining: 666ms\n",
            "34:\tlearn: 0.0107843\ttotal: 2.12s\tremaining: 605ms\n",
            "35:\tlearn: 0.0098928\ttotal: 2.18s\tremaining: 545ms\n",
            "36:\tlearn: 0.0090924\ttotal: 2.24s\tremaining: 484ms\n",
            "37:\tlearn: 0.0084273\ttotal: 2.3s\tremaining: 423ms\n",
            "38:\tlearn: 0.0079318\ttotal: 2.36s\tremaining: 363ms\n",
            "39:\tlearn: 0.0074424\ttotal: 2.42s\tremaining: 303ms\n",
            "40:\tlearn: 0.0069568\ttotal: 2.49s\tremaining: 243ms\n",
            "41:\tlearn: 0.0066059\ttotal: 2.56s\tremaining: 183ms\n",
            "42:\tlearn: 0.0062052\ttotal: 2.64s\tremaining: 123ms\n",
            "43:\tlearn: 0.0058015\ttotal: 2.7s\tremaining: 61.4ms\n",
            "44:\tlearn: 0.0054479\ttotal: 2.78s\tremaining: 0us\n",
            "0:\tlearn: 0.5625130\ttotal: 72.1ms\tremaining: 3.17s\n",
            "1:\tlearn: 0.4895480\ttotal: 139ms\tremaining: 2.99s\n",
            "2:\tlearn: 0.4125486\ttotal: 203ms\tremaining: 2.84s\n",
            "3:\tlearn: 0.3493795\ttotal: 265ms\tremaining: 2.71s\n",
            "4:\tlearn: 0.2997002\ttotal: 337ms\tremaining: 2.69s\n",
            "5:\tlearn: 0.2566529\ttotal: 404ms\tremaining: 2.63s\n",
            "6:\tlearn: 0.2230409\ttotal: 465ms\tremaining: 2.53s\n",
            "7:\tlearn: 0.1857727\ttotal: 534ms\tremaining: 2.47s\n",
            "8:\tlearn: 0.1602392\ttotal: 615ms\tremaining: 2.46s\n",
            "9:\tlearn: 0.1421705\ttotal: 685ms\tremaining: 2.4s\n",
            "10:\tlearn: 0.1266955\ttotal: 776ms\tremaining: 2.4s\n",
            "11:\tlearn: 0.1128744\ttotal: 843ms\tremaining: 2.32s\n",
            "12:\tlearn: 0.1016624\ttotal: 903ms\tremaining: 2.22s\n",
            "13:\tlearn: 0.0926001\ttotal: 962ms\tremaining: 2.13s\n",
            "14:\tlearn: 0.0820953\ttotal: 1.02s\tremaining: 2.04s\n",
            "15:\tlearn: 0.0748342\ttotal: 1.08s\tremaining: 1.96s\n",
            "16:\tlearn: 0.0675849\ttotal: 1.14s\tremaining: 1.88s\n",
            "17:\tlearn: 0.0586197\ttotal: 1.2s\tremaining: 1.8s\n",
            "18:\tlearn: 0.0528763\ttotal: 1.26s\tremaining: 1.72s\n",
            "19:\tlearn: 0.0469691\ttotal: 1.32s\tremaining: 1.65s\n",
            "20:\tlearn: 0.0425508\ttotal: 1.38s\tremaining: 1.58s\n",
            "21:\tlearn: 0.0372888\ttotal: 1.44s\tremaining: 1.5s\n",
            "22:\tlearn: 0.0344937\ttotal: 1.49s\tremaining: 1.43s\n",
            "23:\tlearn: 0.0311517\ttotal: 1.55s\tremaining: 1.36s\n",
            "24:\tlearn: 0.0281823\ttotal: 1.61s\tremaining: 1.29s\n",
            "25:\tlearn: 0.0255295\ttotal: 1.67s\tremaining: 1.22s\n",
            "26:\tlearn: 0.0228774\ttotal: 1.73s\tremaining: 1.15s\n",
            "27:\tlearn: 0.0206671\ttotal: 1.81s\tremaining: 1.1s\n",
            "28:\tlearn: 0.0186608\ttotal: 1.87s\tremaining: 1.03s\n",
            "29:\tlearn: 0.0176370\ttotal: 1.93s\tremaining: 963ms\n",
            "30:\tlearn: 0.0159950\ttotal: 1.99s\tremaining: 897ms\n",
            "31:\tlearn: 0.0144016\ttotal: 2.05s\tremaining: 831ms\n",
            "32:\tlearn: 0.0132916\ttotal: 2.1s\tremaining: 765ms\n",
            "33:\tlearn: 0.0124559\ttotal: 2.16s\tremaining: 700ms\n",
            "34:\tlearn: 0.0114096\ttotal: 2.22s\tremaining: 635ms\n",
            "35:\tlearn: 0.0106051\ttotal: 2.31s\tremaining: 577ms\n",
            "36:\tlearn: 0.0097902\ttotal: 2.38s\tremaining: 515ms\n",
            "37:\tlearn: 0.0091023\ttotal: 2.44s\tremaining: 450ms\n",
            "38:\tlearn: 0.0084135\ttotal: 2.52s\tremaining: 387ms\n",
            "39:\tlearn: 0.0078531\ttotal: 2.58s\tremaining: 323ms\n",
            "40:\tlearn: 0.0073026\ttotal: 2.64s\tremaining: 258ms\n",
            "41:\tlearn: 0.0068534\ttotal: 2.71s\tremaining: 194ms\n",
            "42:\tlearn: 0.0064397\ttotal: 2.78s\tremaining: 129ms\n",
            "43:\tlearn: 0.0061075\ttotal: 2.86s\tremaining: 65.1ms\n",
            "44:\tlearn: 0.0057628\ttotal: 2.92s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 1779, number of negative: 1799\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007617 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32638\n",
            "[LightGBM] [Info] Number of data points in the train set: 3578, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497205 -> initscore=-0.011180\n",
            "[LightGBM] [Info] Start training from score -0.011180\n",
            "[LightGBM] [Info] Number of positive: 1779, number of negative: 1799\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009472 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32627\n",
            "[LightGBM] [Info] Number of data points in the train set: 3578, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497205 -> initscore=-0.011180\n",
            "[LightGBM] [Info] Start training from score -0.011180\n",
            "[LightGBM] [Info] Number of positive: 1779, number of negative: 1799\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32620\n",
            "[LightGBM] [Info] Number of data points in the train set: 3578, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497205 -> initscore=-0.011180\n",
            "[LightGBM] [Info] Start training from score -0.011180\n",
            "[LightGBM] [Info] Number of positive: 1779, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32629\n",
            "[LightGBM] [Info] Number of data points in the train set: 3579, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497066 -> initscore=-0.011735\n",
            "[LightGBM] [Info] Start training from score -0.011735\n",
            "[LightGBM] [Info] Number of positive: 1780, number of negative: 1799\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007355 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32612\n",
            "[LightGBM] [Info] Number of data points in the train set: 3579, number of used features: 128\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497346 -> initscore=-0.010618\n",
            "[LightGBM] [Info] Start training from score -0.010618\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.923701  0.366348   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.784091  0.169361   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.944805  0.600000   \n",
            "3                             KNeighborsClassifier()  0.683442  0.241867   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.923701  0.378369   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.909091  0.510949   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.931818  0.467620   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.939935  0.553282   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.936688  0.520808   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.236659   1.000000  0.145455  0.253968     1.000000     0.145455  \n",
            "1  0.152095   0.185484  0.418182  0.256983     0.819964     0.418182  \n",
            "2  0.529412   1.000000  0.381818  0.552632     1.000000     0.381818  \n",
            "3  0.172727   0.181818  0.727273  0.290909     0.679144     0.727273  \n",
            "4  0.310273   0.750000  0.218182  0.338028     0.992870     0.218182  \n",
            "5  0.505830   0.492958  0.636364  0.555556     0.935829     0.636364  \n",
            "6  0.376127   0.933333  0.254545  0.400000     0.998217     0.254545  \n",
            "7  0.493646   0.909091  0.363636  0.519481     0.996435     0.363636  \n",
            "8  0.454000   0.900000  0.327273  0.480000     0.996435     0.327273  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(FT-Ind).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAQehR4geKHc"
      },
      "source": [
        "# **LSA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OHHN6ERr7FL"
      },
      "source": [
        "**Imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75EByGT3eMEU"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4aJ6LOAePRE"
      },
      "outputs": [],
      "source": [
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNxV7lniedjd",
        "outputId": "8cc4e95b-ed20-41ae-a8d7-2a7c49df1d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.954288  0.683748   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.958738  0.720638   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.911003  0.090590   \n",
            "3                             KNeighborsClassifier()  0.963997  0.759146   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.995550  0.972524   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.994337  0.965039   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.993528  0.959883   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995955  0.975054   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996764  0.980091   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.637149   1.000000  0.490991  0.658610     1.000000     0.490991  \n",
            "1  0.705797   0.894737  0.612613  0.727273     0.992889     0.612613  \n",
            "2  0.016280   1.000000  0.009009  0.017857     1.000000     0.009009  \n",
            "3  0.731208   1.000000  0.599099  0.749296     1.000000     0.599099  \n",
            "4  0.972274   0.995305  0.954955  0.974713     0.999556     0.954955  \n",
            "5  0.964930   0.981481  0.954955  0.968037     0.998222     0.954955  \n",
            "6  0.959079   1.000000  0.927928  0.962617     1.000000     0.927928  \n",
            "7  0.974743   1.000000  0.954955  0.976959     1.000000     0.954955  \n",
            "8  0.980042   0.990826  0.972973  0.981818     0.999111     0.972973  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRQxBBIo2yxd"
      },
      "source": [
        "**ADASYN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BoRZyco4aME"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZPBUxGD23el"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NESeBrUM2_9j",
        "outputId": "8a04a12a-310a-4832-9051-adad7cb048e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.989111  0.978454   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.907778  0.815643   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.969111  0.939966   \n",
            "3                             KNeighborsClassifier()  0.998000  0.996008   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.998222  0.996451   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.931556  0.863276   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.998000  0.996002   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.998000  0.996000   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.998444  0.996891   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.978222   1.000000  0.978222  0.988991     1.000000     0.978222  \n",
            "1  0.815556   0.913848  0.900444  0.907096     0.915111     0.900444  \n",
            "2  0.938222   0.999527  0.938667  0.968141     0.999556     0.938667  \n",
            "3  0.996000   0.996016  1.000000  0.998004     0.996000     1.000000  \n",
            "4  0.996444   0.996457  1.000000  0.998225     0.996444     1.000000  \n",
            "5  0.863111   0.940163  0.921778  0.930880     0.941333     0.921778  \n",
            "6  0.996000   0.996896  0.999111  0.998002     0.996889     0.999111  \n",
            "7  0.996000   0.997779  0.998222  0.998000     0.997778     0.998222  \n",
            "8  0.996889   0.997339  0.999556  0.998446     0.997333     0.999556  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(ADASYN)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "eSAM3ffOjFoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "uwLN9TCDjI3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "10eFwROojOXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SoBgsjEjVT8",
        "outputId": "43bbdc6d-11a0-4316-f68b-2950d1cc0d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.972444  0.946327   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.976444  0.953492   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.954222  0.912276   \n",
            "3                             KNeighborsClassifier()  0.981778  0.964196   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.996889  0.993797   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.996222  0.992445   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.995778  0.991584   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.996444  0.992914   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996444  0.992914   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.944889   1.000000  0.944889  0.971664     1.000000     0.944889  \n",
            "1  0.952889   0.994009  0.958667  0.976018     0.994222     0.958667  \n",
            "2  0.908444   1.000000  0.908444  0.952026     1.000000     0.908444  \n",
            "3  0.963556   1.000000  0.963556  0.981440     1.000000     0.963556  \n",
            "4  0.993778   1.000000  0.993778  0.996879     1.000000     0.993778  \n",
            "5  0.992444   0.996885  0.995556  0.996220     0.996889     0.995556  \n",
            "6  0.991556   0.999552  0.992000  0.995762     0.999556     0.992000  \n",
            "7  0.992889   1.000000  0.992889  0.996432     1.000000     0.992889  \n",
            "8  0.992889   1.000000  0.992889  0.996432     1.000000     0.992889  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qARyehv3RIj"
      },
      "source": [
        "**SMOTETomek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNwtYl5b4qqM"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S83WuLOU3Zh-"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTLwYeRk3ccL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09133bdf-ae1f-4601-8a50-f2bf46a79726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.989333  0.978889   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.898667  0.797387   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.978222  0.957353   \n",
            "3                             KNeighborsClassifier()  0.998889  0.997780   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.996889  0.993779   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.984889  0.969792   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.997111  0.994227   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.997556  0.995111   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.999556  0.999111   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.978667   1.000000  0.978667  0.989218     1.000000     0.978667  \n",
            "1  0.797333   0.894112  0.904444  0.899249     0.892889     0.904444  \n",
            "2  0.956444   1.000000  0.956444  0.977737     1.000000     0.956444  \n",
            "3  0.997778   0.997783  1.000000  0.998890     0.997778     1.000000  \n",
            "4  0.993778   0.996007  0.997778  0.996892     0.996000     0.997778  \n",
            "5  0.969778   0.982317  0.987556  0.984929     0.982222     0.987556  \n",
            "6  0.994222   0.995569  0.998667  0.997116     0.995556     0.998667  \n",
            "7  0.995111   0.997335  0.997778  0.997556     0.997333     0.997778  \n",
            "8  0.999111   0.999556  0.999556  0.999556     0.999556     0.999556  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(SMOTETomek)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRqWngh-3gob"
      },
      "source": [
        "**NearMiss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlUjQ8Dt4roc"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro4kO8Xa3k06"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEXEHnpI3np7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bc9736-99d4-4510-95ff-a57303085e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.986486  0.973329   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.966216  0.932518   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.950450  0.905357   \n",
            "3                             KNeighborsClassifier()  0.909910  0.833461   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988739  0.977567   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.988739  0.977567   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.977477  0.954994   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.986486  0.973329   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990991  0.982141   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.972973   1.000000  0.972973  0.986301     1.000000     0.972973  \n",
            "1  0.932432   0.972603  0.959459  0.965986     0.972973     0.959459  \n",
            "2  0.900901   1.000000  0.900901  0.947867     1.000000     0.900901  \n",
            "3  0.819820   1.000000  0.819820  0.900990     1.000000     0.819820  \n",
            "4  0.977477   0.995434  0.981982  0.988662     0.995495     0.981982  \n",
            "5  0.977477   0.995434  0.981982  0.988662     0.995495     0.981982  \n",
            "6  0.954955   0.981818  0.972973  0.977376     0.981982     0.972973  \n",
            "7  0.972973   1.000000  0.972973  0.986301     1.000000     0.972973  \n",
            "8  0.981982   1.000000  0.981982  0.990909     1.000000     0.981982  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-All-CV(NearMiss)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z16dJjE-3tiT"
      },
      "source": [
        "**TomekLinks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIjbSY6U4X1C"
      },
      "outputs": [],
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKKHCtVF32rV"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCLnHbnP39pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3c4370-f7e8-4c8b-8c4e-eedaba8275ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.955502  0.693534   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.957524  0.712519   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.911408  0.110972   \n",
            "3                             KNeighborsClassifier()  0.963997  0.759146   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.995550  0.972524   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.994337  0.965039   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.993528  0.959883   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.995955  0.975054   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996359  0.977621   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.649552   1.000000  0.504505  0.670659     1.000000     0.504505  \n",
            "1  0.699278   0.877419  0.612613  0.721485     0.991556     0.612613  \n",
            "2  0.024330   1.000000  0.013514  0.026667     1.000000     0.013514  \n",
            "3  0.731208   1.000000  0.599099  0.749296     1.000000     0.599099  \n",
            "4  0.972274   0.995305  0.954955  0.974713     0.999556     0.954955  \n",
            "5  0.964930   0.981481  0.954955  0.968037     0.998222     0.954955  \n",
            "6  0.959079   1.000000  0.927928  0.962617     1.000000     0.927928  \n",
            "7  0.974743   1.000000  0.954955  0.976959     1.000000     0.954955  \n",
            "8  0.977593   0.986301  0.972973  0.979592     0.998667     0.972973  \n"
          ]
        }
      ],
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-CV(TomekLinks)).csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "KGLpm4UjGDe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "NDW348pNGGiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/LSA-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest= df_tr[target]"
      ],
      "metadata": {
        "id": "OvuiRQcXGLWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(LSA-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmjk0RkMGSXJ",
        "outputId": "9e69ffa3-7543-454a-efd9-95e6310a1c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.4211596\ttotal: 74.9ms\tremaining: 3.3s\n",
            "1:\tlearn: 0.3313006\ttotal: 115ms\tremaining: 2.47s\n",
            "2:\tlearn: 0.2516516\ttotal: 173ms\tremaining: 2.42s\n",
            "3:\tlearn: 0.2064881\ttotal: 211ms\tremaining: 2.16s\n",
            "4:\tlearn: 0.1601418\ttotal: 255ms\tremaining: 2.04s\n",
            "5:\tlearn: 0.1370993\ttotal: 313ms\tremaining: 2.03s\n",
            "6:\tlearn: 0.1103933\ttotal: 356ms\tremaining: 1.93s\n",
            "7:\tlearn: 0.0902668\ttotal: 402ms\tremaining: 1.86s\n",
            "8:\tlearn: 0.0797383\ttotal: 449ms\tremaining: 1.8s\n",
            "9:\tlearn: 0.0704787\ttotal: 505ms\tremaining: 1.77s\n",
            "10:\tlearn: 0.0635279\ttotal: 559ms\tremaining: 1.73s\n",
            "11:\tlearn: 0.0539245\ttotal: 604ms\tremaining: 1.66s\n",
            "12:\tlearn: 0.0490943\ttotal: 656ms\tremaining: 1.61s\n",
            "13:\tlearn: 0.0441082\ttotal: 717ms\tremaining: 1.59s\n",
            "14:\tlearn: 0.0391833\ttotal: 764ms\tremaining: 1.53s\n",
            "15:\tlearn: 0.0362749\ttotal: 818ms\tremaining: 1.48s\n",
            "16:\tlearn: 0.0311258\ttotal: 869ms\tremaining: 1.43s\n",
            "17:\tlearn: 0.0287803\ttotal: 927ms\tremaining: 1.39s\n",
            "18:\tlearn: 0.0266019\ttotal: 979ms\tremaining: 1.34s\n",
            "19:\tlearn: 0.0236836\ttotal: 1.04s\tremaining: 1.3s\n",
            "20:\tlearn: 0.0217722\ttotal: 1.08s\tremaining: 1.23s\n",
            "21:\tlearn: 0.0190111\ttotal: 1.13s\tremaining: 1.18s\n",
            "22:\tlearn: 0.0176480\ttotal: 1.19s\tremaining: 1.14s\n",
            "23:\tlearn: 0.0165434\ttotal: 1.24s\tremaining: 1.09s\n",
            "24:\tlearn: 0.0148120\ttotal: 1.29s\tremaining: 1.03s\n",
            "25:\tlearn: 0.0138452\ttotal: 1.34s\tremaining: 981ms\n",
            "26:\tlearn: 0.0127136\ttotal: 1.4s\tremaining: 936ms\n",
            "27:\tlearn: 0.0113510\ttotal: 1.47s\tremaining: 890ms\n",
            "28:\tlearn: 0.0106780\ttotal: 1.53s\tremaining: 844ms\n",
            "29:\tlearn: 0.0099692\ttotal: 1.58s\tremaining: 792ms\n",
            "30:\tlearn: 0.0089459\ttotal: 1.64s\tremaining: 739ms\n",
            "31:\tlearn: 0.0086141\ttotal: 1.69s\tremaining: 689ms\n",
            "32:\tlearn: 0.0079659\ttotal: 1.75s\tremaining: 638ms\n",
            "33:\tlearn: 0.0072174\ttotal: 1.79s\tremaining: 578ms\n",
            "34:\tlearn: 0.0067807\ttotal: 1.85s\tremaining: 528ms\n",
            "35:\tlearn: 0.0063277\ttotal: 1.88s\tremaining: 471ms\n",
            "36:\tlearn: 0.0056884\ttotal: 1.93s\tremaining: 417ms\n",
            "37:\tlearn: 0.0053282\ttotal: 1.99s\tremaining: 366ms\n",
            "38:\tlearn: 0.0051195\ttotal: 2.02s\tremaining: 311ms\n",
            "39:\tlearn: 0.0047636\ttotal: 2.06s\tremaining: 257ms\n",
            "40:\tlearn: 0.0045034\ttotal: 2.09s\tremaining: 204ms\n",
            "41:\tlearn: 0.0042834\ttotal: 2.13s\tremaining: 152ms\n",
            "42:\tlearn: 0.0040943\ttotal: 2.16s\tremaining: 100ms\n",
            "43:\tlearn: 0.0037746\ttotal: 2.19s\tremaining: 49.8ms\n",
            "44:\tlearn: 0.0035484\ttotal: 2.24s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2250, number of negative: 2250\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14273\n",
            "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "0:\tlearn: 0.4211596\ttotal: 48.7ms\tremaining: 2.14s\n",
            "1:\tlearn: 0.3313006\ttotal: 75.5ms\tremaining: 1.62s\n",
            "2:\tlearn: 0.2516516\ttotal: 101ms\tremaining: 1.42s\n",
            "3:\tlearn: 0.2064881\ttotal: 127ms\tremaining: 1.3s\n",
            "4:\tlearn: 0.1601418\ttotal: 152ms\tremaining: 1.22s\n",
            "5:\tlearn: 0.1370993\ttotal: 178ms\tremaining: 1.16s\n",
            "6:\tlearn: 0.1103933\ttotal: 204ms\tremaining: 1.11s\n",
            "7:\tlearn: 0.0902668\ttotal: 230ms\tremaining: 1.06s\n",
            "8:\tlearn: 0.0797383\ttotal: 257ms\tremaining: 1.03s\n",
            "9:\tlearn: 0.0704787\ttotal: 283ms\tremaining: 990ms\n",
            "10:\tlearn: 0.0635279\ttotal: 310ms\tremaining: 959ms\n",
            "11:\tlearn: 0.0539245\ttotal: 336ms\tremaining: 924ms\n",
            "12:\tlearn: 0.0490943\ttotal: 362ms\tremaining: 890ms\n",
            "13:\tlearn: 0.0441082\ttotal: 387ms\tremaining: 858ms\n",
            "14:\tlearn: 0.0391833\ttotal: 413ms\tremaining: 826ms\n",
            "15:\tlearn: 0.0362749\ttotal: 459ms\tremaining: 833ms\n",
            "16:\tlearn: 0.0311258\ttotal: 503ms\tremaining: 828ms\n",
            "17:\tlearn: 0.0287803\ttotal: 546ms\tremaining: 819ms\n",
            "18:\tlearn: 0.0266019\ttotal: 582ms\tremaining: 797ms\n",
            "19:\tlearn: 0.0236836\ttotal: 622ms\tremaining: 777ms\n",
            "20:\tlearn: 0.0217722\ttotal: 674ms\tremaining: 771ms\n",
            "21:\tlearn: 0.0190111\ttotal: 720ms\tremaining: 753ms\n",
            "22:\tlearn: 0.0176480\ttotal: 779ms\tremaining: 746ms\n",
            "23:\tlearn: 0.0165434\ttotal: 833ms\tremaining: 729ms\n",
            "24:\tlearn: 0.0148120\ttotal: 891ms\tremaining: 713ms\n",
            "25:\tlearn: 0.0138452\ttotal: 941ms\tremaining: 688ms\n",
            "26:\tlearn: 0.0127136\ttotal: 993ms\tremaining: 662ms\n",
            "27:\tlearn: 0.0113510\ttotal: 1.05s\tremaining: 640ms\n",
            "28:\tlearn: 0.0106780\ttotal: 1.11s\tremaining: 612ms\n",
            "29:\tlearn: 0.0099692\ttotal: 1.16s\tremaining: 581ms\n",
            "30:\tlearn: 0.0089459\ttotal: 1.22s\tremaining: 553ms\n",
            "31:\tlearn: 0.0086141\ttotal: 1.28s\tremaining: 520ms\n",
            "32:\tlearn: 0.0079659\ttotal: 1.33s\tremaining: 485ms\n",
            "33:\tlearn: 0.0072174\ttotal: 1.38s\tremaining: 448ms\n",
            "34:\tlearn: 0.0067807\ttotal: 1.44s\tremaining: 411ms\n",
            "35:\tlearn: 0.0063277\ttotal: 1.5s\tremaining: 374ms\n",
            "36:\tlearn: 0.0056884\ttotal: 1.55s\tremaining: 336ms\n",
            "37:\tlearn: 0.0053282\ttotal: 1.59s\tremaining: 293ms\n",
            "38:\tlearn: 0.0051195\ttotal: 1.65s\tremaining: 254ms\n",
            "39:\tlearn: 0.0047636\ttotal: 1.71s\tremaining: 213ms\n",
            "40:\tlearn: 0.0045034\ttotal: 1.76s\tremaining: 172ms\n",
            "41:\tlearn: 0.0042834\ttotal: 1.82s\tremaining: 130ms\n",
            "42:\tlearn: 0.0040943\ttotal: 1.88s\tremaining: 87.3ms\n",
            "43:\tlearn: 0.0037746\ttotal: 1.94s\tremaining: 44ms\n",
            "44:\tlearn: 0.0035484\ttotal: 2s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2250, number of negative: 2250\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008011 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14273\n",
            "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "0:\tlearn: 0.3936305\ttotal: 134ms\tremaining: 5.88s\n",
            "1:\tlearn: 0.2866738\ttotal: 257ms\tremaining: 5.52s\n",
            "2:\tlearn: 0.2240884\ttotal: 307ms\tremaining: 4.3s\n",
            "3:\tlearn: 0.1686698\ttotal: 347ms\tremaining: 3.56s\n",
            "4:\tlearn: 0.1403899\ttotal: 420ms\tremaining: 3.36s\n",
            "5:\tlearn: 0.1067380\ttotal: 508ms\tremaining: 3.3s\n",
            "6:\tlearn: 0.0886246\ttotal: 542ms\tremaining: 2.94s\n",
            "7:\tlearn: 0.0724288\ttotal: 575ms\tremaining: 2.66s\n",
            "8:\tlearn: 0.0600424\ttotal: 637ms\tremaining: 2.55s\n",
            "9:\tlearn: 0.0509326\ttotal: 685ms\tremaining: 2.4s\n",
            "10:\tlearn: 0.0466122\ttotal: 713ms\tremaining: 2.2s\n",
            "11:\tlearn: 0.0416638\ttotal: 747ms\tremaining: 2.05s\n",
            "12:\tlearn: 0.0359905\ttotal: 780ms\tremaining: 1.92s\n",
            "13:\tlearn: 0.0321601\ttotal: 808ms\tremaining: 1.79s\n",
            "14:\tlearn: 0.0285613\ttotal: 843ms\tremaining: 1.69s\n",
            "15:\tlearn: 0.0254917\ttotal: 871ms\tremaining: 1.58s\n",
            "16:\tlearn: 0.0238423\ttotal: 900ms\tremaining: 1.48s\n",
            "17:\tlearn: 0.0220616\ttotal: 928ms\tremaining: 1.39s\n",
            "18:\tlearn: 0.0195348\ttotal: 958ms\tremaining: 1.31s\n",
            "19:\tlearn: 0.0178841\ttotal: 990ms\tremaining: 1.24s\n",
            "20:\tlearn: 0.0154329\ttotal: 1.02s\tremaining: 1.16s\n",
            "21:\tlearn: 0.0140536\ttotal: 1.05s\tremaining: 1.1s\n",
            "22:\tlearn: 0.0128612\ttotal: 1.08s\tremaining: 1.03s\n",
            "23:\tlearn: 0.0115028\ttotal: 1.11s\tremaining: 969ms\n",
            "24:\tlearn: 0.0105959\ttotal: 1.14s\tremaining: 909ms\n",
            "25:\tlearn: 0.0099048\ttotal: 1.17s\tremaining: 854ms\n",
            "26:\tlearn: 0.0089283\ttotal: 1.2s\tremaining: 801ms\n",
            "27:\tlearn: 0.0082463\ttotal: 1.24s\tremaining: 750ms\n",
            "28:\tlearn: 0.0076531\ttotal: 1.28s\tremaining: 705ms\n",
            "29:\tlearn: 0.0067484\ttotal: 1.31s\tremaining: 657ms\n",
            "30:\tlearn: 0.0063197\ttotal: 1.34s\tremaining: 606ms\n",
            "31:\tlearn: 0.0057946\ttotal: 1.37s\tremaining: 557ms\n",
            "32:\tlearn: 0.0052802\ttotal: 1.4s\tremaining: 509ms\n",
            "33:\tlearn: 0.0049401\ttotal: 1.43s\tremaining: 464ms\n",
            "34:\tlearn: 0.0046944\ttotal: 1.46s\tremaining: 418ms\n",
            "35:\tlearn: 0.0043662\ttotal: 1.5s\tremaining: 374ms\n",
            "36:\tlearn: 0.0039464\ttotal: 1.52s\tremaining: 330ms\n",
            "37:\tlearn: 0.0038068\ttotal: 1.56s\tremaining: 287ms\n",
            "38:\tlearn: 0.0035550\ttotal: 1.59s\tremaining: 245ms\n",
            "39:\tlearn: 0.0034387\ttotal: 1.62s\tremaining: 203ms\n",
            "40:\tlearn: 0.0032804\ttotal: 1.65s\tremaining: 161ms\n",
            "41:\tlearn: 0.0030855\ttotal: 1.68s\tremaining: 120ms\n",
            "42:\tlearn: 0.0029077\ttotal: 1.71s\tremaining: 79.6ms\n",
            "43:\tlearn: 0.0027623\ttotal: 1.74s\tremaining: 39.6ms\n",
            "44:\tlearn: 0.0025461\ttotal: 1.77s\tremaining: 0us\n",
            "0:\tlearn: 0.4042254\ttotal: 37.9ms\tremaining: 1.67s\n",
            "1:\tlearn: 0.2952135\ttotal: 67ms\tremaining: 1.44s\n",
            "2:\tlearn: 0.2152948\ttotal: 95.6ms\tremaining: 1.34s\n",
            "3:\tlearn: 0.1777857\ttotal: 124ms\tremaining: 1.27s\n",
            "4:\tlearn: 0.1475895\ttotal: 153ms\tremaining: 1.22s\n",
            "5:\tlearn: 0.1247355\ttotal: 182ms\tremaining: 1.18s\n",
            "6:\tlearn: 0.1059318\ttotal: 212ms\tremaining: 1.15s\n",
            "7:\tlearn: 0.0880903\ttotal: 247ms\tremaining: 1.14s\n",
            "8:\tlearn: 0.0796267\ttotal: 278ms\tremaining: 1.11s\n",
            "9:\tlearn: 0.0731466\ttotal: 309ms\tremaining: 1.08s\n",
            "10:\tlearn: 0.0631073\ttotal: 338ms\tremaining: 1.04s\n",
            "11:\tlearn: 0.0587106\ttotal: 373ms\tremaining: 1.02s\n",
            "12:\tlearn: 0.0514087\ttotal: 402ms\tremaining: 990ms\n",
            "13:\tlearn: 0.0468865\ttotal: 431ms\tremaining: 953ms\n",
            "14:\tlearn: 0.0400518\ttotal: 473ms\tremaining: 945ms\n",
            "15:\tlearn: 0.0366865\ttotal: 526ms\tremaining: 953ms\n",
            "16:\tlearn: 0.0335324\ttotal: 555ms\tremaining: 914ms\n",
            "17:\tlearn: 0.0307858\ttotal: 583ms\tremaining: 874ms\n",
            "18:\tlearn: 0.0278453\ttotal: 610ms\tremaining: 835ms\n",
            "19:\tlearn: 0.0261757\ttotal: 640ms\tremaining: 800ms\n",
            "20:\tlearn: 0.0243260\ttotal: 668ms\tremaining: 764ms\n",
            "21:\tlearn: 0.0229026\ttotal: 702ms\tremaining: 734ms\n",
            "22:\tlearn: 0.0213121\ttotal: 733ms\tremaining: 701ms\n",
            "23:\tlearn: 0.0199390\ttotal: 762ms\tremaining: 667ms\n",
            "24:\tlearn: 0.0178825\ttotal: 792ms\tremaining: 633ms\n",
            "25:\tlearn: 0.0160753\ttotal: 821ms\tremaining: 600ms\n",
            "26:\tlearn: 0.0149160\ttotal: 850ms\tremaining: 567ms\n",
            "27:\tlearn: 0.0137604\ttotal: 880ms\tremaining: 534ms\n",
            "28:\tlearn: 0.0124661\ttotal: 911ms\tremaining: 503ms\n",
            "29:\tlearn: 0.0112101\ttotal: 941ms\tremaining: 470ms\n",
            "30:\tlearn: 0.0106315\ttotal: 970ms\tremaining: 438ms\n",
            "31:\tlearn: 0.0097705\ttotal: 1s\tremaining: 407ms\n",
            "32:\tlearn: 0.0091336\ttotal: 1.03s\tremaining: 375ms\n",
            "33:\tlearn: 0.0083776\ttotal: 1.06s\tremaining: 342ms\n",
            "34:\tlearn: 0.0077968\ttotal: 1.09s\tremaining: 311ms\n",
            "35:\tlearn: 0.0072500\ttotal: 1.12s\tremaining: 280ms\n",
            "36:\tlearn: 0.0066771\ttotal: 1.15s\tremaining: 248ms\n",
            "37:\tlearn: 0.0062829\ttotal: 1.18s\tremaining: 217ms\n",
            "38:\tlearn: 0.0059371\ttotal: 1.21s\tremaining: 186ms\n",
            "39:\tlearn: 0.0056446\ttotal: 1.24s\tremaining: 155ms\n",
            "40:\tlearn: 0.0053602\ttotal: 1.26s\tremaining: 123ms\n",
            "41:\tlearn: 0.0050149\ttotal: 1.29s\tremaining: 92.5ms\n",
            "42:\tlearn: 0.0047201\ttotal: 1.33s\tremaining: 61.7ms\n",
            "43:\tlearn: 0.0044879\ttotal: 1.36s\tremaining: 30.9ms\n",
            "44:\tlearn: 0.0042493\ttotal: 1.39s\tremaining: 0us\n",
            "0:\tlearn: 0.4516658\ttotal: 48.3ms\tremaining: 2.12s\n",
            "1:\tlearn: 0.3220995\ttotal: 91ms\tremaining: 1.96s\n",
            "2:\tlearn: 0.2523999\ttotal: 136ms\tremaining: 1.9s\n",
            "3:\tlearn: 0.1856521\ttotal: 168ms\tremaining: 1.72s\n",
            "4:\tlearn: 0.1520614\ttotal: 197ms\tremaining: 1.58s\n",
            "5:\tlearn: 0.1287937\ttotal: 228ms\tremaining: 1.48s\n",
            "6:\tlearn: 0.1131981\ttotal: 262ms\tremaining: 1.42s\n",
            "7:\tlearn: 0.0985079\ttotal: 291ms\tremaining: 1.35s\n",
            "8:\tlearn: 0.0869945\ttotal: 323ms\tremaining: 1.29s\n",
            "9:\tlearn: 0.0750101\ttotal: 351ms\tremaining: 1.23s\n",
            "10:\tlearn: 0.0684501\ttotal: 379ms\tremaining: 1.17s\n",
            "11:\tlearn: 0.0613249\ttotal: 409ms\tremaining: 1.13s\n",
            "12:\tlearn: 0.0513547\ttotal: 437ms\tremaining: 1.07s\n",
            "13:\tlearn: 0.0467128\ttotal: 466ms\tremaining: 1.03s\n",
            "14:\tlearn: 0.0402660\ttotal: 496ms\tremaining: 991ms\n",
            "15:\tlearn: 0.0375353\ttotal: 529ms\tremaining: 959ms\n",
            "16:\tlearn: 0.0346003\ttotal: 559ms\tremaining: 920ms\n",
            "17:\tlearn: 0.0323997\ttotal: 587ms\tremaining: 881ms\n",
            "18:\tlearn: 0.0284354\ttotal: 616ms\tremaining: 843ms\n",
            "19:\tlearn: 0.0261888\ttotal: 646ms\tremaining: 808ms\n",
            "20:\tlearn: 0.0251701\ttotal: 676ms\tremaining: 772ms\n",
            "21:\tlearn: 0.0221895\ttotal: 706ms\tremaining: 739ms\n",
            "22:\tlearn: 0.0209323\ttotal: 735ms\tremaining: 703ms\n",
            "23:\tlearn: 0.0183832\ttotal: 766ms\tremaining: 670ms\n",
            "24:\tlearn: 0.0172338\ttotal: 794ms\tremaining: 635ms\n",
            "25:\tlearn: 0.0166352\ttotal: 822ms\tremaining: 600ms\n",
            "26:\tlearn: 0.0154407\ttotal: 851ms\tremaining: 568ms\n",
            "27:\tlearn: 0.0143701\ttotal: 884ms\tremaining: 537ms\n",
            "28:\tlearn: 0.0131456\ttotal: 923ms\tremaining: 509ms\n",
            "29:\tlearn: 0.0119945\ttotal: 956ms\tremaining: 478ms\n",
            "30:\tlearn: 0.0111708\ttotal: 990ms\tremaining: 447ms\n",
            "31:\tlearn: 0.0104504\ttotal: 1.02s\tremaining: 415ms\n",
            "32:\tlearn: 0.0093891\ttotal: 1.05s\tremaining: 382ms\n",
            "33:\tlearn: 0.0088376\ttotal: 1.08s\tremaining: 350ms\n",
            "34:\tlearn: 0.0084452\ttotal: 1.11s\tremaining: 317ms\n",
            "35:\tlearn: 0.0079825\ttotal: 1.16s\tremaining: 289ms\n",
            "36:\tlearn: 0.0072505\ttotal: 1.21s\tremaining: 262ms\n",
            "37:\tlearn: 0.0069534\ttotal: 1.25s\tremaining: 229ms\n",
            "38:\tlearn: 0.0064534\ttotal: 1.28s\tremaining: 197ms\n",
            "39:\tlearn: 0.0061659\ttotal: 1.31s\tremaining: 163ms\n",
            "40:\tlearn: 0.0057939\ttotal: 1.34s\tremaining: 130ms\n",
            "41:\tlearn: 0.0054407\ttotal: 1.37s\tremaining: 97.8ms\n",
            "42:\tlearn: 0.0051645\ttotal: 1.4s\tremaining: 65.2ms\n",
            "43:\tlearn: 0.0048254\ttotal: 1.46s\tremaining: 33.1ms\n",
            "44:\tlearn: 0.0044372\ttotal: 1.51s\tremaining: 0us\n",
            "0:\tlearn: 0.4206657\ttotal: 58.3ms\tremaining: 2.56s\n",
            "1:\tlearn: 0.3072058\ttotal: 110ms\tremaining: 2.36s\n",
            "2:\tlearn: 0.2368896\ttotal: 177ms\tremaining: 2.48s\n",
            "3:\tlearn: 0.1971460\ttotal: 233ms\tremaining: 2.38s\n",
            "4:\tlearn: 0.1627116\ttotal: 277ms\tremaining: 2.22s\n",
            "5:\tlearn: 0.1272056\ttotal: 348ms\tremaining: 2.26s\n",
            "6:\tlearn: 0.1079536\ttotal: 398ms\tremaining: 2.16s\n",
            "7:\tlearn: 0.0923921\ttotal: 484ms\tremaining: 2.24s\n",
            "8:\tlearn: 0.0833430\ttotal: 551ms\tremaining: 2.2s\n",
            "9:\tlearn: 0.0726406\ttotal: 628ms\tremaining: 2.2s\n",
            "10:\tlearn: 0.0639511\ttotal: 679ms\tremaining: 2.1s\n",
            "11:\tlearn: 0.0588599\ttotal: 745ms\tremaining: 2.05s\n",
            "12:\tlearn: 0.0506727\ttotal: 823ms\tremaining: 2.02s\n",
            "13:\tlearn: 0.0453088\ttotal: 893ms\tremaining: 1.98s\n",
            "14:\tlearn: 0.0405742\ttotal: 959ms\tremaining: 1.92s\n",
            "15:\tlearn: 0.0375326\ttotal: 1.02s\tremaining: 1.86s\n",
            "16:\tlearn: 0.0338774\ttotal: 1.08s\tremaining: 1.79s\n",
            "17:\tlearn: 0.0312998\ttotal: 1.16s\tremaining: 1.75s\n",
            "18:\tlearn: 0.0294820\ttotal: 1.25s\tremaining: 1.7s\n",
            "19:\tlearn: 0.0267667\ttotal: 1.32s\tremaining: 1.65s\n",
            "20:\tlearn: 0.0232880\ttotal: 1.38s\tremaining: 1.58s\n",
            "21:\tlearn: 0.0204598\ttotal: 1.44s\tremaining: 1.51s\n",
            "22:\tlearn: 0.0187274\ttotal: 1.5s\tremaining: 1.44s\n",
            "23:\tlearn: 0.0167490\ttotal: 1.58s\tremaining: 1.39s\n",
            "24:\tlearn: 0.0155155\ttotal: 1.68s\tremaining: 1.34s\n",
            "25:\tlearn: 0.0144684\ttotal: 1.77s\tremaining: 1.29s\n",
            "26:\tlearn: 0.0130525\ttotal: 1.83s\tremaining: 1.22s\n",
            "27:\tlearn: 0.0117433\ttotal: 1.89s\tremaining: 1.15s\n",
            "28:\tlearn: 0.0107466\ttotal: 1.98s\tremaining: 1.09s\n",
            "29:\tlearn: 0.0096028\ttotal: 2.07s\tremaining: 1.04s\n",
            "30:\tlearn: 0.0091555\ttotal: 2.18s\tremaining: 985ms\n",
            "31:\tlearn: 0.0082153\ttotal: 2.27s\tremaining: 921ms\n",
            "32:\tlearn: 0.0077294\ttotal: 2.35s\tremaining: 853ms\n",
            "33:\tlearn: 0.0070148\ttotal: 2.42s\tremaining: 784ms\n",
            "34:\tlearn: 0.0064882\ttotal: 2.5s\tremaining: 713ms\n",
            "35:\tlearn: 0.0061774\ttotal: 2.59s\tremaining: 647ms\n",
            "36:\tlearn: 0.0057593\ttotal: 2.65s\tremaining: 574ms\n",
            "37:\tlearn: 0.0054283\ttotal: 2.72s\tremaining: 502ms\n",
            "38:\tlearn: 0.0051490\ttotal: 2.84s\tremaining: 437ms\n",
            "39:\tlearn: 0.0050023\ttotal: 2.9s\tremaining: 363ms\n",
            "40:\tlearn: 0.0047445\ttotal: 2.96s\tremaining: 289ms\n",
            "41:\tlearn: 0.0044640\ttotal: 3.03s\tremaining: 216ms\n",
            "42:\tlearn: 0.0041863\ttotal: 3.12s\tremaining: 145ms\n",
            "43:\tlearn: 0.0039724\ttotal: 3.19s\tremaining: 72.5ms\n",
            "44:\tlearn: 0.0037823\ttotal: 3.25s\tremaining: 0us\n",
            "0:\tlearn: 0.4316500\ttotal: 98.4ms\tremaining: 4.33s\n",
            "1:\tlearn: 0.3253485\ttotal: 159ms\tremaining: 3.41s\n",
            "2:\tlearn: 0.2668542\ttotal: 222ms\tremaining: 3.11s\n",
            "3:\tlearn: 0.2186975\ttotal: 292ms\tremaining: 2.99s\n",
            "4:\tlearn: 0.1812920\ttotal: 372ms\tremaining: 2.97s\n",
            "5:\tlearn: 0.1473075\ttotal: 459ms\tremaining: 2.98s\n",
            "6:\tlearn: 0.1222112\ttotal: 543ms\tremaining: 2.95s\n",
            "7:\tlearn: 0.1054138\ttotal: 633ms\tremaining: 2.93s\n",
            "8:\tlearn: 0.0948369\ttotal: 718ms\tremaining: 2.87s\n",
            "9:\tlearn: 0.0849034\ttotal: 769ms\tremaining: 2.69s\n",
            "10:\tlearn: 0.0744680\ttotal: 826ms\tremaining: 2.55s\n",
            "11:\tlearn: 0.0660570\ttotal: 856ms\tremaining: 2.35s\n",
            "12:\tlearn: 0.0612316\ttotal: 881ms\tremaining: 2.17s\n",
            "13:\tlearn: 0.0560285\ttotal: 907ms\tremaining: 2.01s\n",
            "14:\tlearn: 0.0514313\ttotal: 932ms\tremaining: 1.86s\n",
            "15:\tlearn: 0.0466049\ttotal: 958ms\tremaining: 1.74s\n",
            "16:\tlearn: 0.0419481\ttotal: 984ms\tremaining: 1.62s\n",
            "17:\tlearn: 0.0384682\ttotal: 1.01s\tremaining: 1.52s\n",
            "18:\tlearn: 0.0351037\ttotal: 1.04s\tremaining: 1.42s\n",
            "19:\tlearn: 0.0319650\ttotal: 1.06s\tremaining: 1.33s\n",
            "20:\tlearn: 0.0294425\ttotal: 1.09s\tremaining: 1.24s\n",
            "21:\tlearn: 0.0275865\ttotal: 1.11s\tremaining: 1.16s\n",
            "22:\tlearn: 0.0236782\ttotal: 1.14s\tremaining: 1.09s\n",
            "23:\tlearn: 0.0214946\ttotal: 1.16s\tremaining: 1.02s\n",
            "24:\tlearn: 0.0195288\ttotal: 1.19s\tremaining: 951ms\n",
            "25:\tlearn: 0.0174077\ttotal: 1.21s\tremaining: 888ms\n",
            "26:\tlearn: 0.0165593\ttotal: 1.24s\tremaining: 828ms\n",
            "27:\tlearn: 0.0149492\ttotal: 1.27s\tremaining: 772ms\n",
            "28:\tlearn: 0.0136661\ttotal: 1.3s\tremaining: 716ms\n",
            "29:\tlearn: 0.0122575\ttotal: 1.32s\tremaining: 661ms\n",
            "30:\tlearn: 0.0114287\ttotal: 1.35s\tremaining: 608ms\n",
            "31:\tlearn: 0.0103901\ttotal: 1.37s\tremaining: 557ms\n",
            "32:\tlearn: 0.0100103\ttotal: 1.4s\tremaining: 508ms\n",
            "33:\tlearn: 0.0089673\ttotal: 1.42s\tremaining: 460ms\n",
            "34:\tlearn: 0.0081174\ttotal: 1.45s\tremaining: 414ms\n",
            "35:\tlearn: 0.0073165\ttotal: 1.48s\tremaining: 369ms\n",
            "36:\tlearn: 0.0066856\ttotal: 1.5s\tremaining: 325ms\n",
            "37:\tlearn: 0.0061613\ttotal: 1.53s\tremaining: 281ms\n",
            "38:\tlearn: 0.0058039\ttotal: 1.55s\tremaining: 239ms\n",
            "39:\tlearn: 0.0054587\ttotal: 1.57s\tremaining: 197ms\n",
            "40:\tlearn: 0.0049627\ttotal: 1.6s\tremaining: 156ms\n",
            "41:\tlearn: 0.0045643\ttotal: 1.62s\tremaining: 116ms\n",
            "42:\tlearn: 0.0043829\ttotal: 1.65s\tremaining: 76.7ms\n",
            "43:\tlearn: 0.0040121\ttotal: 1.67s\tremaining: 38.1ms\n",
            "44:\tlearn: 0.0039047\ttotal: 1.71s\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 1800, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14274\n",
            "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 1800, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002770 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14274\n",
            "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 1800, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14274\n",
            "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 1800, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002445 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14271\n",
            "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 1800, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002623 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14275\n",
            "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 56\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.909385  0.000000   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.852751  0.099303   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.907767 -0.012708   \n",
            "3                             KNeighborsClassifier()  0.896440  0.169958   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.915858  0.263054   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.868932  0.403166   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.909385  0.115108   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.906149 -0.017987   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.901294  0.110850   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.000000   0.000000  0.000000  0.000000     1.000000     0.000000  \n",
            "1  0.099299   0.181818  0.178571  0.180180     0.919929     0.178571  \n",
            "2 -0.003190   0.000000  0.000000  0.000000     0.998221     0.000000  \n",
            "3  0.154004   0.333333  0.142857  0.200000     0.971530     0.142857  \n",
            "4  0.168667   0.750000  0.107143  0.187500     0.996441     0.107143  \n",
            "5  0.387040   0.365591  0.607143  0.456376     0.895018     0.607143  \n",
            "6  0.055252   0.500000  0.035714  0.066667     0.996441     0.035714  \n",
            "7 -0.006289   0.000000  0.000000  0.000000     0.996441     0.000000  \n",
            "8  0.084689   0.307692  0.071429  0.115942     0.983986     0.071429  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AAC**"
      ],
      "metadata": {
        "id": "A2voa3EakKVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "GA9NsInzkoPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "UJnLG7MQkMQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZctZMbykZhs",
        "outputId": "69bd8b1e-bfd7-4a35-acce-6f2c44aacc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.974919  0.837301   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.942557  0.599535   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932443  0.479668   \n",
            "3                             KNeighborsClassifier()  0.948220  0.639243   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907265   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.956311  0.715873   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987460  0.923781   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989887  0.937785   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990291  0.939987   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.830019   0.959770  0.752252  0.843434     0.996889     0.752252  \n",
            "1  0.584524   0.773973  0.509009  0.614130     0.985333     0.509009  \n",
            "2  0.378633   0.982456  0.252252  0.401434     0.999556     0.252252  \n",
            "3  0.620014   0.835714  0.527027  0.646409     0.989778     0.527027  \n",
            "4  0.907125   0.930233  0.900901  0.915332     0.993333     0.900901  \n",
            "5  0.712944   0.803191  0.680180  0.736585     0.983556     0.680180  \n",
            "6  0.923756   0.924444  0.936937  0.930649     0.992444     0.936937  \n",
            "7  0.937759   0.949772  0.936937  0.943311     0.995111     0.936937  \n",
            "8  0.939880   0.958333  0.932432  0.945205     0.996000     0.932432  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "ylZ8Hle0kuYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "vHqHB7DVkwpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "8mQJcOv_k4Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNz9FQVZk47M",
        "outputId": "5d081ec7-00dd-4189-b3bd-e13a7771c714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.988999  0.978218   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.861473  0.722915   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.876066  0.756998   \n",
            "3                             KNeighborsClassifier()  0.954198  0.912303   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989448  0.979097   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.914459  0.829004   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991917  0.983964   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989897  0.979978   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996857  0.993713   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.978000   0.978676  0.999546  0.989001     0.978667     0.999546  \n",
            "1  0.722894   0.862826  0.856171  0.859485     0.866667     0.856171  \n",
            "2  0.751807   0.924897  0.815789  0.866924     0.935111     0.815789  \n",
            "3  0.908474   0.915282  1.000000  0.955768     0.909333     1.000000  \n",
            "4  0.978898   0.979546  0.999546  0.989445     0.979556     0.999546  \n",
            "5  0.828924   0.907830  0.920599  0.914170     0.908444     0.920599  \n",
            "6  0.983836   0.983929  1.000000  0.991899     0.984000     1.000000  \n",
            "7  0.979795   0.980418  0.999546  0.989890     0.980444     0.999546  \n",
            "8  0.993713   0.996374  0.997278  0.996825     0.996444     0.997278  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "ReJ8WxHvk_Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "VmFEdp4ylB6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "5vh1IlOSlFS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqGYm-vElKkk",
        "outputId": "b911880b-ff13-40ec-993b-de59377fbd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.990444  0.980891   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953556  0.907671   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.974222  0.948482   \n",
            "3                             KNeighborsClassifier()  0.976000  0.952122   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988222  0.976449   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.976667  0.953349   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991778  0.983563   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.991778  0.983563   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988000  0.976139   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.980889   0.991537  0.989333  0.990434     0.991556     0.989333  \n",
            "1  0.907111   0.938171  0.971111  0.954357     0.936000     0.971111  \n",
            "2  0.948444   0.970044  0.978667  0.974336     0.969778     0.978667  \n",
            "3  0.952000   0.983740  0.968000  0.975806     0.984000     0.968000  \n",
            "4  0.976444   0.986708  0.989778  0.988241     0.986667     0.989778  \n",
            "5  0.953333   0.979437  0.973778  0.976599     0.979556     0.973778  \n",
            "6  0.983556   0.989819  0.993778  0.991794     0.989778     0.993778  \n",
            "7  0.983556   0.989819  0.993778  0.991794     0.989778     0.993778  \n",
            "8  0.976000   0.996383  0.979556  0.987898     0.996444     0.979556  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "1hGEPWadlQEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "4XGA6J5BlTe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "PS2troZolWP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd-5r-fSlb4U",
        "outputId": "8c4204fd-e5ba-4916-9ab3-0940a680cb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.985556  0.971123   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.901333  0.803078   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.898667  0.802063   \n",
            "3                             KNeighborsClassifier()  0.958000  0.919249   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.989333  0.978754   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.919556  0.839138   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.990667  0.981421   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988000  0.976111   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.995778  0.991560   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.971111   0.983193  0.988000  0.985591     0.983111     0.988000  \n",
            "1  0.802667   0.888889  0.917333  0.902887     0.885333     0.917333  \n",
            "2  0.797333   0.947159  0.844444  0.892857     0.952889     0.844444  \n",
            "3  0.916000   0.922509  1.000000  0.959693     0.916000     1.000000  \n",
            "4  0.978667   0.982895  0.996000  0.989404     0.982667     0.996000  \n",
            "5  0.839111   0.922939  0.915556  0.919232     0.923556     0.915556  \n",
            "6  0.981333   0.984211  0.997333  0.990728     0.984000     0.997333  \n",
            "7  0.976000   0.980736  0.995556  0.988090     0.980444     0.995556  \n",
            "8  0.991556   0.994240  0.997333  0.995784     0.994222     0.997333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "qCkhzQaIlhGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "H_LTHp1LlsBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "IPMp7JNhlu5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PqZvO01l1dM",
        "outputId": "8862e9e6-bd8b-4b8f-91f6-25b499f892e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.950450  0.900937   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.921171  0.843378   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.916667  0.835787   \n",
            "3                             KNeighborsClassifier()  0.826577  0.659616   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.954955  0.909910   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.934685  0.871930   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.943694  0.888913   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.959459  0.918956   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.961712  0.924559   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.900901   0.946429  0.954955  0.950673     0.945946     0.954955  \n",
            "1  0.842342   0.943128  0.896396  0.919169     0.945946     0.896396  \n",
            "2  0.833333   0.951220  0.878378  0.913349     0.954955     0.878378  \n",
            "3  0.653153   0.879581  0.756757  0.813559     0.896396     0.756757  \n",
            "4  0.909910   0.954955  0.954955  0.954955     0.954955     0.954955  \n",
            "5  0.869369   0.903766  0.972973  0.937093     0.896396     0.972973  \n",
            "6  0.887387   0.919149  0.972973  0.945295     0.914414     0.972973  \n",
            "7  0.918919   0.955357  0.963964  0.959641     0.954955     0.963964  \n",
            "8  0.923423   0.985782  0.936937  0.960739     0.986486     0.936937  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "n6YO25x0l8NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "roioSspYl-Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "51PEl5fAmATr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUCSXP3SmF2D",
        "outputId": "569cadb7-a73a-4ac4-f958-05d75834744d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.973706  0.828727   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.943366  0.604509   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.932039  0.475177   \n",
            "3                             KNeighborsClassifier()  0.948220  0.639243   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907265   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.956311  0.715873   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987460  0.923781   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.989887  0.937785   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990291  0.939987   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.818944   0.970060  0.729730  0.832905     0.997778     0.729730  \n",
            "1  0.588400   0.784722  0.509009  0.617486     0.986222     0.509009  \n",
            "2  0.372998   0.982143  0.247748  0.395683     0.999556     0.247748  \n",
            "3  0.620014   0.835714  0.527027  0.646409     0.989778     0.527027  \n",
            "4  0.907125   0.930233  0.900901  0.915332     0.993333     0.900901  \n",
            "5  0.712944   0.803191  0.680180  0.736585     0.983556     0.680180  \n",
            "6  0.923756   0.924444  0.936937  0.930649     0.992444     0.936937  \n",
            "7  0.937759   0.949772  0.936937  0.943311     0.995111     0.936937  \n",
            "8  0.939880   0.958333  0.932432  0.945205     0.996000     0.932432  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "5lhzV8jx3xXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Hr_HeLHM3zqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/AAC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "ah6zRD6032W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(AAC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18itG_Gp37yk",
        "outputId": "3cd24743-a97a-48df-bba3-bb55adc297f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.4824594\ttotal: 10.5ms\tremaining: 463ms\n",
            "1:\tlearn: 0.3844909\ttotal: 20.9ms\tremaining: 450ms\n",
            "2:\tlearn: 0.2901433\ttotal: 31.2ms\tremaining: 437ms\n",
            "3:\tlearn: 0.2331804\ttotal: 41.6ms\tremaining: 427ms\n",
            "4:\tlearn: 0.1894703\ttotal: 51.8ms\tremaining: 414ms\n",
            "5:\tlearn: 0.1646907\ttotal: 61.8ms\tremaining: 402ms\n",
            "6:\tlearn: 0.1416311\ttotal: 86.9ms\tremaining: 472ms\n",
            "7:\tlearn: 0.1183332\ttotal: 103ms\tremaining: 477ms\n",
            "8:\tlearn: 0.1094611\ttotal: 113ms\tremaining: 450ms\n",
            "9:\tlearn: 0.0918857\ttotal: 123ms\tremaining: 429ms\n",
            "10:\tlearn: 0.0856434\ttotal: 132ms\tremaining: 409ms\n",
            "11:\tlearn: 0.0705944\ttotal: 143ms\tremaining: 393ms\n",
            "12:\tlearn: 0.0663252\ttotal: 153ms\tremaining: 377ms\n",
            "13:\tlearn: 0.0610828\ttotal: 163ms\tremaining: 362ms\n",
            "14:\tlearn: 0.0577424\ttotal: 173ms\tremaining: 346ms\n",
            "15:\tlearn: 0.0512666\ttotal: 183ms\tremaining: 332ms\n",
            "16:\tlearn: 0.0461945\ttotal: 193ms\tremaining: 318ms\n",
            "17:\tlearn: 0.0417817\ttotal: 204ms\tremaining: 306ms\n",
            "18:\tlearn: 0.0405127\ttotal: 217ms\tremaining: 297ms\n",
            "19:\tlearn: 0.0373893\ttotal: 227ms\tremaining: 284ms\n",
            "20:\tlearn: 0.0349084\ttotal: 237ms\tremaining: 271ms\n",
            "21:\tlearn: 0.0340239\ttotal: 250ms\tremaining: 261ms\n",
            "22:\tlearn: 0.0314321\ttotal: 260ms\tremaining: 249ms\n",
            "23:\tlearn: 0.0298489\ttotal: 270ms\tremaining: 236ms\n",
            "24:\tlearn: 0.0281773\ttotal: 280ms\tremaining: 224ms\n",
            "25:\tlearn: 0.0274851\ttotal: 289ms\tremaining: 212ms\n",
            "26:\tlearn: 0.0263725\ttotal: 299ms\tremaining: 200ms\n",
            "27:\tlearn: 0.0247508\ttotal: 309ms\tremaining: 188ms\n",
            "28:\tlearn: 0.0235160\ttotal: 319ms\tremaining: 176ms\n",
            "29:\tlearn: 0.0212483\ttotal: 330ms\tremaining: 165ms\n",
            "30:\tlearn: 0.0206700\ttotal: 339ms\tremaining: 153ms\n",
            "31:\tlearn: 0.0203398\ttotal: 349ms\tremaining: 142ms\n",
            "32:\tlearn: 0.0195648\ttotal: 359ms\tremaining: 131ms\n",
            "33:\tlearn: 0.0188348\ttotal: 369ms\tremaining: 119ms\n",
            "34:\tlearn: 0.0178640\ttotal: 379ms\tremaining: 108ms\n",
            "35:\tlearn: 0.0167858\ttotal: 389ms\tremaining: 97.3ms\n",
            "36:\tlearn: 0.0161322\ttotal: 400ms\tremaining: 86.4ms\n",
            "37:\tlearn: 0.0156696\ttotal: 409ms\tremaining: 75.4ms\n",
            "38:\tlearn: 0.0151970\ttotal: 422ms\tremaining: 64.9ms\n",
            "39:\tlearn: 0.0142282\ttotal: 432ms\tremaining: 54ms\n",
            "40:\tlearn: 0.0132572\ttotal: 442ms\tremaining: 43.1ms\n",
            "41:\tlearn: 0.0124606\ttotal: 452ms\tremaining: 32.3ms\n",
            "42:\tlearn: 0.0115935\ttotal: 464ms\tremaining: 21.6ms\n",
            "43:\tlearn: 0.0113028\ttotal: 474ms\tremaining: 10.8ms\n",
            "44:\tlearn: 0.0106997\ttotal: 484ms\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2204, number of negative: 2250\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5083\n",
            "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494836 -> initscore=-0.020656\n",
            "[LightGBM] [Info] Start training from score -0.020656\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.4824594\ttotal: 10.2ms\tremaining: 449ms\n",
            "1:\tlearn: 0.3844909\ttotal: 20.8ms\tremaining: 448ms\n",
            "2:\tlearn: 0.2901433\ttotal: 31ms\tremaining: 433ms\n",
            "3:\tlearn: 0.2331804\ttotal: 40.9ms\tremaining: 419ms\n",
            "4:\tlearn: 0.1894703\ttotal: 51.2ms\tremaining: 410ms\n",
            "5:\tlearn: 0.1646907\ttotal: 61ms\tremaining: 397ms\n",
            "6:\tlearn: 0.1416311\ttotal: 71.2ms\tremaining: 386ms\n",
            "7:\tlearn: 0.1183332\ttotal: 81.1ms\tremaining: 375ms\n",
            "8:\tlearn: 0.1094611\ttotal: 91ms\tremaining: 364ms\n",
            "9:\tlearn: 0.0918857\ttotal: 101ms\tremaining: 354ms\n",
            "10:\tlearn: 0.0856434\ttotal: 111ms\tremaining: 343ms\n",
            "11:\tlearn: 0.0705944\ttotal: 121ms\tremaining: 332ms\n",
            "12:\tlearn: 0.0663252\ttotal: 131ms\tremaining: 321ms\n",
            "13:\tlearn: 0.0610828\ttotal: 140ms\tremaining: 311ms\n",
            "14:\tlearn: 0.0577424\ttotal: 151ms\tremaining: 301ms\n",
            "15:\tlearn: 0.0512666\ttotal: 160ms\tremaining: 291ms\n",
            "16:\tlearn: 0.0461945\ttotal: 170ms\tremaining: 280ms\n",
            "17:\tlearn: 0.0417817\ttotal: 180ms\tremaining: 270ms\n",
            "18:\tlearn: 0.0405127\ttotal: 190ms\tremaining: 260ms\n",
            "19:\tlearn: 0.0373893\ttotal: 200ms\tremaining: 250ms\n",
            "20:\tlearn: 0.0349084\ttotal: 213ms\tremaining: 243ms\n",
            "21:\tlearn: 0.0340239\ttotal: 223ms\tremaining: 233ms\n",
            "22:\tlearn: 0.0314321\ttotal: 233ms\tremaining: 223ms\n",
            "23:\tlearn: 0.0298489\ttotal: 243ms\tremaining: 212ms\n",
            "24:\tlearn: 0.0281773\ttotal: 252ms\tremaining: 202ms\n",
            "25:\tlearn: 0.0274851\ttotal: 262ms\tremaining: 191ms\n",
            "26:\tlearn: 0.0263725\ttotal: 271ms\tremaining: 181ms\n",
            "27:\tlearn: 0.0247508\ttotal: 281ms\tremaining: 171ms\n",
            "28:\tlearn: 0.0235160\ttotal: 291ms\tremaining: 161ms\n",
            "29:\tlearn: 0.0212483\ttotal: 301ms\tremaining: 151ms\n",
            "30:\tlearn: 0.0206700\ttotal: 311ms\tremaining: 140ms\n",
            "31:\tlearn: 0.0203398\ttotal: 320ms\tremaining: 130ms\n",
            "32:\tlearn: 0.0195648\ttotal: 330ms\tremaining: 120ms\n",
            "33:\tlearn: 0.0188348\ttotal: 340ms\tremaining: 110ms\n",
            "34:\tlearn: 0.0178640\ttotal: 350ms\tremaining: 100ms\n",
            "35:\tlearn: 0.0167858\ttotal: 361ms\tremaining: 90.3ms\n",
            "36:\tlearn: 0.0161322\ttotal: 372ms\tremaining: 80.4ms\n",
            "37:\tlearn: 0.0156696\ttotal: 381ms\tremaining: 70.2ms\n",
            "38:\tlearn: 0.0151970\ttotal: 391ms\tremaining: 60.2ms\n",
            "39:\tlearn: 0.0142282\ttotal: 401ms\tremaining: 50.1ms\n",
            "40:\tlearn: 0.0132572\ttotal: 412ms\tremaining: 40.2ms\n",
            "41:\tlearn: 0.0124606\ttotal: 422ms\tremaining: 30.2ms\n",
            "42:\tlearn: 0.0115935\ttotal: 432ms\tremaining: 20.1ms\n",
            "43:\tlearn: 0.0113028\ttotal: 442ms\tremaining: 10ms\n",
            "44:\tlearn: 0.0106997\ttotal: 452ms\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 2204, number of negative: 2250\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5083\n",
            "[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494836 -> initscore=-0.020656\n",
            "[LightGBM] [Info] Start training from score -0.020656\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.5078403\ttotal: 9.94ms\tremaining: 437ms\n",
            "1:\tlearn: 0.3839181\ttotal: 22.4ms\tremaining: 481ms\n",
            "2:\tlearn: 0.2998022\ttotal: 32.8ms\tremaining: 459ms\n",
            "3:\tlearn: 0.2390905\ttotal: 42.6ms\tremaining: 437ms\n",
            "4:\tlearn: 0.1947567\ttotal: 52.2ms\tremaining: 418ms\n",
            "5:\tlearn: 0.1705027\ttotal: 61.9ms\tremaining: 402ms\n",
            "6:\tlearn: 0.1464200\ttotal: 71.5ms\tremaining: 388ms\n",
            "7:\tlearn: 0.1324550\ttotal: 81.1ms\tremaining: 375ms\n",
            "8:\tlearn: 0.1121499\ttotal: 91.2ms\tremaining: 365ms\n",
            "9:\tlearn: 0.1022551\ttotal: 101ms\tremaining: 352ms\n",
            "10:\tlearn: 0.0887455\ttotal: 116ms\tremaining: 357ms\n",
            "11:\tlearn: 0.0803623\ttotal: 125ms\tremaining: 345ms\n",
            "12:\tlearn: 0.0750806\ttotal: 135ms\tremaining: 332ms\n",
            "13:\tlearn: 0.0715223\ttotal: 144ms\tremaining: 319ms\n",
            "14:\tlearn: 0.0652032\ttotal: 154ms\tremaining: 307ms\n",
            "15:\tlearn: 0.0596696\ttotal: 164ms\tremaining: 296ms\n",
            "16:\tlearn: 0.0551443\ttotal: 173ms\tremaining: 284ms\n",
            "17:\tlearn: 0.0509237\ttotal: 182ms\tremaining: 274ms\n",
            "18:\tlearn: 0.0476604\ttotal: 192ms\tremaining: 262ms\n",
            "19:\tlearn: 0.0434841\ttotal: 201ms\tremaining: 251ms\n",
            "20:\tlearn: 0.0402423\ttotal: 213ms\tremaining: 243ms\n",
            "21:\tlearn: 0.0392468\ttotal: 222ms\tremaining: 232ms\n",
            "22:\tlearn: 0.0385826\ttotal: 232ms\tremaining: 222ms\n",
            "23:\tlearn: 0.0361097\ttotal: 241ms\tremaining: 211ms\n",
            "24:\tlearn: 0.0326647\ttotal: 250ms\tremaining: 200ms\n",
            "25:\tlearn: 0.0303160\ttotal: 260ms\tremaining: 190ms\n",
            "26:\tlearn: 0.0282400\ttotal: 270ms\tremaining: 180ms\n",
            "27:\tlearn: 0.0264269\ttotal: 280ms\tremaining: 170ms\n",
            "28:\tlearn: 0.0247643\ttotal: 290ms\tremaining: 160ms\n",
            "29:\tlearn: 0.0240446\ttotal: 300ms\tremaining: 150ms\n",
            "30:\tlearn: 0.0227295\ttotal: 310ms\tremaining: 140ms\n",
            "31:\tlearn: 0.0218188\ttotal: 320ms\tremaining: 130ms\n",
            "32:\tlearn: 0.0206673\ttotal: 331ms\tremaining: 120ms\n",
            "33:\tlearn: 0.0196507\ttotal: 341ms\tremaining: 110ms\n",
            "34:\tlearn: 0.0171582\ttotal: 350ms\tremaining: 100ms\n",
            "35:\tlearn: 0.0170747\ttotal: 360ms\tremaining: 90.1ms\n",
            "36:\tlearn: 0.0159496\ttotal: 373ms\tremaining: 80.6ms\n",
            "37:\tlearn: 0.0147724\ttotal: 382ms\tremaining: 70.5ms\n",
            "38:\tlearn: 0.0145342\ttotal: 392ms\tremaining: 60.4ms\n",
            "39:\tlearn: 0.0135919\ttotal: 402ms\tremaining: 50.2ms\n",
            "40:\tlearn: 0.0135306\ttotal: 415ms\tremaining: 40.5ms\n",
            "41:\tlearn: 0.0125748\ttotal: 428ms\tremaining: 30.6ms\n",
            "42:\tlearn: 0.0121532\ttotal: 439ms\tremaining: 20.4ms\n",
            "43:\tlearn: 0.0118011\ttotal: 449ms\tremaining: 10.2ms\n",
            "44:\tlearn: 0.0113029\ttotal: 458ms\tremaining: 0us\n",
            "0:\tlearn: 0.4889887\ttotal: 9.78ms\tremaining: 430ms\n",
            "1:\tlearn: 0.3667493\ttotal: 19.6ms\tremaining: 422ms\n",
            "2:\tlearn: 0.2780246\ttotal: 29.4ms\tremaining: 412ms\n",
            "3:\tlearn: 0.2306129\ttotal: 39ms\tremaining: 399ms\n",
            "4:\tlearn: 0.2009210\ttotal: 49.1ms\tremaining: 393ms\n",
            "5:\tlearn: 0.1728898\ttotal: 58.7ms\tremaining: 382ms\n",
            "6:\tlearn: 0.1520808\ttotal: 68.5ms\tremaining: 372ms\n",
            "7:\tlearn: 0.1268195\ttotal: 78.2ms\tremaining: 362ms\n",
            "8:\tlearn: 0.1100944\ttotal: 88ms\tremaining: 352ms\n",
            "9:\tlearn: 0.1002562\ttotal: 97.5ms\tremaining: 341ms\n",
            "10:\tlearn: 0.0951722\ttotal: 107ms\tremaining: 330ms\n",
            "11:\tlearn: 0.0874489\ttotal: 120ms\tremaining: 330ms\n",
            "12:\tlearn: 0.0771060\ttotal: 129ms\tremaining: 319ms\n",
            "13:\tlearn: 0.0713855\ttotal: 139ms\tremaining: 308ms\n",
            "14:\tlearn: 0.0646160\ttotal: 149ms\tremaining: 299ms\n",
            "15:\tlearn: 0.0557787\ttotal: 159ms\tremaining: 288ms\n",
            "16:\tlearn: 0.0518120\ttotal: 169ms\tremaining: 278ms\n",
            "17:\tlearn: 0.0490890\ttotal: 179ms\tremaining: 268ms\n",
            "18:\tlearn: 0.0454068\ttotal: 191ms\tremaining: 261ms\n",
            "19:\tlearn: 0.0426532\ttotal: 200ms\tremaining: 251ms\n",
            "20:\tlearn: 0.0385308\ttotal: 210ms\tremaining: 240ms\n",
            "21:\tlearn: 0.0367300\ttotal: 220ms\tremaining: 230ms\n",
            "22:\tlearn: 0.0352200\ttotal: 229ms\tremaining: 219ms\n",
            "23:\tlearn: 0.0339143\ttotal: 239ms\tremaining: 209ms\n",
            "24:\tlearn: 0.0322993\ttotal: 250ms\tremaining: 200ms\n",
            "25:\tlearn: 0.0301001\ttotal: 260ms\tremaining: 190ms\n",
            "26:\tlearn: 0.0284557\ttotal: 270ms\tremaining: 180ms\n",
            "27:\tlearn: 0.0271103\ttotal: 279ms\tremaining: 169ms\n",
            "28:\tlearn: 0.0262289\ttotal: 290ms\tremaining: 160ms\n",
            "29:\tlearn: 0.0249030\ttotal: 300ms\tremaining: 150ms\n",
            "30:\tlearn: 0.0232621\ttotal: 310ms\tremaining: 140ms\n",
            "31:\tlearn: 0.0210497\ttotal: 322ms\tremaining: 131ms\n",
            "32:\tlearn: 0.0207705\ttotal: 332ms\tremaining: 121ms\n",
            "33:\tlearn: 0.0193363\ttotal: 342ms\tremaining: 111ms\n",
            "34:\tlearn: 0.0183260\ttotal: 352ms\tremaining: 101ms\n",
            "35:\tlearn: 0.0181247\ttotal: 362ms\tremaining: 90.4ms\n",
            "36:\tlearn: 0.0174737\ttotal: 372ms\tremaining: 80.4ms\n",
            "37:\tlearn: 0.0168378\ttotal: 382ms\tremaining: 70.3ms\n",
            "38:\tlearn: 0.0164105\ttotal: 397ms\tremaining: 61.2ms\n",
            "39:\tlearn: 0.0152258\ttotal: 417ms\tremaining: 52.1ms\n",
            "40:\tlearn: 0.0145184\ttotal: 432ms\tremaining: 42.1ms\n",
            "41:\tlearn: 0.0133968\ttotal: 442ms\tremaining: 31.6ms\n",
            "42:\tlearn: 0.0121915\ttotal: 452ms\tremaining: 21ms\n",
            "43:\tlearn: 0.0119462\ttotal: 462ms\tremaining: 10.5ms\n",
            "44:\tlearn: 0.0117172\ttotal: 472ms\tremaining: 0us\n",
            "0:\tlearn: 0.5029594\ttotal: 13ms\tremaining: 573ms\n",
            "1:\tlearn: 0.3856751\ttotal: 22.8ms\tremaining: 490ms\n",
            "2:\tlearn: 0.3094358\ttotal: 32.6ms\tremaining: 456ms\n",
            "3:\tlearn: 0.2453910\ttotal: 42ms\tremaining: 431ms\n",
            "4:\tlearn: 0.2169071\ttotal: 51.6ms\tremaining: 413ms\n",
            "5:\tlearn: 0.1813502\ttotal: 61.6ms\tremaining: 401ms\n",
            "6:\tlearn: 0.1595634\ttotal: 71.7ms\tremaining: 389ms\n",
            "7:\tlearn: 0.1417689\ttotal: 81.5ms\tremaining: 377ms\n",
            "8:\tlearn: 0.1244769\ttotal: 91.4ms\tremaining: 366ms\n",
            "9:\tlearn: 0.1153340\ttotal: 101ms\tremaining: 353ms\n",
            "10:\tlearn: 0.1074848\ttotal: 110ms\tremaining: 341ms\n",
            "11:\tlearn: 0.1019885\ttotal: 120ms\tremaining: 329ms\n",
            "12:\tlearn: 0.0938414\ttotal: 130ms\tremaining: 320ms\n",
            "13:\tlearn: 0.0821557\ttotal: 140ms\tremaining: 309ms\n",
            "14:\tlearn: 0.0766056\ttotal: 149ms\tremaining: 299ms\n",
            "15:\tlearn: 0.0691500\ttotal: 159ms\tremaining: 288ms\n",
            "16:\tlearn: 0.0622034\ttotal: 168ms\tremaining: 277ms\n",
            "17:\tlearn: 0.0588892\ttotal: 178ms\tremaining: 267ms\n",
            "18:\tlearn: 0.0541362\ttotal: 187ms\tremaining: 256ms\n",
            "19:\tlearn: 0.0485194\ttotal: 197ms\tremaining: 246ms\n",
            "20:\tlearn: 0.0464410\ttotal: 207ms\tremaining: 236ms\n",
            "21:\tlearn: 0.0408852\ttotal: 220ms\tremaining: 230ms\n",
            "22:\tlearn: 0.0357729\ttotal: 232ms\tremaining: 222ms\n",
            "23:\tlearn: 0.0335848\ttotal: 243ms\tremaining: 212ms\n",
            "24:\tlearn: 0.0326901\ttotal: 252ms\tremaining: 202ms\n",
            "25:\tlearn: 0.0319390\ttotal: 262ms\tremaining: 191ms\n",
            "26:\tlearn: 0.0311793\ttotal: 272ms\tremaining: 181ms\n",
            "27:\tlearn: 0.0291918\ttotal: 281ms\tremaining: 171ms\n",
            "28:\tlearn: 0.0261593\ttotal: 291ms\tremaining: 160ms\n",
            "29:\tlearn: 0.0234303\ttotal: 301ms\tremaining: 150ms\n",
            "30:\tlearn: 0.0222444\ttotal: 310ms\tremaining: 140ms\n",
            "31:\tlearn: 0.0203245\ttotal: 320ms\tremaining: 130ms\n",
            "32:\tlearn: 0.0199672\ttotal: 330ms\tremaining: 120ms\n",
            "33:\tlearn: 0.0189258\ttotal: 340ms\tremaining: 110ms\n",
            "34:\tlearn: 0.0173558\ttotal: 349ms\tremaining: 99.7ms\n",
            "35:\tlearn: 0.0159445\ttotal: 359ms\tremaining: 89.8ms\n",
            "36:\tlearn: 0.0151446\ttotal: 369ms\tremaining: 79.8ms\n",
            "37:\tlearn: 0.0146221\ttotal: 378ms\tremaining: 69.7ms\n",
            "38:\tlearn: 0.0133553\ttotal: 388ms\tremaining: 59.7ms\n",
            "39:\tlearn: 0.0129294\ttotal: 398ms\tremaining: 49.7ms\n",
            "40:\tlearn: 0.0120601\ttotal: 407ms\tremaining: 39.7ms\n",
            "41:\tlearn: 0.0118796\ttotal: 417ms\tremaining: 29.8ms\n",
            "42:\tlearn: 0.0115004\ttotal: 429ms\tremaining: 20ms\n",
            "43:\tlearn: 0.0110830\ttotal: 439ms\tremaining: 9.98ms\n",
            "44:\tlearn: 0.0105852\ttotal: 449ms\tremaining: 0us\n",
            "0:\tlearn: 0.4602440\ttotal: 10ms\tremaining: 442ms\n",
            "1:\tlearn: 0.3396425\ttotal: 20.6ms\tremaining: 442ms\n",
            "2:\tlearn: 0.2572242\ttotal: 30.6ms\tremaining: 428ms\n",
            "3:\tlearn: 0.2196778\ttotal: 41.8ms\tremaining: 428ms\n",
            "4:\tlearn: 0.1793613\ttotal: 51.4ms\tremaining: 411ms\n",
            "5:\tlearn: 0.1523398\ttotal: 61.2ms\tremaining: 398ms\n",
            "6:\tlearn: 0.1349023\ttotal: 70.8ms\tremaining: 384ms\n",
            "7:\tlearn: 0.1174260\ttotal: 80.5ms\tremaining: 372ms\n",
            "8:\tlearn: 0.1085962\ttotal: 90.4ms\tremaining: 362ms\n",
            "9:\tlearn: 0.1014623\ttotal: 99.9ms\tremaining: 350ms\n",
            "10:\tlearn: 0.0949127\ttotal: 110ms\tremaining: 339ms\n",
            "11:\tlearn: 0.0830823\ttotal: 119ms\tremaining: 328ms\n",
            "12:\tlearn: 0.0747394\ttotal: 129ms\tremaining: 317ms\n",
            "13:\tlearn: 0.0694396\ttotal: 141ms\tremaining: 313ms\n",
            "14:\tlearn: 0.0642589\ttotal: 151ms\tremaining: 301ms\n",
            "15:\tlearn: 0.0569771\ttotal: 160ms\tremaining: 291ms\n",
            "16:\tlearn: 0.0537104\ttotal: 172ms\tremaining: 283ms\n",
            "17:\tlearn: 0.0498138\ttotal: 182ms\tremaining: 273ms\n",
            "18:\tlearn: 0.0467442\ttotal: 191ms\tremaining: 262ms\n",
            "19:\tlearn: 0.0446747\ttotal: 201ms\tremaining: 251ms\n",
            "20:\tlearn: 0.0397189\ttotal: 210ms\tremaining: 240ms\n",
            "21:\tlearn: 0.0372321\ttotal: 220ms\tremaining: 230ms\n",
            "22:\tlearn: 0.0368226\ttotal: 232ms\tremaining: 222ms\n",
            "23:\tlearn: 0.0352164\ttotal: 241ms\tremaining: 211ms\n",
            "24:\tlearn: 0.0344633\ttotal: 251ms\tremaining: 200ms\n",
            "25:\tlearn: 0.0318137\ttotal: 260ms\tremaining: 190ms\n",
            "26:\tlearn: 0.0299004\ttotal: 270ms\tremaining: 180ms\n",
            "27:\tlearn: 0.0282124\ttotal: 279ms\tremaining: 170ms\n",
            "28:\tlearn: 0.0255694\ttotal: 289ms\tremaining: 159ms\n",
            "29:\tlearn: 0.0240397\ttotal: 299ms\tremaining: 150ms\n",
            "30:\tlearn: 0.0229400\ttotal: 309ms\tremaining: 139ms\n",
            "31:\tlearn: 0.0215841\ttotal: 318ms\tremaining: 129ms\n",
            "32:\tlearn: 0.0206587\ttotal: 328ms\tremaining: 119ms\n",
            "33:\tlearn: 0.0198933\ttotal: 338ms\tremaining: 109ms\n",
            "34:\tlearn: 0.0183852\ttotal: 351ms\tremaining: 100ms\n",
            "35:\tlearn: 0.0174164\ttotal: 361ms\tremaining: 90.2ms\n",
            "36:\tlearn: 0.0172900\ttotal: 370ms\tremaining: 80ms\n",
            "37:\tlearn: 0.0165000\ttotal: 380ms\tremaining: 70ms\n",
            "38:\tlearn: 0.0159368\ttotal: 389ms\tremaining: 59.9ms\n",
            "39:\tlearn: 0.0155478\ttotal: 399ms\tremaining: 49.9ms\n",
            "40:\tlearn: 0.0152077\ttotal: 415ms\tremaining: 40.5ms\n",
            "41:\tlearn: 0.0144665\ttotal: 437ms\tremaining: 31.2ms\n",
            "42:\tlearn: 0.0140907\ttotal: 448ms\tremaining: 20.9ms\n",
            "43:\tlearn: 0.0133768\ttotal: 459ms\tremaining: 10.4ms\n",
            "44:\tlearn: 0.0123615\ttotal: 469ms\tremaining: 0us\n",
            "0:\tlearn: 0.5086615\ttotal: 11.3ms\tremaining: 497ms\n",
            "1:\tlearn: 0.3664121\ttotal: 22ms\tremaining: 472ms\n",
            "2:\tlearn: 0.2733555\ttotal: 32.9ms\tremaining: 460ms\n",
            "3:\tlearn: 0.2280614\ttotal: 44.9ms\tremaining: 460ms\n",
            "4:\tlearn: 0.1847436\ttotal: 55ms\tremaining: 440ms\n",
            "5:\tlearn: 0.1502472\ttotal: 64.7ms\tremaining: 421ms\n",
            "6:\tlearn: 0.1322432\ttotal: 74.5ms\tremaining: 404ms\n",
            "7:\tlearn: 0.1185671\ttotal: 84.6ms\tremaining: 391ms\n",
            "8:\tlearn: 0.1031555\ttotal: 94.2ms\tremaining: 377ms\n",
            "9:\tlearn: 0.0951703\ttotal: 104ms\tremaining: 364ms\n",
            "10:\tlearn: 0.0823304\ttotal: 114ms\tremaining: 351ms\n",
            "11:\tlearn: 0.0781632\ttotal: 123ms\tremaining: 339ms\n",
            "12:\tlearn: 0.0682811\ttotal: 133ms\tremaining: 326ms\n",
            "13:\tlearn: 0.0641133\ttotal: 142ms\tremaining: 314ms\n",
            "14:\tlearn: 0.0603217\ttotal: 151ms\tremaining: 303ms\n",
            "15:\tlearn: 0.0557525\ttotal: 161ms\tremaining: 293ms\n",
            "16:\tlearn: 0.0532817\ttotal: 171ms\tremaining: 281ms\n",
            "17:\tlearn: 0.0484700\ttotal: 180ms\tremaining: 270ms\n",
            "18:\tlearn: 0.0462083\ttotal: 190ms\tremaining: 260ms\n",
            "19:\tlearn: 0.0416633\ttotal: 200ms\tremaining: 250ms\n",
            "20:\tlearn: 0.0374378\ttotal: 209ms\tremaining: 239ms\n",
            "21:\tlearn: 0.0356811\ttotal: 219ms\tremaining: 229ms\n",
            "22:\tlearn: 0.0351277\ttotal: 228ms\tremaining: 218ms\n",
            "23:\tlearn: 0.0330603\ttotal: 238ms\tremaining: 208ms\n",
            "24:\tlearn: 0.0325126\ttotal: 250ms\tremaining: 200ms\n",
            "25:\tlearn: 0.0296737\ttotal: 260ms\tremaining: 190ms\n",
            "26:\tlearn: 0.0273568\ttotal: 270ms\tremaining: 180ms\n",
            "27:\tlearn: 0.0262643\ttotal: 279ms\tremaining: 169ms\n",
            "28:\tlearn: 0.0260205\ttotal: 289ms\tremaining: 159ms\n",
            "29:\tlearn: 0.0247529\ttotal: 299ms\tremaining: 149ms\n",
            "30:\tlearn: 0.0239313\ttotal: 308ms\tremaining: 139ms\n",
            "31:\tlearn: 0.0228958\ttotal: 318ms\tremaining: 129ms\n",
            "32:\tlearn: 0.0211364\ttotal: 328ms\tremaining: 119ms\n",
            "33:\tlearn: 0.0206261\ttotal: 338ms\tremaining: 109ms\n",
            "34:\tlearn: 0.0193615\ttotal: 347ms\tremaining: 99.1ms\n",
            "35:\tlearn: 0.0180829\ttotal: 357ms\tremaining: 89.2ms\n",
            "36:\tlearn: 0.0165322\ttotal: 367ms\tremaining: 79.3ms\n",
            "37:\tlearn: 0.0156524\ttotal: 378ms\tremaining: 69.6ms\n",
            "38:\tlearn: 0.0143728\ttotal: 388ms\tremaining: 59.6ms\n",
            "39:\tlearn: 0.0134103\ttotal: 397ms\tremaining: 49.7ms\n",
            "40:\tlearn: 0.0124076\ttotal: 407ms\tremaining: 39.7ms\n",
            "41:\tlearn: 0.0115601\ttotal: 416ms\tremaining: 29.7ms\n",
            "42:\tlearn: 0.0114322\ttotal: 427ms\tremaining: 19.9ms\n",
            "43:\tlearn: 0.0111933\ttotal: 437ms\tremaining: 9.93ms\n",
            "44:\tlearn: 0.0103816\ttotal: 446ms\tremaining: 0us\n",
            "[LightGBM] [Info] Number of positive: 1763, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5076\n",
            "[LightGBM] [Info] Number of data points in the train set: 3563, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494808 -> initscore=-0.020770\n",
            "[LightGBM] [Info] Start training from score -0.020770\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1763, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5083\n",
            "[LightGBM] [Info] Number of data points in the train set: 3563, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494808 -> initscore=-0.020770\n",
            "[LightGBM] [Info] Start training from score -0.020770\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1763, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5077\n",
            "[LightGBM] [Info] Number of data points in the train set: 3563, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494808 -> initscore=-0.020770\n",
            "[LightGBM] [Info] Start training from score -0.020770\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1763, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5075\n",
            "[LightGBM] [Info] Number of data points in the train set: 3563, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494808 -> initscore=-0.020770\n",
            "[LightGBM] [Info] Start training from score -0.020770\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1764, number of negative: 1800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5080\n",
            "[LightGBM] [Info] Number of data points in the train set: 3564, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494949 -> initscore=-0.020203\n",
            "[LightGBM] [Info] Start training from score -0.020203\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.974110  0.837845   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.886731  0.547865   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.936893  0.685489   \n",
            "3                             KNeighborsClassifier()  0.930421  0.665088   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.967638  0.800420   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.886731  0.522722   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.969256  0.811981   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.962783  0.780422   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.983819  0.896480   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.837673   0.867925  0.836364  0.851852     0.987567     0.836364  \n",
            "1  0.510334   0.429907  0.836364  0.567901     0.891652     0.836364  \n",
            "2  0.672589   0.602564  0.854545  0.706767     0.944938     0.854545  \n",
            "3  0.648706   0.573171  0.854545  0.686131     0.937833     0.854545  \n",
            "4  0.800420   0.818182  0.818182  0.818182     0.982238     0.818182  \n",
            "5  0.492837   0.425743  0.781818  0.551282     0.896980     0.781818  \n",
            "6  0.811941   0.821429  0.836364  0.828829     0.982238     0.836364  \n",
            "7  0.779525   0.766667  0.836364  0.800000     0.975133     0.836364  \n",
            "8  0.893202   0.978723  0.836364  0.901961     0.998224     0.836364  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CTDC**"
      ],
      "metadata": {
        "id": "vFklypxYteEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "anV1VVLf58m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ivoj_mmttgRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C703JLHVtxFa",
        "outputId": "ad0890e0-0256-47d5-eafe-0ad0c0c97769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.967233  0.783627   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953074  0.679408   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.955097  0.689450   \n",
            "3                             KNeighborsClassifier()  0.948220  0.645854   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960761  0.745603   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987864  0.926077   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.987864  0.924955   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.988269  0.926666   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.774376   0.922156  0.693694  0.791774     0.994222     0.693694  \n",
            "1  0.665416   0.848684  0.581081  0.689840     0.989778     0.581081  \n",
            "2  0.654493   0.958678  0.522523  0.676385     0.997778     0.522523  \n",
            "3  0.634265   0.801282  0.563063  0.661376     0.986222     0.563063  \n",
            "4  0.907506   0.926267  0.905405  0.915718     0.992889     0.905405  \n",
            "5  0.742742   0.830688  0.707207  0.763990     0.985778     0.707207  \n",
            "6  0.926066   0.928571  0.936937  0.932735     0.992889     0.936937  \n",
            "7  0.924850   0.944444  0.918919  0.931507     0.994667     0.918919  \n",
            "8  0.925986   0.966184  0.900901  0.932401     0.996889     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "j38w7F9Vt6Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "MYhjqz36t8P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "GcqRP1xSt-hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxUY-6_nuE3T",
        "outputId": "6b704303-95a0-40c2-849e-85bf47e89af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.974745  0.949608   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.807045  0.614906   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.844705  0.701414   \n",
            "3                             KNeighborsClassifier()  0.940408  0.887098   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985600  0.971577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.939521  0.880014   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.989809  0.979757   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988259  0.976710   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.996899  0.993811   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.949487   0.967391  0.982774  0.975022     0.966667     0.982774  \n",
            "1  0.614022   0.792034  0.834364  0.812648     0.779556     0.834364  \n",
            "2  0.689584   0.922204  0.753975  0.829648     0.936000     0.753975  \n",
            "3  0.880770   0.893802  1.000000  0.943923     0.880444     1.000000  \n",
            "4  0.971198   0.972497  0.999558  0.985842     0.971556     0.999558  \n",
            "5  0.879024   0.919865  0.963339  0.941100     0.915556     0.963339  \n",
            "6  0.979618   0.981755  0.998233  0.989926     0.981333     0.998233  \n",
            "7  0.976516   0.978779  0.998233  0.988410     0.978222     0.998233  \n",
            "8  0.993797   0.994288  0.999558  0.996916     0.994222     0.999558  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "n6bX2r_XuMFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "iNDXhKKUuOnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "JRgu-1KTuQ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZBOBNNEuWVy",
        "outputId": "c7e08f61-6a16-4dda-9c4b-106ebb8ebfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.988444  0.976965   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.948444  0.896902   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.966000  0.933017   \n",
            "3                             KNeighborsClassifier()  0.976667  0.953541   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.990000  0.980001   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.982889  0.965799   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.992667  0.985333   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.993333  0.986667   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.978889  0.958495   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.976889   0.994599  0.982222  0.988372     0.994667     0.982222  \n",
            "1  0.896889   0.950849  0.945778  0.948307     0.951111     0.945778  \n",
            "2  0.932000   0.988811  0.942667  0.965188     0.989333     0.942667  \n",
            "3  0.953333   0.986836  0.966222  0.976420     0.987111     0.966222  \n",
            "4  0.980000   0.989348  0.990667  0.990007     0.989333     0.990667  \n",
            "5  0.965778   0.986130  0.979556  0.982832     0.986222     0.979556  \n",
            "6  0.985333   0.992448  0.992889  0.992668     0.992444     0.992889  \n",
            "7  0.986667   0.993772  0.992889  0.993330     0.993778     0.992889  \n",
            "8  0.957778   0.998151  0.959556  0.978473     0.998222     0.959556  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "k2KoYXwBuf-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ypXk0fKjuj26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "fypSM6GZul8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBeKGDwhuq1M",
        "outputId": "f32cf449-8353-4dd9-aca0-c587e0d3aeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.976667  0.953436   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.840000  0.680017   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.867111  0.750065   \n",
            "3                             KNeighborsClassifier()  0.947778  0.900230   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985556  0.971242   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.947111  0.894240   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.985778  0.971631   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.988000  0.976031   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.990444  0.980891   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.953333   0.983762  0.969333  0.976494     0.984000     0.969333  \n",
            "1  0.680000   0.842435  0.836444  0.839429     0.843556     0.836444  \n",
            "2  0.734222   0.961453  0.764889  0.851980     0.969333     0.764889  \n",
            "3  0.895556   0.906414  0.998667  0.950307     0.896889     0.998667  \n",
            "4  0.971111   0.977700  0.993778  0.985673     0.977333     0.993778  \n",
            "5  0.894222   0.944346  0.950222  0.947275     0.944000     0.950222  \n",
            "6  0.971556   0.979807  0.992000  0.985866     0.979556     0.992000  \n",
            "7  0.976000   0.984127  0.992000  0.988048     0.984000     0.992000  \n",
            "8  0.980889   0.991537  0.989333  0.990434     0.991556     0.989333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "hZOdhVTDuyx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "pJxI28Fiu070"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "13aFoQL9u3jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85FvUoEfu8Uy",
        "outputId": "2721faf1-117c-4f87-b34a-ee1c8e6aa991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.936937  0.875617   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.869369  0.741755   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.905405  0.821687   \n",
            "3                             KNeighborsClassifier()  0.869369  0.743094   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.961712  0.923508   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.943694  0.887396   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.952703  0.905415   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.963964  0.928079   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.961712  0.924559   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.873874   0.966346  0.905405  0.934884     0.968468     0.905405  \n",
            "1  0.738739   0.905941  0.824324  0.863208     0.914414     0.824324  \n",
            "2  0.810811   0.983871  0.824324  0.897059     0.986486     0.824324  \n",
            "3  0.738739   0.914141  0.815315  0.861905     0.923423     0.815315  \n",
            "4  0.923423   0.968037  0.954955  0.961451     0.968468     0.954955  \n",
            "5  0.887387   0.941704  0.945946  0.943820     0.941441     0.945946  \n",
            "6  0.905405   0.950673  0.954955  0.952809     0.950450     0.954955  \n",
            "7  0.927928   0.972477  0.954955  0.963636     0.972973     0.954955  \n",
            "8  0.923423   0.985782  0.936937  0.960739     0.986486     0.936937  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "AzQ0NEMnvATb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Z-PcIaJAvEVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "B-47KbOVvHIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4G4sPlhvLfq",
        "outputId": "e9d56326-b75a-40b0-b807-1805e552fc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.966828  0.780956   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.953074  0.680076   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.954288  0.682944   \n",
            "3                             KNeighborsClassifier()  0.948220  0.645854   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.985032  0.907577   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.960761  0.745603   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.987864  0.926077   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.987864  0.924955   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.987864  0.924182   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.772112   0.916667  0.693694  0.789744     0.993778     0.693694  \n",
            "1  0.666992   0.844156  0.585586  0.691489     0.989333     0.585586  \n",
            "2  0.644638   0.965812  0.509009  0.666667     0.998222     0.509009  \n",
            "3  0.634265   0.801282  0.563063  0.661376     0.986222     0.563063  \n",
            "4  0.907506   0.926267  0.905405  0.915718     0.992889     0.905405  \n",
            "5  0.742742   0.830688  0.707207  0.763990     0.985778     0.707207  \n",
            "6  0.926066   0.928571  0.936937  0.932735     0.992889     0.936937  \n",
            "7  0.924850   0.944444  0.918919  0.931507     0.994667     0.918919  \n",
            "8  0.923594   0.961538  0.900901  0.930233     0.996444     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "FXbrWS565Lr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "Tg4ndrjA5OHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/CTDC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest = df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "08F3_k8H5Q_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(CTDC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ohU8nHlHv3",
        "outputId": "684bc6d7-97a2-4407-a47a-a2b3123d96b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3586288\ttotal: 101ms\tremaining: 4.44s\n",
            "1:\tlearn: 0.2387314\ttotal: 133ms\tremaining: 2.86s\n",
            "2:\tlearn: 0.1838333\ttotal: 172ms\tremaining: 2.41s\n",
            "3:\tlearn: 0.1574430\ttotal: 209ms\tremaining: 2.14s\n",
            "4:\tlearn: 0.1386140\ttotal: 248ms\tremaining: 1.99s\n",
            "5:\tlearn: 0.1305302\ttotal: 289ms\tremaining: 1.88s\n",
            "6:\tlearn: 0.1233358\ttotal: 323ms\tremaining: 1.75s\n",
            "7:\tlearn: 0.1182270\ttotal: 359ms\tremaining: 1.66s\n",
            "8:\tlearn: 0.1038264\ttotal: 399ms\tremaining: 1.6s\n",
            "9:\tlearn: 0.0897411\ttotal: 430ms\tremaining: 1.5s\n",
            "10:\tlearn: 0.0825722\ttotal: 454ms\tremaining: 1.4s\n",
            "11:\tlearn: 0.0725579\ttotal: 479ms\tremaining: 1.32s\n",
            "12:\tlearn: 0.0647758\ttotal: 503ms\tremaining: 1.24s\n",
            "13:\tlearn: 0.0583320\ttotal: 533ms\tremaining: 1.18s\n",
            "14:\tlearn: 0.0535854\ttotal: 559ms\tremaining: 1.12s\n",
            "15:\tlearn: 0.0496486\ttotal: 599ms\tremaining: 1.09s\n",
            "16:\tlearn: 0.0474797\ttotal: 638ms\tremaining: 1.05s\n",
            "17:\tlearn: 0.0420768\ttotal: 680ms\tremaining: 1.02s\n",
            "18:\tlearn: 0.0381864\ttotal: 719ms\tremaining: 983ms\n",
            "19:\tlearn: 0.0366009\ttotal: 777ms\tremaining: 971ms\n",
            "20:\tlearn: 0.0353731\ttotal: 814ms\tremaining: 930ms\n",
            "21:\tlearn: 0.0346316\ttotal: 853ms\tremaining: 892ms\n",
            "22:\tlearn: 0.0336706\ttotal: 891ms\tremaining: 852ms\n",
            "23:\tlearn: 0.0315762\ttotal: 932ms\tremaining: 816ms\n",
            "24:\tlearn: 0.0305250\ttotal: 956ms\tremaining: 764ms\n",
            "25:\tlearn: 0.0269423\ttotal: 999ms\tremaining: 730ms\n",
            "26:\tlearn: 0.0248460\ttotal: 1.02s\tremaining: 683ms\n",
            "27:\tlearn: 0.0239162\ttotal: 1.05s\tremaining: 637ms\n",
            "28:\tlearn: 0.0224920\ttotal: 1.07s\tremaining: 592ms\n",
            "29:\tlearn: 0.0213980\ttotal: 1.11s\tremaining: 556ms\n",
            "30:\tlearn: 0.0197375\ttotal: 1.15s\tremaining: 518ms\n",
            "31:\tlearn: 0.0185057\ttotal: 1.18s\tremaining: 481ms\n",
            "32:\tlearn: 0.0176920\ttotal: 1.22s\tremaining: 445ms\n",
            "33:\tlearn: 0.0163918\ttotal: 1.26s\tremaining: 409ms\n",
            "34:\tlearn: 0.0150582\ttotal: 1.29s\tremaining: 369ms\n",
            "35:\tlearn: 0.0145251\ttotal: 1.33s\tremaining: 332ms\n",
            "36:\tlearn: 0.0139709\ttotal: 1.36s\tremaining: 293ms\n",
            "37:\tlearn: 0.0131429\ttotal: 1.39s\tremaining: 257ms\n",
            "38:\tlearn: 0.0127097\ttotal: 1.44s\tremaining: 221ms\n",
            "39:\tlearn: 0.0123042\ttotal: 1.47s\tremaining: 184ms\n",
            "40:\tlearn: 0.0119026\ttotal: 1.51s\tremaining: 147ms\n",
            "41:\tlearn: 0.0112949\ttotal: 1.53s\tremaining: 110ms\n",
            "42:\tlearn: 0.0105152\ttotal: 1.56s\tremaining: 72.8ms\n",
            "43:\tlearn: 0.0100410\ttotal: 1.6s\tremaining: 36.4ms\n",
            "44:\tlearn: 0.0098126\ttotal: 1.65s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9599\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3586288\ttotal: 52.8ms\tremaining: 2.32s\n",
            "1:\tlearn: 0.2387314\ttotal: 81.5ms\tremaining: 1.75s\n",
            "2:\tlearn: 0.1838333\ttotal: 120ms\tremaining: 1.69s\n",
            "3:\tlearn: 0.1574430\ttotal: 159ms\tremaining: 1.63s\n",
            "4:\tlearn: 0.1386140\ttotal: 197ms\tremaining: 1.57s\n",
            "5:\tlearn: 0.1305302\ttotal: 235ms\tremaining: 1.53s\n",
            "6:\tlearn: 0.1233358\ttotal: 267ms\tremaining: 1.45s\n",
            "7:\tlearn: 0.1182270\ttotal: 303ms\tremaining: 1.4s\n",
            "8:\tlearn: 0.1038264\ttotal: 343ms\tremaining: 1.37s\n",
            "9:\tlearn: 0.0897411\ttotal: 382ms\tremaining: 1.33s\n",
            "10:\tlearn: 0.0825722\ttotal: 421ms\tremaining: 1.3s\n",
            "11:\tlearn: 0.0725579\ttotal: 458ms\tremaining: 1.26s\n",
            "12:\tlearn: 0.0647758\ttotal: 504ms\tremaining: 1.24s\n",
            "13:\tlearn: 0.0583320\ttotal: 544ms\tremaining: 1.2s\n",
            "14:\tlearn: 0.0535854\ttotal: 581ms\tremaining: 1.16s\n",
            "15:\tlearn: 0.0496486\ttotal: 622ms\tremaining: 1.13s\n",
            "16:\tlearn: 0.0474797\ttotal: 658ms\tremaining: 1.08s\n",
            "17:\tlearn: 0.0420768\ttotal: 698ms\tremaining: 1.05s\n",
            "18:\tlearn: 0.0381864\ttotal: 744ms\tremaining: 1.02s\n",
            "19:\tlearn: 0.0366009\ttotal: 783ms\tremaining: 979ms\n",
            "20:\tlearn: 0.0353731\ttotal: 820ms\tremaining: 937ms\n",
            "21:\tlearn: 0.0346316\ttotal: 858ms\tremaining: 897ms\n",
            "22:\tlearn: 0.0336706\ttotal: 895ms\tremaining: 856ms\n",
            "23:\tlearn: 0.0315762\ttotal: 923ms\tremaining: 808ms\n",
            "24:\tlearn: 0.0305250\ttotal: 953ms\tremaining: 763ms\n",
            "25:\tlearn: 0.0269423\ttotal: 982ms\tremaining: 718ms\n",
            "26:\tlearn: 0.0248460\ttotal: 1.02s\tremaining: 680ms\n",
            "27:\tlearn: 0.0239162\ttotal: 1.06s\tremaining: 643ms\n",
            "28:\tlearn: 0.0224920\ttotal: 1.1s\tremaining: 605ms\n",
            "29:\tlearn: 0.0213980\ttotal: 1.14s\tremaining: 568ms\n",
            "30:\tlearn: 0.0197375\ttotal: 1.18s\tremaining: 533ms\n",
            "31:\tlearn: 0.0185057\ttotal: 1.22s\tremaining: 494ms\n",
            "32:\tlearn: 0.0176920\ttotal: 1.26s\tremaining: 460ms\n",
            "33:\tlearn: 0.0163918\ttotal: 1.29s\tremaining: 417ms\n",
            "34:\tlearn: 0.0150582\ttotal: 1.31s\tremaining: 375ms\n",
            "35:\tlearn: 0.0145251\ttotal: 1.34s\tremaining: 336ms\n",
            "36:\tlearn: 0.0139709\ttotal: 1.39s\tremaining: 300ms\n",
            "37:\tlearn: 0.0131429\ttotal: 1.43s\tremaining: 263ms\n",
            "38:\tlearn: 0.0127097\ttotal: 1.46s\tremaining: 224ms\n",
            "39:\tlearn: 0.0123042\ttotal: 1.48s\tremaining: 185ms\n",
            "40:\tlearn: 0.0119026\ttotal: 1.5s\tremaining: 146ms\n",
            "41:\tlearn: 0.0112949\ttotal: 1.52s\tremaining: 109ms\n",
            "42:\tlearn: 0.0105152\ttotal: 1.57s\tremaining: 72.9ms\n",
            "43:\tlearn: 0.0100410\ttotal: 1.61s\tremaining: 36.6ms\n",
            "44:\tlearn: 0.0098126\ttotal: 1.64s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9599\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3580301\ttotal: 25.8ms\tremaining: 1.13s\n",
            "1:\tlearn: 0.2429120\ttotal: 44.2ms\tremaining: 950ms\n",
            "2:\tlearn: 0.1882013\ttotal: 62.3ms\tremaining: 873ms\n",
            "3:\tlearn: 0.1612841\ttotal: 80.1ms\tremaining: 821ms\n",
            "4:\tlearn: 0.1437649\ttotal: 98.1ms\tremaining: 785ms\n",
            "5:\tlearn: 0.1257453\ttotal: 116ms\tremaining: 752ms\n",
            "6:\tlearn: 0.1089581\ttotal: 134ms\tremaining: 726ms\n",
            "7:\tlearn: 0.0984017\ttotal: 153ms\tremaining: 707ms\n",
            "8:\tlearn: 0.0910546\ttotal: 171ms\tremaining: 685ms\n",
            "9:\tlearn: 0.0844652\ttotal: 191ms\tremaining: 668ms\n",
            "10:\tlearn: 0.0759659\ttotal: 209ms\tremaining: 646ms\n",
            "11:\tlearn: 0.0724873\ttotal: 230ms\tremaining: 633ms\n",
            "12:\tlearn: 0.0669872\ttotal: 250ms\tremaining: 615ms\n",
            "13:\tlearn: 0.0655711\ttotal: 268ms\tremaining: 593ms\n",
            "14:\tlearn: 0.0616706\ttotal: 285ms\tremaining: 571ms\n",
            "15:\tlearn: 0.0565467\ttotal: 310ms\tremaining: 563ms\n",
            "16:\tlearn: 0.0525054\ttotal: 329ms\tremaining: 541ms\n",
            "17:\tlearn: 0.0489922\ttotal: 348ms\tremaining: 522ms\n",
            "18:\tlearn: 0.0454648\ttotal: 366ms\tremaining: 501ms\n",
            "19:\tlearn: 0.0404473\ttotal: 384ms\tremaining: 480ms\n",
            "20:\tlearn: 0.0385622\ttotal: 404ms\tremaining: 462ms\n",
            "21:\tlearn: 0.0351312\ttotal: 423ms\tremaining: 442ms\n",
            "22:\tlearn: 0.0321159\ttotal: 453ms\tremaining: 433ms\n",
            "23:\tlearn: 0.0306954\ttotal: 472ms\tremaining: 413ms\n",
            "24:\tlearn: 0.0285596\ttotal: 493ms\tremaining: 394ms\n",
            "25:\tlearn: 0.0270237\ttotal: 512ms\tremaining: 374ms\n",
            "26:\tlearn: 0.0261159\ttotal: 531ms\tremaining: 354ms\n",
            "27:\tlearn: 0.0242745\ttotal: 549ms\tremaining: 333ms\n",
            "28:\tlearn: 0.0241376\ttotal: 567ms\tremaining: 313ms\n",
            "29:\tlearn: 0.0237586\ttotal: 585ms\tremaining: 292ms\n",
            "30:\tlearn: 0.0226190\ttotal: 603ms\tremaining: 272ms\n",
            "31:\tlearn: 0.0213925\ttotal: 634ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0201158\ttotal: 656ms\tremaining: 238ms\n",
            "33:\tlearn: 0.0194989\ttotal: 674ms\tremaining: 218ms\n",
            "34:\tlearn: 0.0193273\ttotal: 691ms\tremaining: 197ms\n",
            "35:\tlearn: 0.0183704\ttotal: 709ms\tremaining: 177ms\n",
            "36:\tlearn: 0.0179158\ttotal: 727ms\tremaining: 157ms\n",
            "37:\tlearn: 0.0176732\ttotal: 745ms\tremaining: 137ms\n",
            "38:\tlearn: 0.0173469\ttotal: 764ms\tremaining: 117ms\n",
            "39:\tlearn: 0.0169115\ttotal: 782ms\tremaining: 97.7ms\n",
            "40:\tlearn: 0.0161948\ttotal: 800ms\tremaining: 78ms\n",
            "41:\tlearn: 0.0151240\ttotal: 818ms\tremaining: 58.4ms\n",
            "42:\tlearn: 0.0142486\ttotal: 836ms\tremaining: 38.9ms\n",
            "43:\tlearn: 0.0135549\ttotal: 854ms\tremaining: 19.4ms\n",
            "44:\tlearn: 0.0134990\ttotal: 876ms\tremaining: 0us\n",
            "0:\tlearn: 0.3581177\ttotal: 24.7ms\tremaining: 1.08s\n",
            "1:\tlearn: 0.2404813\ttotal: 43.8ms\tremaining: 942ms\n",
            "2:\tlearn: 0.1808769\ttotal: 65.7ms\tremaining: 920ms\n",
            "3:\tlearn: 0.1490260\ttotal: 83ms\tremaining: 851ms\n",
            "4:\tlearn: 0.1251307\ttotal: 101ms\tremaining: 805ms\n",
            "5:\tlearn: 0.1156475\ttotal: 118ms\tremaining: 766ms\n",
            "6:\tlearn: 0.1052872\ttotal: 136ms\tremaining: 738ms\n",
            "7:\tlearn: 0.0986180\ttotal: 162ms\tremaining: 749ms\n",
            "8:\tlearn: 0.0901084\ttotal: 180ms\tremaining: 720ms\n",
            "9:\tlearn: 0.0853232\ttotal: 199ms\tremaining: 695ms\n",
            "10:\tlearn: 0.0808490\ttotal: 217ms\tremaining: 672ms\n",
            "11:\tlearn: 0.0740693\ttotal: 236ms\tremaining: 648ms\n",
            "12:\tlearn: 0.0694011\ttotal: 259ms\tremaining: 639ms\n",
            "13:\tlearn: 0.0632936\ttotal: 283ms\tremaining: 626ms\n",
            "14:\tlearn: 0.0599668\ttotal: 301ms\tremaining: 602ms\n",
            "15:\tlearn: 0.0562174\ttotal: 319ms\tremaining: 578ms\n",
            "16:\tlearn: 0.0539855\ttotal: 347ms\tremaining: 572ms\n",
            "17:\tlearn: 0.0514032\ttotal: 371ms\tremaining: 556ms\n",
            "18:\tlearn: 0.0466942\ttotal: 389ms\tremaining: 533ms\n",
            "19:\tlearn: 0.0438356\ttotal: 408ms\tremaining: 510ms\n",
            "20:\tlearn: 0.0424533\ttotal: 426ms\tremaining: 487ms\n",
            "21:\tlearn: 0.0414160\ttotal: 444ms\tremaining: 464ms\n",
            "22:\tlearn: 0.0388852\ttotal: 462ms\tremaining: 442ms\n",
            "23:\tlearn: 0.0369552\ttotal: 480ms\tremaining: 420ms\n",
            "24:\tlearn: 0.0344024\ttotal: 499ms\tremaining: 399ms\n",
            "25:\tlearn: 0.0326347\ttotal: 517ms\tremaining: 378ms\n",
            "26:\tlearn: 0.0301244\ttotal: 536ms\tremaining: 357ms\n",
            "27:\tlearn: 0.0285723\ttotal: 556ms\tremaining: 338ms\n",
            "28:\tlearn: 0.0264187\ttotal: 579ms\tremaining: 319ms\n",
            "29:\tlearn: 0.0255267\ttotal: 597ms\tremaining: 299ms\n",
            "30:\tlearn: 0.0247788\ttotal: 615ms\tremaining: 278ms\n",
            "31:\tlearn: 0.0234462\ttotal: 633ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0229431\ttotal: 651ms\tremaining: 237ms\n",
            "33:\tlearn: 0.0220068\ttotal: 669ms\tremaining: 216ms\n",
            "34:\tlearn: 0.0209141\ttotal: 689ms\tremaining: 197ms\n",
            "35:\tlearn: 0.0200348\ttotal: 718ms\tremaining: 179ms\n",
            "36:\tlearn: 0.0193650\ttotal: 735ms\tremaining: 159ms\n",
            "37:\tlearn: 0.0184726\ttotal: 753ms\tremaining: 139ms\n",
            "38:\tlearn: 0.0177331\ttotal: 771ms\tremaining: 119ms\n",
            "39:\tlearn: 0.0160636\ttotal: 795ms\tremaining: 99.3ms\n",
            "40:\tlearn: 0.0151891\ttotal: 814ms\tremaining: 79.4ms\n",
            "41:\tlearn: 0.0146737\ttotal: 832ms\tremaining: 59.4ms\n",
            "42:\tlearn: 0.0136955\ttotal: 849ms\tremaining: 39.5ms\n",
            "43:\tlearn: 0.0136087\ttotal: 867ms\tremaining: 19.7ms\n",
            "44:\tlearn: 0.0127224\ttotal: 886ms\tremaining: 0us\n",
            "0:\tlearn: 0.3759563\ttotal: 27.4ms\tremaining: 1.21s\n",
            "1:\tlearn: 0.2490870\ttotal: 46ms\tremaining: 988ms\n",
            "2:\tlearn: 0.1873794\ttotal: 69.7ms\tremaining: 976ms\n",
            "3:\tlearn: 0.1659344\ttotal: 87.9ms\tremaining: 901ms\n",
            "4:\tlearn: 0.1426832\ttotal: 107ms\tremaining: 854ms\n",
            "5:\tlearn: 0.1309803\ttotal: 125ms\tremaining: 814ms\n",
            "6:\tlearn: 0.1232565\ttotal: 147ms\tremaining: 796ms\n",
            "7:\tlearn: 0.1166084\ttotal: 166ms\tremaining: 767ms\n",
            "8:\tlearn: 0.1080087\ttotal: 184ms\tremaining: 736ms\n",
            "9:\tlearn: 0.0989371\ttotal: 213ms\tremaining: 746ms\n",
            "10:\tlearn: 0.0938614\ttotal: 232ms\tremaining: 717ms\n",
            "11:\tlearn: 0.0854130\ttotal: 251ms\tremaining: 691ms\n",
            "12:\tlearn: 0.0765574\ttotal: 274ms\tremaining: 675ms\n",
            "13:\tlearn: 0.0685072\ttotal: 292ms\tremaining: 646ms\n",
            "14:\tlearn: 0.0632222\ttotal: 310ms\tremaining: 620ms\n",
            "15:\tlearn: 0.0583043\ttotal: 328ms\tremaining: 595ms\n",
            "16:\tlearn: 0.0504233\ttotal: 347ms\tremaining: 571ms\n",
            "17:\tlearn: 0.0476766\ttotal: 366ms\tremaining: 548ms\n",
            "18:\tlearn: 0.0461135\ttotal: 384ms\tremaining: 526ms\n",
            "19:\tlearn: 0.0409022\ttotal: 403ms\tremaining: 504ms\n",
            "20:\tlearn: 0.0391294\ttotal: 422ms\tremaining: 482ms\n",
            "21:\tlearn: 0.0381615\ttotal: 439ms\tremaining: 459ms\n",
            "22:\tlearn: 0.0343269\ttotal: 458ms\tremaining: 438ms\n",
            "23:\tlearn: 0.0334897\ttotal: 481ms\tremaining: 421ms\n",
            "24:\tlearn: 0.0319164\ttotal: 500ms\tremaining: 400ms\n",
            "25:\tlearn: 0.0295874\ttotal: 518ms\tremaining: 379ms\n",
            "26:\tlearn: 0.0282627\ttotal: 537ms\tremaining: 358ms\n",
            "27:\tlearn: 0.0273424\ttotal: 557ms\tremaining: 338ms\n",
            "28:\tlearn: 0.0266733\ttotal: 574ms\tremaining: 317ms\n",
            "29:\tlearn: 0.0263568\ttotal: 592ms\tremaining: 296ms\n",
            "30:\tlearn: 0.0256254\ttotal: 615ms\tremaining: 278ms\n",
            "31:\tlearn: 0.0230975\ttotal: 633ms\tremaining: 257ms\n",
            "32:\tlearn: 0.0212591\ttotal: 652ms\tremaining: 237ms\n",
            "33:\tlearn: 0.0203518\ttotal: 670ms\tremaining: 217ms\n",
            "34:\tlearn: 0.0195848\ttotal: 694ms\tremaining: 198ms\n",
            "35:\tlearn: 0.0188137\ttotal: 711ms\tremaining: 178ms\n",
            "36:\tlearn: 0.0178416\ttotal: 730ms\tremaining: 158ms\n",
            "37:\tlearn: 0.0167930\ttotal: 748ms\tremaining: 138ms\n",
            "38:\tlearn: 0.0156024\ttotal: 778ms\tremaining: 120ms\n",
            "39:\tlearn: 0.0152886\ttotal: 797ms\tremaining: 99.6ms\n",
            "40:\tlearn: 0.0149545\ttotal: 814ms\tremaining: 79.5ms\n",
            "41:\tlearn: 0.0141503\ttotal: 832ms\tremaining: 59.4ms\n",
            "42:\tlearn: 0.0136034\ttotal: 850ms\tremaining: 39.5ms\n",
            "43:\tlearn: 0.0132373\ttotal: 870ms\tremaining: 19.8ms\n",
            "44:\tlearn: 0.0125890\ttotal: 888ms\tremaining: 0us\n",
            "0:\tlearn: 0.3709012\ttotal: 25.3ms\tremaining: 1.11s\n",
            "1:\tlearn: 0.2346238\ttotal: 44.2ms\tremaining: 951ms\n",
            "2:\tlearn: 0.1770783\ttotal: 62.1ms\tremaining: 869ms\n",
            "3:\tlearn: 0.1522849\ttotal: 81.7ms\tremaining: 838ms\n",
            "4:\tlearn: 0.1303747\ttotal: 99.2ms\tremaining: 793ms\n",
            "5:\tlearn: 0.1225885\ttotal: 118ms\tremaining: 765ms\n",
            "6:\tlearn: 0.1131574\ttotal: 135ms\tremaining: 735ms\n",
            "7:\tlearn: 0.1061087\ttotal: 153ms\tremaining: 709ms\n",
            "8:\tlearn: 0.0940950\ttotal: 172ms\tremaining: 689ms\n",
            "9:\tlearn: 0.0877181\ttotal: 191ms\tremaining: 667ms\n",
            "10:\tlearn: 0.0840612\ttotal: 209ms\tremaining: 646ms\n",
            "11:\tlearn: 0.0766950\ttotal: 232ms\tremaining: 639ms\n",
            "12:\tlearn: 0.0677780\ttotal: 252ms\tremaining: 621ms\n",
            "13:\tlearn: 0.0620937\ttotal: 270ms\tremaining: 599ms\n",
            "14:\tlearn: 0.0579948\ttotal: 289ms\tremaining: 578ms\n",
            "15:\tlearn: 0.0551115\ttotal: 309ms\tremaining: 559ms\n",
            "16:\tlearn: 0.0513568\ttotal: 327ms\tremaining: 539ms\n",
            "17:\tlearn: 0.0484354\ttotal: 346ms\tremaining: 520ms\n",
            "18:\tlearn: 0.0462616\ttotal: 365ms\tremaining: 499ms\n",
            "19:\tlearn: 0.0439989\ttotal: 383ms\tremaining: 479ms\n",
            "20:\tlearn: 0.0417022\ttotal: 401ms\tremaining: 458ms\n",
            "21:\tlearn: 0.0398838\ttotal: 419ms\tremaining: 438ms\n",
            "22:\tlearn: 0.0375260\ttotal: 442ms\tremaining: 423ms\n",
            "23:\tlearn: 0.0358054\ttotal: 460ms\tremaining: 403ms\n",
            "24:\tlearn: 0.0329369\ttotal: 478ms\tremaining: 382ms\n",
            "25:\tlearn: 0.0299109\ttotal: 497ms\tremaining: 363ms\n",
            "26:\tlearn: 0.0269845\ttotal: 515ms\tremaining: 343ms\n",
            "27:\tlearn: 0.0262457\ttotal: 533ms\tremaining: 323ms\n",
            "28:\tlearn: 0.0239024\ttotal: 550ms\tremaining: 304ms\n",
            "29:\tlearn: 0.0234416\ttotal: 568ms\tremaining: 284ms\n",
            "30:\tlearn: 0.0227592\ttotal: 586ms\tremaining: 265ms\n",
            "31:\tlearn: 0.0219604\ttotal: 604ms\tremaining: 246ms\n",
            "32:\tlearn: 0.0214849\ttotal: 623ms\tremaining: 227ms\n",
            "33:\tlearn: 0.0203568\ttotal: 645ms\tremaining: 209ms\n",
            "34:\tlearn: 0.0184978\ttotal: 668ms\tremaining: 191ms\n",
            "35:\tlearn: 0.0179673\ttotal: 692ms\tremaining: 173ms\n",
            "36:\tlearn: 0.0169672\ttotal: 710ms\tremaining: 154ms\n",
            "37:\tlearn: 0.0163208\ttotal: 728ms\tremaining: 134ms\n",
            "38:\tlearn: 0.0161161\ttotal: 746ms\tremaining: 115ms\n",
            "39:\tlearn: 0.0156345\ttotal: 765ms\tremaining: 95.6ms\n",
            "40:\tlearn: 0.0141953\ttotal: 790ms\tremaining: 77.1ms\n",
            "41:\tlearn: 0.0136019\ttotal: 810ms\tremaining: 57.9ms\n",
            "42:\tlearn: 0.0129384\ttotal: 832ms\tremaining: 38.7ms\n",
            "43:\tlearn: 0.0126822\ttotal: 864ms\tremaining: 19.6ms\n",
            "44:\tlearn: 0.0122900\ttotal: 883ms\tremaining: 0us\n",
            "0:\tlearn: 0.3637753\ttotal: 26ms\tremaining: 1.14s\n",
            "1:\tlearn: 0.2347715\ttotal: 45.6ms\tremaining: 980ms\n",
            "2:\tlearn: 0.1829685\ttotal: 63.5ms\tremaining: 889ms\n",
            "3:\tlearn: 0.1516314\ttotal: 81.3ms\tremaining: 833ms\n",
            "4:\tlearn: 0.1392544\ttotal: 99.5ms\tremaining: 796ms\n",
            "5:\tlearn: 0.1296885\ttotal: 117ms\tremaining: 761ms\n",
            "6:\tlearn: 0.1195466\ttotal: 140ms\tremaining: 760ms\n",
            "7:\tlearn: 0.1088423\ttotal: 163ms\tremaining: 756ms\n",
            "8:\tlearn: 0.1009076\ttotal: 181ms\tremaining: 724ms\n",
            "9:\tlearn: 0.0966029\ttotal: 199ms\tremaining: 695ms\n",
            "10:\tlearn: 0.0911841\ttotal: 216ms\tremaining: 668ms\n",
            "11:\tlearn: 0.0847459\ttotal: 234ms\tremaining: 643ms\n",
            "12:\tlearn: 0.0797987\ttotal: 251ms\tremaining: 619ms\n",
            "13:\tlearn: 0.0702344\ttotal: 270ms\tremaining: 597ms\n",
            "14:\tlearn: 0.0644793\ttotal: 288ms\tremaining: 576ms\n",
            "15:\tlearn: 0.0579673\ttotal: 306ms\tremaining: 554ms\n",
            "16:\tlearn: 0.0561784\ttotal: 324ms\tremaining: 534ms\n",
            "17:\tlearn: 0.0534578\ttotal: 342ms\tremaining: 513ms\n",
            "18:\tlearn: 0.0488479\ttotal: 370ms\tremaining: 507ms\n",
            "19:\tlearn: 0.0457838\ttotal: 393ms\tremaining: 491ms\n",
            "20:\tlearn: 0.0439936\ttotal: 411ms\tremaining: 470ms\n",
            "21:\tlearn: 0.0405462\ttotal: 430ms\tremaining: 449ms\n",
            "22:\tlearn: 0.0363988\ttotal: 448ms\tremaining: 429ms\n",
            "23:\tlearn: 0.0348939\ttotal: 467ms\tremaining: 408ms\n",
            "24:\tlearn: 0.0324656\ttotal: 485ms\tremaining: 388ms\n",
            "25:\tlearn: 0.0311903\ttotal: 505ms\tremaining: 369ms\n",
            "26:\tlearn: 0.0278019\ttotal: 524ms\tremaining: 349ms\n",
            "27:\tlearn: 0.0270423\ttotal: 542ms\tremaining: 329ms\n",
            "28:\tlearn: 0.0252397\ttotal: 560ms\tremaining: 309ms\n",
            "29:\tlearn: 0.0238219\ttotal: 584ms\tremaining: 292ms\n",
            "30:\tlearn: 0.0233651\ttotal: 603ms\tremaining: 272ms\n",
            "31:\tlearn: 0.0229280\ttotal: 622ms\tremaining: 253ms\n",
            "32:\tlearn: 0.0214437\ttotal: 642ms\tremaining: 233ms\n",
            "33:\tlearn: 0.0197893\ttotal: 660ms\tremaining: 214ms\n",
            "34:\tlearn: 0.0187118\ttotal: 678ms\tremaining: 194ms\n",
            "35:\tlearn: 0.0177485\ttotal: 696ms\tremaining: 174ms\n",
            "36:\tlearn: 0.0168183\ttotal: 717ms\tremaining: 155ms\n",
            "37:\tlearn: 0.0156311\ttotal: 735ms\tremaining: 135ms\n",
            "38:\tlearn: 0.0152557\ttotal: 754ms\tremaining: 116ms\n",
            "39:\tlearn: 0.0149229\ttotal: 772ms\tremaining: 96.5ms\n",
            "40:\tlearn: 0.0143682\ttotal: 795ms\tremaining: 77.6ms\n",
            "41:\tlearn: 0.0138352\ttotal: 813ms\tremaining: 58.1ms\n",
            "42:\tlearn: 0.0136601\ttotal: 832ms\tremaining: 38.7ms\n",
            "43:\tlearn: 0.0132779\ttotal: 851ms\tremaining: 19.3ms\n",
            "44:\tlearn: 0.0125731\ttotal: 870ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9520\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9543\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9560\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9573\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9557\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 39\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.961165  0.739754   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.957929  0.714933   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.957929  0.715560   \n",
            "3                             KNeighborsClassifier()  0.956311  0.706269   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.964401  0.763941   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.964401  0.769515   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.964401  0.764376   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.961165  0.741733   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.954693  0.690124   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.719219   0.944444  0.607143  0.739130     0.996441     0.607143  \n",
            "1  0.689879   0.941176  0.571429  0.711111     0.996441     0.571429  \n",
            "2  0.677272   1.000000  0.535714  0.697674     1.000000     0.535714  \n",
            "3  0.692945   0.871795  0.607143  0.715789     0.991103     0.607143  \n",
            "4  0.747455   0.947368  0.642857  0.765957     0.996441     0.642857  \n",
            "5  0.765116   0.869565  0.714286  0.784314     0.989324     0.714286  \n",
            "6  0.737590   1.000000  0.607143  0.755556     1.000000     0.607143  \n",
            "7  0.729580   0.900000  0.642857  0.750000     0.992883     0.642857  \n",
            "8  0.645235   1.000000  0.500000  0.666667     1.000000     0.500000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GDPC**"
      ],
      "metadata": {
        "id": "VZobnVY14S_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced**"
      ],
      "metadata": {
        "id": "ecs4kPAM4oAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "RA_PIkMj4cGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbKYxrSj4qJZ",
        "outputId": "ff666d1f-322f-4235-abd7-a5fef6a5df01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.961974  0.744471   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.934871  0.537537   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.927994  0.427229   \n",
            "3                             KNeighborsClassifier()  0.937298  0.579366   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.980987  0.882159   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.954288  0.701120   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983819  0.901432   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.984628  0.906361   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.985437  0.909633   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.730149   0.915584  0.635135  0.750000     0.994222     0.635135  \n",
            "1  0.520882   0.719424  0.450450  0.554017     0.982667     0.450450  \n",
            "2  0.327439   0.923077  0.216216  0.350365     0.998222     0.216216  \n",
            "3  0.574091   0.693642  0.540541  0.607595     0.976444     0.540541  \n",
            "4  0.882023   0.906977  0.878378  0.892449     0.991111     0.878378  \n",
            "5  0.697677   0.794595  0.662162  0.722359     0.983111     0.662162  \n",
            "6  0.901421   0.906250  0.914414  0.910314     0.990667     0.914414  \n",
            "7  0.906350   0.910714  0.918919  0.914798     0.991111     0.918919  \n",
            "8  0.909448   0.934579  0.900901  0.917431     0.993778     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADASYN**"
      ],
      "metadata": {
        "id": "BNUDC1dB4ySc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "p8422GQf40M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN()\n",
        "xtrain, ytrain = ada.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "U_IVSuxs42QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(ADASYN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-3sc9gl473y",
        "outputId": "952ba557-af11-4371-ae81-03c6ae5bf5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.981531  0.963418   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.820427  0.661764   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.869826  0.741879   \n",
            "3                             KNeighborsClassifier()  0.930797  0.869989   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.988652  0.977466   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.922563  0.845974   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.990209  0.980518   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.990877  0.981847   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993992  0.987996   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.963063   0.968764  0.995098  0.981754     0.968000     0.995098  \n",
            "1  0.640973   0.756333  0.944742  0.840103     0.696444     0.944742  \n",
            "2  0.739625   0.900918  0.830660  0.864364     0.908889     0.830660  \n",
            "3  0.861619   0.878278  1.000000  0.935195     0.861778     1.000000  \n",
            "4  0.977304   0.979869  0.997772  0.988739     0.979556     0.997772  \n",
            "5  0.845136   0.904437  0.944742  0.924150     0.900444     0.944742  \n",
            "6  0.980419   0.983304  0.997326  0.990265     0.983111     0.997326  \n",
            "7  0.981754   0.984176  0.997772  0.990927     0.984000     0.997772  \n",
            "8  0.987984   0.991574  0.996435  0.993999     0.991556     0.996435  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTEN**"
      ],
      "metadata": {
        "id": "DqmKDj5I5Aoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "aQnr5ttn5CRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTEN\n",
        "smn = SMOTEN()\n",
        "xtrain, ytrain = smn.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "5xtzVgou5EUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(SMOTEN)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4O5Kxg75LPa",
        "outputId": "3ab5c770-0d99-4d46-9e09-c8d547e22cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.984667  0.969345   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.945778  0.891832   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.948889  0.897813   \n",
            "3                             KNeighborsClassifier()  0.964667  0.929341   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.986222  0.972445   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.973778  0.947580   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.989556  0.979116   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.991111  0.982224   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.975556  0.951807   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.969333   0.982309  0.987111  0.984704     0.982222     0.987111  \n",
            "1  0.891556   0.934952  0.958222  0.946444     0.933333     0.958222  \n",
            "2  0.897778   0.944934  0.953333  0.949115     0.944444     0.953333  \n",
            "3  0.929333   0.966533  0.962667  0.964596     0.966667     0.962667  \n",
            "4  0.972444   0.985790  0.986667  0.986228     0.985778     0.986667  \n",
            "5  0.947556   0.977171  0.970222  0.973684     0.977333     0.970222  \n",
            "6  0.979111   0.988037  0.991111  0.989572     0.988000     0.991111  \n",
            "7  0.982222   0.990240  0.992000  0.991119     0.990222     0.992000  \n",
            "8  0.951111   0.994455  0.956444  0.975079     0.994667     0.956444  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTETomek**"
      ],
      "metadata": {
        "id": "H4YoJYpJ5QBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "pXw5ANO15SSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smt = SMOTETomek()\n",
        "xtrain, ytrain = smt.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "J9ytFTKX5UOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(SMOTETomek)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSqr5tg85ZF5",
        "outputId": "f1b12579-5278-408d-ca14-f1fe5fd2cae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.977333  0.954685   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.834222  0.668482   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.892000  0.786635   \n",
            "3                             KNeighborsClassifier()  0.937333  0.881619   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.987778  0.975687   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.928667  0.857649   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.991111  0.982310   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.990222  0.980510   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.993333  0.986681   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.954667   0.974382  0.980444  0.977404     0.974222     0.980444  \n",
            "1  0.668444   0.837826  0.828889  0.833333     0.839556     0.828889  \n",
            "2  0.784000   0.926912  0.851111  0.887396     0.932889     0.851111  \n",
            "3  0.874667   0.888626  1.000000  0.941029     0.874667     1.000000  \n",
            "4  0.975556   0.979886  0.996000  0.987877     0.979556     0.996000  \n",
            "5  0.857333   0.917352  0.942222  0.929621     0.915111     0.942222  \n",
            "6  0.982222   0.984649  0.997778  0.991170     0.984444     0.997778  \n",
            "7  0.980444   0.984622  0.996000  0.990278     0.984444     0.996000  \n",
            "8  0.986667   0.990716  0.996000  0.993351     0.990667     0.996000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NearMiss**"
      ],
      "metadata": {
        "id": "QoN9DVFb5c_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "h6UM-A0e5eyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "nm = NearMiss()\n",
        "xtrain, ytrain = nm.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "LNV0_J-r5hb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(NearMiss)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo6yTJ5h5mbi",
        "outputId": "f891a006-33c5-43ad-9251-e6a24a5126fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.912162  0.824400   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.885135  0.770904   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.891892  0.783911   \n",
            "3                             KNeighborsClassifier()  0.795045  0.593283   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.909910  0.820353   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.914414  0.829132   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.907658  0.815986   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.909910  0.820353   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.914414  0.829368   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.824324   0.906667  0.918919  0.912752     0.905405     0.918919  \n",
            "1  0.770270   0.901408  0.864865  0.882759     0.905405     0.864865  \n",
            "2  0.783784   0.899083  0.882883  0.890909     0.900901     0.882883  \n",
            "3  0.590090   0.829146  0.743243  0.783848     0.846847     0.743243  \n",
            "4  0.819820   0.895652  0.927928  0.911504     0.891892     0.927928  \n",
            "5  0.828829   0.903509  0.927928  0.915556     0.900901     0.927928  \n",
            "6  0.815315   0.891775  0.927928  0.909492     0.887387     0.927928  \n",
            "7  0.819820   0.895652  0.927928  0.911504     0.891892     0.927928  \n",
            "8  0.828829   0.929907  0.896396  0.912844     0.932432     0.896396  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TomekLinks**"
      ],
      "metadata": {
        "id": "dV9Xj1SH5q0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "ytrnqX1X5stj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "tl = TomekLinks()\n",
        "xtrain, ytrain = tl.fit_resample(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "da87gVNo5vD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # model.fit(xtrain, ytrain)\n",
        "  # pred = model.predict(xtest)\n",
        "  pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytrain, pred)\n",
        "  mcc = matthews_corrcoef(ytrain, pred)\n",
        "  cm1 = confusion_matrix(ytrain, pred)\n",
        "  kappa = cohen_kappa_score(ytrain, pred)\n",
        "  f1 = f1_score(ytrain, pred)\n",
        "  precision_score = precision_score(ytrain, pred)\n",
        "  recall_score = recall_score(ytrain, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-CV(TomekLinks)).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KoN_z065zbj",
        "outputId": "b521dd7d-d384-4127-ebd6-99a2ad60c463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  RandomForestClassifier(max_depth=9, n_estimato...  0.962379  0.747538   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.934466  0.535179   \n",
            "2  ExtraTreesClassifier(max_depth=7, n_estimators...  0.927994  0.427229   \n",
            "3                             KNeighborsClassifier()  0.937298  0.579366   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.980987  0.882159   \n",
            "5  AdaBoostClassifier(learning_rate=0.5, n_estima...  0.954288  0.701120   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.983819  0.901432   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.984628  0.906361   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.984628  0.904913   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.733647   0.916129  0.639640  0.753316     0.994222     0.639640  \n",
            "1  0.519080   0.714286  0.450450  0.552486     0.982222     0.450450  \n",
            "2  0.327439   0.923077  0.216216  0.350365     0.998222     0.216216  \n",
            "3  0.574091   0.693642  0.540541  0.607595     0.976444     0.540541  \n",
            "4  0.882023   0.906977  0.878378  0.892449     0.991111     0.878378  \n",
            "5  0.697677   0.794595  0.662162  0.722359     0.983111     0.662162  \n",
            "6  0.901421   0.906250  0.914414  0.910314     0.990667     0.914414  \n",
            "7  0.906350   0.910714  0.918919  0.914798     0.991111     0.918919  \n",
            "8  0.904811   0.925926  0.900901  0.913242     0.992889     0.900901  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ind-Test**"
      ],
      "metadata": {
        "id": "V_qzWolfCiey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Tr.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtrain = df_tr[columns]\n",
        "ytrain = df_tr[target]"
      ],
      "metadata": {
        "id": "B_AllsNtCl2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = pd.read_csv('/content/GDPC-Ind.csv')\n",
        "columns = df_tr.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Target\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Target\"\n",
        "xtest= df_tr[columns]\n",
        "ytest = df_tr[target]"
      ],
      "metadata": {
        "id": "RpsPGIZCCoth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_Metics = []\n",
        "total_Metics = pd.DataFrame(total_Metics)\n",
        "total_Metics['Classifier'] = 'Classifier'\n",
        "total_Metics['Accuracy'] = 'Accuracy'\n",
        "total_Metics['mcc'] = 'mcc'\n",
        "# total_Metics['auc'] = 'auc'\n",
        "total_Metics['Kappa'] = 'Kappa'\n",
        "total_Metics['precision'] = 'precision'\n",
        "total_Metics['recall'] = 'recall'\n",
        "total_Metics['f1'] = 'f1'\n",
        "total_Metics['sensitivity'] = 'sensitivity'\n",
        "total_Metics['specificity'] = 'specificity'\n",
        "\n",
        "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "# create model\n",
        "models = [RandomForestClassifier(n_estimators = 450, max_depth = 9),\n",
        "          DecisionTreeClassifier(max_depth = 5),\n",
        "          ExtraTreesClassifier(n_estimators = 450, max_depth = 7),\n",
        "          KNeighborsClassifier(n_neighbors=5),\n",
        "          CatBoostClassifier(depth= 7, iterations = 45, learning_rate = 0.35),\n",
        "          AdaBoostClassifier(n_estimators = 350, learning_rate = 0.5, random_state = 50),\n",
        "          XGBClassifier(n_estimators = 350,max_depth = 7, base_score = 0.5, learning_rate = 0.1),\n",
        "          LGBMClassifier(learning_rate = 0.1,max_depth = 7,random_state = 50),\n",
        "          Stacking]\n",
        "for model in models:\n",
        "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
        "  # evaluate model\n",
        "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  pred = model.predict(xtest)\n",
        "  # pred = cross_val_predict(model, xtrain, ytrain, cv=cv, n_jobs=-1)\n",
        "\n",
        "  # cm1 = confusion_matrix(y, y_pred)\n",
        "  # report performance\n",
        "  Accuracy = accuracy_score(ytest, pred)\n",
        "  mcc = matthews_corrcoef(ytest, pred)\n",
        "  cm1 = confusion_matrix(ytest, pred)\n",
        "  kappa = cohen_kappa_score(ytest, pred)\n",
        "  f1 = f1_score(ytest, pred)\n",
        "  precision_score = precision_score(ytest, pred)\n",
        "  recall_score = recall_score(ytest, pred)\n",
        "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "  # y_pred = np.argmax(y_pred, axis=0)\n",
        "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
        "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
        "\n",
        "print(total_Metics)\n",
        "total_Metics.to_csv(\"total_Metics(GDPC-Ind).csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI769vCoCxKK",
        "outputId": "76ac3da0-f60e-43da-aef7-5693473784ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.3375109\ttotal: 77.6ms\tremaining: 3.42s\n",
            "1:\tlearn: 0.2176891\ttotal: 99.8ms\tremaining: 2.15s\n",
            "2:\tlearn: 0.1674932\ttotal: 119ms\tremaining: 1.67s\n",
            "3:\tlearn: 0.1458531\ttotal: 138ms\tremaining: 1.42s\n",
            "4:\tlearn: 0.1277541\ttotal: 159ms\tremaining: 1.27s\n",
            "5:\tlearn: 0.1210375\ttotal: 176ms\tremaining: 1.15s\n",
            "6:\tlearn: 0.1151019\ttotal: 195ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.1081074\ttotal: 218ms\tremaining: 1.01s\n",
            "8:\tlearn: 0.1020136\ttotal: 238ms\tremaining: 952ms\n",
            "9:\tlearn: 0.0970428\ttotal: 261ms\tremaining: 913ms\n",
            "10:\tlearn: 0.0860568\ttotal: 289ms\tremaining: 894ms\n",
            "11:\tlearn: 0.0795166\ttotal: 311ms\tremaining: 854ms\n",
            "12:\tlearn: 0.0741892\ttotal: 331ms\tremaining: 815ms\n",
            "13:\tlearn: 0.0665348\ttotal: 352ms\tremaining: 780ms\n",
            "14:\tlearn: 0.0634794\ttotal: 374ms\tremaining: 748ms\n",
            "15:\tlearn: 0.0622037\ttotal: 397ms\tremaining: 720ms\n",
            "16:\tlearn: 0.0590992\ttotal: 419ms\tremaining: 691ms\n",
            "17:\tlearn: 0.0569823\ttotal: 439ms\tremaining: 659ms\n",
            "18:\tlearn: 0.0554606\ttotal: 454ms\tremaining: 621ms\n",
            "19:\tlearn: 0.0531405\ttotal: 471ms\tremaining: 589ms\n",
            "20:\tlearn: 0.0488269\ttotal: 489ms\tremaining: 559ms\n",
            "21:\tlearn: 0.0474172\ttotal: 501ms\tremaining: 524ms\n",
            "22:\tlearn: 0.0459131\ttotal: 513ms\tremaining: 491ms\n",
            "23:\tlearn: 0.0448672\ttotal: 526ms\tremaining: 460ms\n",
            "24:\tlearn: 0.0420708\ttotal: 538ms\tremaining: 430ms\n",
            "25:\tlearn: 0.0409108\ttotal: 549ms\tremaining: 401ms\n",
            "26:\tlearn: 0.0393012\ttotal: 561ms\tremaining: 374ms\n",
            "27:\tlearn: 0.0379897\ttotal: 573ms\tremaining: 348ms\n",
            "28:\tlearn: 0.0347955\ttotal: 592ms\tremaining: 326ms\n",
            "29:\tlearn: 0.0316232\ttotal: 612ms\tremaining: 306ms\n",
            "30:\tlearn: 0.0296974\ttotal: 634ms\tremaining: 286ms\n",
            "31:\tlearn: 0.0276197\ttotal: 657ms\tremaining: 267ms\n",
            "32:\tlearn: 0.0274195\ttotal: 677ms\tremaining: 246ms\n",
            "33:\tlearn: 0.0258432\ttotal: 703ms\tremaining: 228ms\n",
            "34:\tlearn: 0.0244146\ttotal: 726ms\tremaining: 207ms\n",
            "35:\tlearn: 0.0232285\ttotal: 748ms\tremaining: 187ms\n",
            "36:\tlearn: 0.0220336\ttotal: 766ms\tremaining: 166ms\n",
            "37:\tlearn: 0.0208506\ttotal: 785ms\tremaining: 145ms\n",
            "38:\tlearn: 0.0200129\ttotal: 808ms\tremaining: 124ms\n",
            "39:\tlearn: 0.0193279\ttotal: 828ms\tremaining: 103ms\n",
            "40:\tlearn: 0.0185371\ttotal: 850ms\tremaining: 82.9ms\n",
            "41:\tlearn: 0.0177718\ttotal: 872ms\tremaining: 62.3ms\n",
            "42:\tlearn: 0.0168416\ttotal: 892ms\tremaining: 41.5ms\n",
            "43:\tlearn: 0.0161007\ttotal: 917ms\tremaining: 20.8ms\n",
            "44:\tlearn: 0.0152464\ttotal: 931ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3209\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "0:\tlearn: 0.3375109\ttotal: 28.1ms\tremaining: 1.24s\n",
            "1:\tlearn: 0.2176891\ttotal: 49.1ms\tremaining: 1.05s\n",
            "2:\tlearn: 0.1674932\ttotal: 71.8ms\tremaining: 1s\n",
            "3:\tlearn: 0.1458531\ttotal: 95.3ms\tremaining: 977ms\n",
            "4:\tlearn: 0.1277541\ttotal: 118ms\tremaining: 945ms\n",
            "5:\tlearn: 0.1210375\ttotal: 136ms\tremaining: 887ms\n",
            "6:\tlearn: 0.1151019\ttotal: 159ms\tremaining: 864ms\n",
            "7:\tlearn: 0.1081074\ttotal: 182ms\tremaining: 841ms\n",
            "8:\tlearn: 0.1020136\ttotal: 201ms\tremaining: 806ms\n",
            "9:\tlearn: 0.0970428\ttotal: 213ms\tremaining: 747ms\n",
            "10:\tlearn: 0.0860568\ttotal: 233ms\tremaining: 719ms\n",
            "11:\tlearn: 0.0795166\ttotal: 245ms\tremaining: 673ms\n",
            "12:\tlearn: 0.0741892\ttotal: 257ms\tremaining: 631ms\n",
            "13:\tlearn: 0.0665348\ttotal: 268ms\tremaining: 593ms\n",
            "14:\tlearn: 0.0634794\ttotal: 289ms\tremaining: 577ms\n",
            "15:\tlearn: 0.0622037\ttotal: 312ms\tremaining: 565ms\n",
            "16:\tlearn: 0.0590992\ttotal: 342ms\tremaining: 564ms\n",
            "17:\tlearn: 0.0569823\ttotal: 373ms\tremaining: 560ms\n",
            "18:\tlearn: 0.0554606\ttotal: 402ms\tremaining: 551ms\n",
            "19:\tlearn: 0.0531405\ttotal: 427ms\tremaining: 533ms\n",
            "20:\tlearn: 0.0488269\ttotal: 455ms\tremaining: 520ms\n",
            "21:\tlearn: 0.0474172\ttotal: 480ms\tremaining: 502ms\n",
            "22:\tlearn: 0.0459131\ttotal: 503ms\tremaining: 481ms\n",
            "23:\tlearn: 0.0448672\ttotal: 522ms\tremaining: 456ms\n",
            "24:\tlearn: 0.0420708\ttotal: 545ms\tremaining: 436ms\n",
            "25:\tlearn: 0.0409108\ttotal: 570ms\tremaining: 417ms\n",
            "26:\tlearn: 0.0393012\ttotal: 593ms\tremaining: 395ms\n",
            "27:\tlearn: 0.0379897\ttotal: 624ms\tremaining: 379ms\n",
            "28:\tlearn: 0.0347955\ttotal: 660ms\tremaining: 364ms\n",
            "29:\tlearn: 0.0316232\ttotal: 694ms\tremaining: 347ms\n",
            "30:\tlearn: 0.0296974\ttotal: 727ms\tremaining: 328ms\n",
            "31:\tlearn: 0.0276197\ttotal: 754ms\tremaining: 307ms\n",
            "32:\tlearn: 0.0274195\ttotal: 781ms\tremaining: 284ms\n",
            "33:\tlearn: 0.0258432\ttotal: 811ms\tremaining: 262ms\n",
            "34:\tlearn: 0.0244146\ttotal: 839ms\tremaining: 240ms\n",
            "35:\tlearn: 0.0232285\ttotal: 872ms\tremaining: 218ms\n",
            "36:\tlearn: 0.0220336\ttotal: 898ms\tremaining: 194ms\n",
            "37:\tlearn: 0.0208506\ttotal: 929ms\tremaining: 171ms\n",
            "38:\tlearn: 0.0200129\ttotal: 957ms\tremaining: 147ms\n",
            "39:\tlearn: 0.0193279\ttotal: 990ms\tremaining: 124ms\n",
            "40:\tlearn: 0.0185371\ttotal: 1.02s\tremaining: 99.7ms\n",
            "41:\tlearn: 0.0177718\ttotal: 1.05s\tremaining: 75.4ms\n",
            "42:\tlearn: 0.0168416\ttotal: 1.08s\tremaining: 50.5ms\n",
            "43:\tlearn: 0.0161007\ttotal: 1.11s\tremaining: 25.3ms\n",
            "44:\tlearn: 0.0152464\ttotal: 1.14s\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 222, number of negative: 2250\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3209\n",
            "[LightGBM] [Info] Number of data points in the train set: 2472, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089806 -> initscore=-2.316008\n",
            "[LightGBM] [Info] Start training from score -2.316008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\tlearn: 0.3427439\ttotal: 13ms\tremaining: 573ms\n",
            "1:\tlearn: 0.2145218\ttotal: 24.3ms\tremaining: 523ms\n",
            "2:\tlearn: 0.1689906\ttotal: 33.8ms\tremaining: 473ms\n",
            "3:\tlearn: 0.1475432\ttotal: 42.9ms\tremaining: 439ms\n",
            "4:\tlearn: 0.1316782\ttotal: 51.9ms\tremaining: 415ms\n",
            "5:\tlearn: 0.1220640\ttotal: 60.9ms\tremaining: 396ms\n",
            "6:\tlearn: 0.1114936\ttotal: 70ms\tremaining: 380ms\n",
            "7:\tlearn: 0.1076156\ttotal: 79.4ms\tremaining: 367ms\n",
            "8:\tlearn: 0.0997450\ttotal: 89.3ms\tremaining: 357ms\n",
            "9:\tlearn: 0.0943125\ttotal: 109ms\tremaining: 383ms\n",
            "10:\tlearn: 0.0857051\ttotal: 124ms\tremaining: 384ms\n",
            "11:\tlearn: 0.0805959\ttotal: 137ms\tremaining: 376ms\n",
            "12:\tlearn: 0.0767948\ttotal: 146ms\tremaining: 361ms\n",
            "13:\tlearn: 0.0714441\ttotal: 155ms\tremaining: 344ms\n",
            "14:\tlearn: 0.0686166\ttotal: 164ms\tremaining: 328ms\n",
            "15:\tlearn: 0.0648519\ttotal: 173ms\tremaining: 313ms\n",
            "16:\tlearn: 0.0615071\ttotal: 182ms\tremaining: 300ms\n",
            "17:\tlearn: 0.0572561\ttotal: 191ms\tremaining: 287ms\n",
            "18:\tlearn: 0.0544884\ttotal: 202ms\tremaining: 276ms\n",
            "19:\tlearn: 0.0509123\ttotal: 212ms\tremaining: 265ms\n",
            "20:\tlearn: 0.0492362\ttotal: 226ms\tremaining: 259ms\n",
            "21:\tlearn: 0.0448815\ttotal: 235ms\tremaining: 246ms\n",
            "22:\tlearn: 0.0425944\ttotal: 245ms\tremaining: 234ms\n",
            "23:\tlearn: 0.0414056\ttotal: 253ms\tremaining: 222ms\n",
            "24:\tlearn: 0.0397840\ttotal: 262ms\tremaining: 210ms\n",
            "25:\tlearn: 0.0373513\ttotal: 274ms\tremaining: 200ms\n",
            "26:\tlearn: 0.0343745\ttotal: 284ms\tremaining: 189ms\n",
            "27:\tlearn: 0.0332783\ttotal: 293ms\tremaining: 178ms\n",
            "28:\tlearn: 0.0330218\ttotal: 302ms\tremaining: 167ms\n",
            "29:\tlearn: 0.0313443\ttotal: 315ms\tremaining: 157ms\n",
            "30:\tlearn: 0.0304942\ttotal: 324ms\tremaining: 146ms\n",
            "31:\tlearn: 0.0294333\ttotal: 333ms\tremaining: 135ms\n",
            "32:\tlearn: 0.0284563\ttotal: 341ms\tremaining: 124ms\n",
            "33:\tlearn: 0.0268455\ttotal: 351ms\tremaining: 113ms\n",
            "34:\tlearn: 0.0246594\ttotal: 361ms\tremaining: 103ms\n",
            "35:\tlearn: 0.0242822\ttotal: 369ms\tremaining: 92.3ms\n",
            "36:\tlearn: 0.0232366\ttotal: 379ms\tremaining: 81.8ms\n",
            "37:\tlearn: 0.0230477\ttotal: 387ms\tremaining: 71.4ms\n",
            "38:\tlearn: 0.0217319\ttotal: 396ms\tremaining: 61ms\n",
            "39:\tlearn: 0.0198762\ttotal: 406ms\tremaining: 50.7ms\n",
            "40:\tlearn: 0.0197294\ttotal: 421ms\tremaining: 41.1ms\n",
            "41:\tlearn: 0.0188853\ttotal: 431ms\tremaining: 30.8ms\n",
            "42:\tlearn: 0.0169937\ttotal: 440ms\tremaining: 20.5ms\n",
            "43:\tlearn: 0.0167462\ttotal: 450ms\tremaining: 10.2ms\n",
            "44:\tlearn: 0.0162331\ttotal: 459ms\tremaining: 0us\n",
            "0:\tlearn: 0.3426847\ttotal: 10ms\tremaining: 440ms\n",
            "1:\tlearn: 0.2231983\ttotal: 18.7ms\tremaining: 403ms\n",
            "2:\tlearn: 0.1746699\ttotal: 30.1ms\tremaining: 421ms\n",
            "3:\tlearn: 0.1485142\ttotal: 40.1ms\tremaining: 411ms\n",
            "4:\tlearn: 0.1393710\ttotal: 49.1ms\tremaining: 393ms\n",
            "5:\tlearn: 0.1302300\ttotal: 57.7ms\tremaining: 375ms\n",
            "6:\tlearn: 0.1238051\ttotal: 66.4ms\tremaining: 361ms\n",
            "7:\tlearn: 0.1138519\ttotal: 75ms\tremaining: 347ms\n",
            "8:\tlearn: 0.1085171\ttotal: 83.5ms\tremaining: 334ms\n",
            "9:\tlearn: 0.1048904\ttotal: 93.9ms\tremaining: 329ms\n",
            "10:\tlearn: 0.0944177\ttotal: 103ms\tremaining: 317ms\n",
            "11:\tlearn: 0.0880679\ttotal: 111ms\tremaining: 306ms\n",
            "12:\tlearn: 0.0859471\ttotal: 124ms\tremaining: 304ms\n",
            "13:\tlearn: 0.0784929\ttotal: 133ms\tremaining: 294ms\n",
            "14:\tlearn: 0.0764983\ttotal: 142ms\tremaining: 283ms\n",
            "15:\tlearn: 0.0727936\ttotal: 150ms\tremaining: 272ms\n",
            "16:\tlearn: 0.0689096\ttotal: 159ms\tremaining: 262ms\n",
            "17:\tlearn: 0.0657597\ttotal: 168ms\tremaining: 251ms\n",
            "18:\tlearn: 0.0616969\ttotal: 177ms\tremaining: 242ms\n",
            "19:\tlearn: 0.0584334\ttotal: 185ms\tremaining: 231ms\n",
            "20:\tlearn: 0.0540995\ttotal: 194ms\tremaining: 222ms\n",
            "21:\tlearn: 0.0507504\ttotal: 202ms\tremaining: 212ms\n",
            "22:\tlearn: 0.0475492\ttotal: 211ms\tremaining: 202ms\n",
            "23:\tlearn: 0.0455451\ttotal: 220ms\tremaining: 192ms\n",
            "24:\tlearn: 0.0443469\ttotal: 228ms\tremaining: 183ms\n",
            "25:\tlearn: 0.0438724\ttotal: 237ms\tremaining: 173ms\n",
            "26:\tlearn: 0.0398617\ttotal: 246ms\tremaining: 164ms\n",
            "27:\tlearn: 0.0396607\ttotal: 254ms\tremaining: 154ms\n",
            "28:\tlearn: 0.0379253\ttotal: 263ms\tremaining: 145ms\n",
            "29:\tlearn: 0.0364779\ttotal: 274ms\tremaining: 137ms\n",
            "30:\tlearn: 0.0349501\ttotal: 283ms\tremaining: 128ms\n",
            "31:\tlearn: 0.0330412\ttotal: 292ms\tremaining: 118ms\n",
            "32:\tlearn: 0.0329241\ttotal: 300ms\tremaining: 109ms\n",
            "33:\tlearn: 0.0316933\ttotal: 309ms\tremaining: 99.9ms\n",
            "34:\tlearn: 0.0309293\ttotal: 318ms\tremaining: 90.7ms\n",
            "35:\tlearn: 0.0287118\ttotal: 336ms\tremaining: 83.9ms\n",
            "36:\tlearn: 0.0270029\ttotal: 345ms\tremaining: 74.6ms\n",
            "37:\tlearn: 0.0264056\ttotal: 355ms\tremaining: 65.4ms\n",
            "38:\tlearn: 0.0252036\ttotal: 364ms\tremaining: 56ms\n",
            "39:\tlearn: 0.0243834\ttotal: 373ms\tremaining: 46.6ms\n",
            "40:\tlearn: 0.0239067\ttotal: 381ms\tremaining: 37.2ms\n",
            "41:\tlearn: 0.0238153\ttotal: 390ms\tremaining: 27.8ms\n",
            "42:\tlearn: 0.0231949\ttotal: 398ms\tremaining: 18.5ms\n",
            "43:\tlearn: 0.0226752\ttotal: 406ms\tremaining: 9.24ms\n",
            "44:\tlearn: 0.0220857\ttotal: 415ms\tremaining: 0us\n",
            "0:\tlearn: 0.3433914\ttotal: 9.46ms\tremaining: 416ms\n",
            "1:\tlearn: 0.2179278\ttotal: 17.7ms\tremaining: 380ms\n",
            "2:\tlearn: 0.1773329\ttotal: 26.4ms\tremaining: 369ms\n",
            "3:\tlearn: 0.1595308\ttotal: 37.7ms\tremaining: 387ms\n",
            "4:\tlearn: 0.1409975\ttotal: 46.3ms\tremaining: 370ms\n",
            "5:\tlearn: 0.1320427\ttotal: 54.9ms\tremaining: 357ms\n",
            "6:\tlearn: 0.1227302\ttotal: 63.3ms\tremaining: 343ms\n",
            "7:\tlearn: 0.1147946\ttotal: 71.7ms\tremaining: 332ms\n",
            "8:\tlearn: 0.1051975\ttotal: 84.5ms\tremaining: 338ms\n",
            "9:\tlearn: 0.1013870\ttotal: 96ms\tremaining: 336ms\n",
            "10:\tlearn: 0.0965643\ttotal: 107ms\tremaining: 330ms\n",
            "11:\tlearn: 0.0903135\ttotal: 115ms\tremaining: 317ms\n",
            "12:\tlearn: 0.0820153\ttotal: 125ms\tremaining: 307ms\n",
            "13:\tlearn: 0.0759272\ttotal: 141ms\tremaining: 313ms\n",
            "14:\tlearn: 0.0712368\ttotal: 155ms\tremaining: 310ms\n",
            "15:\tlearn: 0.0685806\ttotal: 163ms\tremaining: 296ms\n",
            "16:\tlearn: 0.0619722\ttotal: 172ms\tremaining: 283ms\n",
            "17:\tlearn: 0.0588157\ttotal: 181ms\tremaining: 272ms\n",
            "18:\tlearn: 0.0570650\ttotal: 190ms\tremaining: 260ms\n",
            "19:\tlearn: 0.0543861\ttotal: 209ms\tremaining: 261ms\n",
            "20:\tlearn: 0.0524746\ttotal: 220ms\tremaining: 252ms\n",
            "21:\tlearn: 0.0512782\ttotal: 235ms\tremaining: 246ms\n",
            "22:\tlearn: 0.0503718\ttotal: 242ms\tremaining: 232ms\n",
            "23:\tlearn: 0.0475548\ttotal: 251ms\tremaining: 220ms\n",
            "24:\tlearn: 0.0459208\ttotal: 259ms\tremaining: 207ms\n",
            "25:\tlearn: 0.0447111\ttotal: 268ms\tremaining: 196ms\n",
            "26:\tlearn: 0.0443746\ttotal: 277ms\tremaining: 184ms\n",
            "27:\tlearn: 0.0418852\ttotal: 290ms\tremaining: 176ms\n",
            "28:\tlearn: 0.0407047\ttotal: 299ms\tremaining: 165ms\n",
            "29:\tlearn: 0.0368519\ttotal: 307ms\tremaining: 154ms\n",
            "30:\tlearn: 0.0334279\ttotal: 317ms\tremaining: 143ms\n",
            "31:\tlearn: 0.0333184\ttotal: 325ms\tremaining: 132ms\n",
            "32:\tlearn: 0.0307065\ttotal: 334ms\tremaining: 121ms\n",
            "33:\tlearn: 0.0299994\ttotal: 342ms\tremaining: 111ms\n",
            "34:\tlearn: 0.0295010\ttotal: 351ms\tremaining: 100ms\n",
            "35:\tlearn: 0.0288136\ttotal: 359ms\tremaining: 89.8ms\n",
            "36:\tlearn: 0.0285320\ttotal: 368ms\tremaining: 79.5ms\n",
            "37:\tlearn: 0.0275638\ttotal: 377ms\tremaining: 69.4ms\n",
            "38:\tlearn: 0.0260299\ttotal: 386ms\tremaining: 59.4ms\n",
            "39:\tlearn: 0.0247051\ttotal: 395ms\tremaining: 49.3ms\n",
            "40:\tlearn: 0.0246334\ttotal: 404ms\tremaining: 39.4ms\n",
            "41:\tlearn: 0.0236343\ttotal: 413ms\tremaining: 29.5ms\n",
            "42:\tlearn: 0.0229493\ttotal: 422ms\tremaining: 19.6ms\n",
            "43:\tlearn: 0.0227376\ttotal: 430ms\tremaining: 9.78ms\n",
            "44:\tlearn: 0.0226913\ttotal: 439ms\tremaining: 0us\n",
            "0:\tlearn: 0.3431901\ttotal: 14.1ms\tremaining: 620ms\n",
            "1:\tlearn: 0.2192930\ttotal: 23.4ms\tremaining: 503ms\n",
            "2:\tlearn: 0.1731057\ttotal: 32ms\tremaining: 447ms\n",
            "3:\tlearn: 0.1513922\ttotal: 40.6ms\tremaining: 416ms\n",
            "4:\tlearn: 0.1368336\ttotal: 49.5ms\tremaining: 396ms\n",
            "5:\tlearn: 0.1293557\ttotal: 59.8ms\tremaining: 389ms\n",
            "6:\tlearn: 0.1150403\ttotal: 69.8ms\tremaining: 379ms\n",
            "7:\tlearn: 0.1074266\ttotal: 78.8ms\tremaining: 364ms\n",
            "8:\tlearn: 0.1023948\ttotal: 87.7ms\tremaining: 351ms\n",
            "9:\tlearn: 0.0981962\ttotal: 96.2ms\tremaining: 337ms\n",
            "10:\tlearn: 0.0893434\ttotal: 105ms\tremaining: 325ms\n",
            "11:\tlearn: 0.0826279\ttotal: 114ms\tremaining: 312ms\n",
            "12:\tlearn: 0.0792929\ttotal: 122ms\tremaining: 300ms\n",
            "13:\tlearn: 0.0748216\ttotal: 131ms\tremaining: 290ms\n",
            "14:\tlearn: 0.0709660\ttotal: 140ms\tremaining: 279ms\n",
            "15:\tlearn: 0.0679487\ttotal: 148ms\tremaining: 269ms\n",
            "16:\tlearn: 0.0638423\ttotal: 157ms\tremaining: 259ms\n",
            "17:\tlearn: 0.0600235\ttotal: 166ms\tremaining: 250ms\n",
            "18:\tlearn: 0.0567800\ttotal: 175ms\tremaining: 240ms\n",
            "19:\tlearn: 0.0542438\ttotal: 186ms\tremaining: 232ms\n",
            "20:\tlearn: 0.0515795\ttotal: 200ms\tremaining: 229ms\n",
            "21:\tlearn: 0.0490214\ttotal: 209ms\tremaining: 219ms\n",
            "22:\tlearn: 0.0441175\ttotal: 222ms\tremaining: 213ms\n",
            "23:\tlearn: 0.0434470\ttotal: 232ms\tremaining: 203ms\n",
            "24:\tlearn: 0.0429407\ttotal: 241ms\tremaining: 192ms\n",
            "25:\tlearn: 0.0407942\ttotal: 249ms\tremaining: 182ms\n",
            "26:\tlearn: 0.0402757\ttotal: 258ms\tremaining: 172ms\n",
            "27:\tlearn: 0.0377500\ttotal: 267ms\tremaining: 162ms\n",
            "28:\tlearn: 0.0353398\ttotal: 276ms\tremaining: 152ms\n",
            "29:\tlearn: 0.0345122\ttotal: 285ms\tremaining: 143ms\n",
            "30:\tlearn: 0.0333013\ttotal: 294ms\tremaining: 133ms\n",
            "31:\tlearn: 0.0322262\ttotal: 303ms\tremaining: 123ms\n",
            "32:\tlearn: 0.0317857\ttotal: 312ms\tremaining: 113ms\n",
            "33:\tlearn: 0.0306564\ttotal: 321ms\tremaining: 104ms\n",
            "34:\tlearn: 0.0302940\ttotal: 330ms\tremaining: 94.2ms\n",
            "35:\tlearn: 0.0294239\ttotal: 338ms\tremaining: 84.6ms\n",
            "36:\tlearn: 0.0286111\ttotal: 347ms\tremaining: 75.1ms\n",
            "37:\tlearn: 0.0277723\ttotal: 357ms\tremaining: 65.7ms\n",
            "38:\tlearn: 0.0267440\ttotal: 366ms\tremaining: 56.3ms\n",
            "39:\tlearn: 0.0264700\ttotal: 375ms\tremaining: 46.9ms\n",
            "40:\tlearn: 0.0246159\ttotal: 385ms\tremaining: 37.6ms\n",
            "41:\tlearn: 0.0239892\ttotal: 395ms\tremaining: 28.2ms\n",
            "42:\tlearn: 0.0237922\ttotal: 404ms\tremaining: 18.8ms\n",
            "43:\tlearn: 0.0234816\ttotal: 413ms\tremaining: 9.39ms\n",
            "44:\tlearn: 0.0230912\ttotal: 427ms\tremaining: 0us\n",
            "0:\tlearn: 0.3402991\ttotal: 9.53ms\tremaining: 419ms\n",
            "1:\tlearn: 0.2231404\ttotal: 18.2ms\tremaining: 392ms\n",
            "2:\tlearn: 0.1759218\ttotal: 30.2ms\tremaining: 423ms\n",
            "3:\tlearn: 0.1515803\ttotal: 42.5ms\tremaining: 435ms\n",
            "4:\tlearn: 0.1369999\ttotal: 51.9ms\tremaining: 415ms\n",
            "5:\tlearn: 0.1300142\ttotal: 62.2ms\tremaining: 404ms\n",
            "6:\tlearn: 0.1223263\ttotal: 70.8ms\tremaining: 384ms\n",
            "7:\tlearn: 0.1095727\ttotal: 79.5ms\tremaining: 368ms\n",
            "8:\tlearn: 0.1046594\ttotal: 88.3ms\tremaining: 353ms\n",
            "9:\tlearn: 0.1001246\ttotal: 97.6ms\tremaining: 342ms\n",
            "10:\tlearn: 0.0947474\ttotal: 107ms\tremaining: 330ms\n",
            "11:\tlearn: 0.0866883\ttotal: 120ms\tremaining: 331ms\n",
            "12:\tlearn: 0.0845025\ttotal: 131ms\tremaining: 322ms\n",
            "13:\tlearn: 0.0790414\ttotal: 141ms\tremaining: 313ms\n",
            "14:\tlearn: 0.0752014\ttotal: 151ms\tremaining: 302ms\n",
            "15:\tlearn: 0.0720376\ttotal: 165ms\tremaining: 299ms\n",
            "16:\tlearn: 0.0690210\ttotal: 183ms\tremaining: 302ms\n",
            "17:\tlearn: 0.0644226\ttotal: 199ms\tremaining: 299ms\n",
            "18:\tlearn: 0.0605009\ttotal: 211ms\tremaining: 288ms\n",
            "19:\tlearn: 0.0587194\ttotal: 223ms\tremaining: 278ms\n",
            "20:\tlearn: 0.0570225\ttotal: 231ms\tremaining: 264ms\n",
            "21:\tlearn: 0.0546859\ttotal: 240ms\tremaining: 251ms\n",
            "22:\tlearn: 0.0514577\ttotal: 249ms\tremaining: 238ms\n",
            "23:\tlearn: 0.0482000\ttotal: 258ms\tremaining: 226ms\n",
            "24:\tlearn: 0.0467094\ttotal: 267ms\tremaining: 214ms\n",
            "25:\tlearn: 0.0432172\ttotal: 276ms\tremaining: 202ms\n",
            "26:\tlearn: 0.0414340\ttotal: 285ms\tremaining: 190ms\n",
            "27:\tlearn: 0.0386684\ttotal: 294ms\tremaining: 179ms\n",
            "28:\tlearn: 0.0381396\ttotal: 303ms\tremaining: 167ms\n",
            "29:\tlearn: 0.0355582\ttotal: 312ms\tremaining: 156ms\n",
            "30:\tlearn: 0.0346826\ttotal: 321ms\tremaining: 145ms\n",
            "31:\tlearn: 0.0315669\ttotal: 330ms\tremaining: 134ms\n",
            "32:\tlearn: 0.0313656\ttotal: 339ms\tremaining: 123ms\n",
            "33:\tlearn: 0.0303227\ttotal: 347ms\tremaining: 112ms\n",
            "34:\tlearn: 0.0287261\ttotal: 356ms\tremaining: 102ms\n",
            "35:\tlearn: 0.0276237\ttotal: 371ms\tremaining: 92.8ms\n",
            "36:\tlearn: 0.0257261\ttotal: 380ms\tremaining: 82.3ms\n",
            "37:\tlearn: 0.0246158\ttotal: 389ms\tremaining: 71.7ms\n",
            "38:\tlearn: 0.0232443\ttotal: 398ms\tremaining: 61.2ms\n",
            "39:\tlearn: 0.0231279\ttotal: 407ms\tremaining: 50.9ms\n",
            "40:\tlearn: 0.0216461\ttotal: 416ms\tremaining: 40.6ms\n",
            "41:\tlearn: 0.0199874\ttotal: 424ms\tremaining: 30.3ms\n",
            "42:\tlearn: 0.0190831\ttotal: 433ms\tremaining: 20.1ms\n",
            "43:\tlearn: 0.0188735\ttotal: 441ms\tremaining: 10ms\n",
            "44:\tlearn: 0.0185279\ttotal: 450ms\tremaining: 0us\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 177, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2877\n",
            "[LightGBM] [Info] Number of data points in the train set: 1977, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089530 -> initscore=-2.319392\n",
            "[LightGBM] [Info] Start training from score -2.319392\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2933\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2926\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 178, number of negative: 1800\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3098\n",
            "[LightGBM] [Info] Number of data points in the train set: 1978, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089990 -> initscore=-2.313758\n",
            "[LightGBM] [Info] Start training from score -2.313758\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "                                          Classifier  Accuracy       mcc  \\\n",
            "0  (DecisionTreeClassifier(max_depth=9, max_featu...  0.962783  0.752634   \n",
            "1                DecisionTreeClassifier(max_depth=5)  0.943366  0.622615   \n",
            "2  (ExtraTreeClassifier(max_depth=7, random_state...  0.922330  0.362789   \n",
            "3                             KNeighborsClassifier()  0.933657  0.526758   \n",
            "4  <catboost.core.CatBoostClassifier object at 0x...  0.966019  0.775682   \n",
            "5  (DecisionTreeClassifier(max_depth=1, random_st...  0.953074  0.685916   \n",
            "6  XGBClassifier(base_score=0.5, booster=None, ca...  0.969256  0.799849   \n",
            "7       LGBMClassifier(max_depth=7, random_state=50)  0.964401  0.763941   \n",
            "8  StackingClassifier(estimators=[('RF',\\n       ...  0.959547  0.727335   \n",
            "\n",
            "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
            "0  0.738434   0.923077  0.642857  0.757895     0.994662     0.642857  \n",
            "1  0.616258   0.744186  0.571429  0.646465     0.980427     0.571429  \n",
            "2  0.232616   1.000000  0.142857  0.250000     1.000000     0.142857  \n",
            "3  0.506140   0.727273  0.428571  0.539326     0.983986     0.428571  \n",
            "4  0.756647   0.972973  0.642857  0.774194     0.998221     0.642857  \n",
            "5  0.676229   0.829268  0.607143  0.701031     0.987544     0.607143  \n",
            "6  0.791683   0.930233  0.714286  0.808081     0.994662     0.714286  \n",
            "7  0.747455   0.947368  0.642857  0.765957     0.996441     0.642857  \n",
            "8  0.698866   0.969697  0.571429  0.719101     0.998221     0.571429  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
